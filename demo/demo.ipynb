{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19a0bac3",
   "metadata": {},
   "source": [
    "This is a notebook that based on software mention from a paper, doi of that paper and paragraph surronding the software mention retrieves URLs that software is refering to. User has two options:\n",
    "1. **As an input, putting csv file with columns name, doi and paragraph (optional column candidate_urls). \n",
    "2. As an input, entering name, doi and paragraph, optionally candidate_urls separated by comma\n",
    "ADD SOFTWARE MENTION EXACTLY AS MENTIONED IN THE PAPER AND PARAGRAPH SURROUNDING THE MENTION.**\n",
    "\n",
    "**IMPORTANT**\n",
    "In order for a notebook to work, it is necessary to have a CZI folder with synonym_matrix inside of it, folder with code and model_pipeline file with the model (when downloading the zip with the notebook, all are included). \n",
    "Only URLs that are valid are the ones belonging to GitHub, PyPI and CRAN.\n",
    "Only thing that needs to be changed in the notebook is right bellow in the first cell and it is clearly marked:\n",
    "input_file - if input is file, provide the path to it\n",
    "model_input_path - path to the file that is input to the model, if path is not provided the default (./model_input.csv) is be used \n",
    "output_path_aggregated_groups - path to the file that is general output, this file will contain all mentions with their metadata and columns url (URLs which software is refering to) andd not url (URLs which software is not refering to), if not provided default (./aggregated_groups.csv) is used \n",
    "**OPTIONAL** - in the process a lot of files can be produced in order to follow the process. If you wish to produce these files change paths for them or leave the current default versions, if you wish to not save any of them, put None.\n",
    "output_file_corpus - path to the file that will contain software mention/s with all additional data added (synonyms, language, authors and candidate URLs)\n",
    "output_path_pairs - path to the file that will contain software mention/s paired with each candidate URLs found\n",
    "output_path_updated_with_metadata - path to the file that will contain software mention/s with all aditional data added, as well as metadata fetched from each URL\n",
    "output_path_similarities - path to the file that will contain software mention/s with all additional data and metadata, as well as similarities calculated\n",
    "output_path_predictions - path to the file that has all columns like similarities file, with addition of prediction made by model\n",
    "\n",
    "WHAT DOES NOTEBOOK DO:\n",
    "1. For each pair of software mention/doi/paragraph are fetched:\n",
    "    -   language (searches paragraph to find a programming language closest to the software mention)\n",
    "    -   synonyms (searches CZI to find synonyms of software mention)\n",
    "    -   authors (uses openAlex tool to get names of the paper authors)\n",
    "    -   candidate URLs (searches GitHub, PyPI and CRAN  to get possible URLs software may be refering to)\n",
    "2. Updates metadata cache JSON file that containts all up until now fetched metadata from URLs\n",
    "3. Makes pairs of software mention and URL for every software and URL candidate\n",
    "4. Adds metadata fetched from URLs\n",
    "5. Calculates similarities for every software/URL pair\n",
    "    -   software name, author and synonym similarities are calculated using Jaro Wrinkler\n",
    "    -   paragraph and repository description similarity is calculated using BERT model\n",
    "6. Selects columns necessary for the model and feeds the input to receive a predictions\n",
    "7. When predictions are there, groups rows based on software name, doi and paragraph and separates candidate URLs into two columns url and not url, based on the prediction\n",
    "Model used for prediction is Random Forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789662a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "#Add the path to the input file (optional)\n",
    "input_file = \"\"\n",
    "if input_file is None or input_file == \"\":\n",
    "    name = input(\"Enter the software mention: \")\n",
    "    if name == \"\":\n",
    "        print(\"No software mention provided. Exiting.\")\n",
    "        sys.exit(1)\n",
    "    paragraph = input(\"Enter the paragraph: \")\n",
    "    if paragraph == \"\":\n",
    "        print(\"No paragraph provided. Exiting.\")\n",
    "        sys.exit(1)\n",
    "    doi = input(\"Enter the DOI: \")\n",
    "    if doi == \"\":\n",
    "        print(\"No DOI provided. Exiting.\")\n",
    "        sys.exit(1)\n",
    "    candidate_urls = input(\"Enter the candidate URLs (comma-separated, optional): \")\n",
    "    input_dataframe = pd.DataFrame({\n",
    "        'name': [name],\n",
    "        'paragraph': [paragraph],\n",
    "        'doi': [doi],\n",
    "        'candidate_urls': [candidate_urls]\n",
    "    })\n",
    "else:\n",
    "    input_dataframe = pd.read_csv(input_file,delimiter=';')\n",
    "# Add the path to the output file for file with added languages, synonyms, authors and candidate URLs (optional)\n",
    "output_file_corpus = \"./temp/softwares_with_languages.csv\"\n",
    "# Add the path to the output file for file with pairs of software names with candidate URLs (optional)\n",
    "output_path_pairs = \"./temp/pairs.csv\"\n",
    "# Add the path to the output file for file with added metadata (optional)\n",
    "output_path_updated_with_metadata = \"./temp/updated_with_metadata_file.csv\"\n",
    "# Add the path to the output file for file with calculated similarities (optional)\n",
    "output_path_similarities = \"./temp/similarities.csv\"\n",
    "# Add the path to the output file for file with model input\n",
    "model_input_path = \"./model_input.csv\"\n",
    "if model_input_path is None or model_input_path == \"\":\n",
    "    model_input_path = \"./model_input.csv\"\n",
    "# Add the path to the output file with predictions (optional)\n",
    "output_path_predictions = \"./temp/predictions.csv\"\n",
    "# Add the path to the output file with aggregated groups)\n",
    "output_path_aggregated_groups = \"./aggregated_groups.csv\"\n",
    "if output_path_aggregated_groups is None or output_path_aggregated_groups == \"\":\n",
    "    output_path_aggregated_groups = \"./aggregated_groups.csv\"\n",
    "\n",
    "\n",
    "candidates_cache_file = \"./candidate_urls.json\"\n",
    "synonyms_file = \"./synonym_dictionary.json\"\n",
    "metadata_cache_file = \"./metadata_cache.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986fe4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Add ../code to sys.path (1 level up from demo, into code)\n",
    "sys.path.append(os.path.abspath(\"../code\"))\n",
    "\n",
    "from preprocessing_corpus import find_nearest_language_for_softwares,get_authors,get_synonyms_from_file, make_pairs, dictionary_with_candidate_metadata, add_metadata,aggregate_group\n",
    "from fetch_candidates import get_candidate_urls\n",
    "from similarity_metrics import compute_similarity_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "950a1b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae992ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CZI = pd.read_csv(\"./CZI/synonyms_matrix.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ff316f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jelena\\AppData\\Local\\Temp\\ipykernel_15720\\4038535159.py:23: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  input_dataframe.fillna(value=np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Get the synonyms from the file\n",
    "get_synonyms_from_file(synonyms_file, input_dataframe,CZI_df=CZI)\n",
    "# Find the nearest language for each software\n",
    "input_dataframe['language'] = input_dataframe.apply(\n",
    "    lambda row: find_nearest_language_for_softwares(row['paragraph'], row['name']), axis=1\n",
    ")\n",
    "results = input_dataframe['doi'].apply(get_authors)\n",
    "input_dataframe['authors'] = results.apply(lambda x: ','.join(x.get('authors', [])) if isinstance(x, dict) else '')\n",
    "# Get candidate URLs for each software\n",
    "input_dataframe=get_candidate_urls(input_dataframe, candidates_cache_file)\n",
    "#Fill all missing values with Nan\n",
    "input_dataframe.fillna(value=np.nan, inplace=True)\n",
    "# Save the updated DataFrame to a new CSV file (optional)\n",
    "if output_file_corpus is not None and output_file_corpus != \"\":\n",
    "    input_dataframe.to_csv(output_file_corpus, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6395460e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All done â€” cache saved to ./metadata_cache.json\n",
      "ðŸ“„ Updated CSV file saved to ./temp/updated_with_metadata_file.csv\n",
      "ðŸ“„ Similarity metrics saved to ./temp/similarities.csv\n"
     ]
    }
   ],
   "source": [
    "#input_dataframe = pd.read_csv(output_file_corpus)\n",
    "metadata_cache = dictionary_with_candidate_metadata(input_dataframe, metadata_cache_file)\n",
    "input_dataframe= make_pairs(input_dataframe,output_path_pairs)\n",
    "\n",
    "add_metadata(input_dataframe,metadata_cache, output_path_updated_with_metadata)\n",
    "input_dataframe= compute_similarity_test(input_dataframe,output_path_similarities)\n",
    "\n",
    "model_input = input_dataframe[['name_metric', 'paragraph_metric','language_metric','synonym_metric','author_metric']].copy()\n",
    "model_input.to_csv(model_input_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4061868d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Output files generated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jelena\\AppData\\Local\\Temp\\ipykernel_15720\\2920222209.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped = input_dataframe.groupby(['name', 'paragraph', 'doi']).apply(aggregate_group).reset_index()\n"
     ]
    }
   ],
   "source": [
    "#Loading model\n",
    "\n",
    "model = joblib.load(\"../model_pipeline.joblib\")\n",
    "predictions = model.predict(model_input)\n",
    "# Add predictions to the input DataFrame\n",
    "input_dataframe['prediction'] = predictions\n",
    "# Save the final DataFrame with predictions to a new CSV file\n",
    "if output_path_similarities is not None:\n",
    "    input_dataframe.to_csv(output_path_similarities, index=False)\n",
    "grouped = input_dataframe.groupby(['name', 'paragraph', 'doi']).apply(aggregate_group).reset_index()\n",
    "grouped.to_csv(output_path_aggregated_groups, index=False)\n",
    "print(\"Processing complete. Output files generated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
