{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19a0bac3",
   "metadata": {},
   "source": [
    "# ğŸ” Software Mention Disambiguation Notebook\n",
    "\n",
    "This notebook identifies which software repository (GitHub, PyPI, or CRAN) a software mention from a scientific paper refers to.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ› ï¸ Input Options\n",
    "\n",
    "You can provide the software mention in two ways:\n",
    "\n",
    "1. **CSV input**: File must include columns:\n",
    "   - `name` (software mention)\n",
    "   - `doi` (paper DOI)\n",
    "   - `paragraph` (context around the mention)\n",
    "   - `candidate_urls` (optional, comma-separated list of URLs)\n",
    "\n",
    "2. **Manual input**: If no CSV is provided, you'll be prompted to enter:\n",
    "   - Software name (as mentioned in the paper)\n",
    "   - Paragraph\n",
    "   - DOI\n",
    "   - Candidate URLs (optional, comma-separated)\n",
    "\n",
    "âš ï¸ **Make sure to copy the software mention *exactly as in the paper* and include the surrounding paragraph.**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ Folder Structure (Expected)\n",
    "\n",
    "These must be present for the notebook to work:\n",
    "```\n",
    "â”œâ”€â”€ demo.ipynb\n",
    "â”œâ”€â”€ model.pkl                     â† Trained model\n",
    "â”œâ”€â”€ preprocessing.py             â† Utility functions\n",
    "â”œâ”€â”€ models.py                    â† ML model utilities\n",
    "â”œâ”€â”€ CZI/synonyms_matrix.csv      â† Synonym mapping\n",
    "â”œâ”€â”€ json/\n",
    "â”‚   â”œâ”€â”€ candidate_urls.json\n",
    "â”‚   â”œâ”€â”€ synonym_dictionary.json\n",
    "â”‚   â””â”€â”€ metadata_cache.json      â† JSON caches\n",
    "```\n",
    "If the `json/` folder is missing, it will be recreated during execution â€” make sure you set valid paths for those files if you want to store them.\n",
    "\n",
    "Optional output files will be saved in:\n",
    "```\n",
    "â”œâ”€â”€ temp/\n",
    "â”‚   â”œâ”€â”€ corpus_with_candidates.csv\n",
    "â”‚   â”œâ”€â”€ pairs.csv\n",
    "â”‚   â”œâ”€â”€ updated_with_metadata.csv\n",
    "â”‚   â”œâ”€â”€ similarities.csv\n",
    "â”‚   â””â”€â”€ predictions.csv\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## âœï¸ Configuration (Edit Below)\n",
    "\n",
    "In the first code cell:\n",
    "- `input_file`: Path to your CSV input\n",
    "- `model_path`: Path to model (`./model.pkl` by default)\n",
    "- `model_input_path`: File for model input\n",
    "- `output_path_aggregated_groups`: Final file with URLs predicted as relevant (`url`) and irrelevant (`not url`)\n",
    "- `somef_path`: Path to cloned SOMEF repository\n",
    "\n",
    "If you do **not** want to save intermediate files, set those output paths to `None`.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸŒ GitHub Token\n",
    "GitHub API access requires a token. Instructions:\n",
    "https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token\n",
    "\n",
    "To use GitHub search functionality, you **must** set an environment variable:\n",
    "```bash\n",
    "export GITHUB_TOKEN=your_token_here     # macOS/Linux\n",
    "set GITHUB_TOKEN=your_token_here        # Windows\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§© SOMEF\n",
    "\n",
    "This notebook requires [SOMEF](https://github.com/KnowledgeCaptureAndDiscovery/somef) to fetch repository metadata.\n",
    "\n",
    "Clone the repo (and follow instructions provided in repository README) and set `somef_path` in the notebook.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  What Happens Inside\n",
    "\n",
    "1. Extracts extra info for each mention:\n",
    "   - Language (from paragraph)\n",
    "   - Synonyms (from CZI)\n",
    "   - Authors (from OpenAlex)\n",
    "   - Candidate URLs (from GitHub, PyPI, CRAN)\n",
    "2. Adds metadata for each candidate URL\n",
    "3. Computes similarities:\n",
    "   - Jaro-Winkler (name, authors, synonyms)\n",
    "   - BERT (paragraph vs. repo description)\n",
    "4. Predicts with a Random Forest model\n",
    "5. Aggregates output with predicted `url` and `not url`\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Output\n",
    "\n",
    "- Final results are saved to: **`aggregated_groups.csv`**\n",
    "- Contains original fields + classified URLs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "789662a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "#Add the path to the input file (optional)\n",
    "input_file = \"./input.csv\"\n",
    "if input_file is None or input_file == \"\":\n",
    "    name = input(\"Enter the software mention: \")\n",
    "    if name == \"\":\n",
    "        print(\"No software mention provided. Exiting.\")\n",
    "        sys.exit(1)\n",
    "    paragraph = input(\"Enter the paragraph: \")\n",
    "    if paragraph == \"\":\n",
    "        print(\"No paragraph provided. Exiting.\")\n",
    "        sys.exit(1)\n",
    "    doi = input(\"Enter the DOI: \")\n",
    "    if doi == \"\":\n",
    "        print(\"No DOI provided. Exiting.\")\n",
    "        sys.exit(1)\n",
    "    candidate_urls = input(\"Enter the candidate URLs (comma-separated, optional): \")\n",
    "    input_dataframe = pd.DataFrame({\n",
    "        'name': [name],\n",
    "        'paragraph': [paragraph],\n",
    "        'doi': [doi],\n",
    "        'candidate_urls': [candidate_urls]\n",
    "    })\n",
    "else:\n",
    "    input_dataframe = pd.read_csv(input_file,delimiter=';')\n",
    "# Add the path to the output file for file with added languages, synonyms, authors and candidate URLs (optional)\n",
    "output_file_corpus = './temp/corpus_with_candidates.csv'\n",
    "# Add the path to the output file for file with pairs of software names with candidate URLs (optional)\n",
    "output_path_pairs = \"./temp/pairs.csv\"\n",
    "# Add the path to the output file for file with added metadata (optional)\n",
    "output_path_updated_with_metadata = \"./temp/updated_with_metadata.csv\"\n",
    "# Add the path to the output file for file with calculated similarities (optional)\n",
    "output_path_similarities = \"./temp/similarities.csv\"\n",
    "#Add the path to the model\n",
    "model_path = \"./model.pkl\"\n",
    "if model_path is None or model_path == \"\":\n",
    "    model_path = \"./model.pkl\"\n",
    "# Add the path to the output file for file with model input\n",
    "model_input_path = \"./model_input.csv\"\n",
    "if model_input_path is None or model_input_path == \"\":\n",
    "    model_input_path = \"./model_input.csv\"\n",
    "# Add the path to the output file with predictions (optional)\n",
    "output_path_predictions = \"./temp/predictions.csv\"\n",
    "# Add the path to the output file with aggregated groups)\n",
    "output_path_aggregated_groups = \"./aggregated_groups.csv\"\n",
    "if output_path_aggregated_groups is None or output_path_aggregated_groups == \"\":\n",
    "    output_path_aggregated_groups = \"./aggregated_groups.csv\"\n",
    "\n",
    "# Add the path to the somef repository\n",
    "somef_path = \"D:/MASTER/TMF/somef\"\n",
    "\n",
    "\n",
    "candidates_cache_file = \"./json/candidate_urls.json\"\n",
    "synonyms_file = \"./json/synonym_dictionary.json\"\n",
    "metadata_cache_file = \"./json/metadata_cache.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "986fe4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "\n",
    "\n",
    "from preprocessing import find_nearest_language_for_softwares,get_authors,get_synonyms_from_file, make_pairs, dictionary_with_candidate_metadata, add_metadata,aggregate_group,get_candidate_urls,compute_similarity_test\n",
    "from models import make_model, get_preprocessing_pipeline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "950a1b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae992ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CZI = pd.read_csv(\"./CZI/synonyms_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0ff316f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Attempt 1] Rate limited. Sleeping 35s until resetâ€¦\n",
      "[Attempt 2] Rate limited. Sleeping 1s until resetâ€¦\n",
      "[Attempt 1] Rate limited. Sleeping 37s until resetâ€¦\n",
      "[Attempt 2] Rate limited. Sleeping 1s until resetâ€¦\n",
      "[Attempt 1] Rate limited. Sleeping 35s until resetâ€¦\n",
      "[Attempt 2] Rate limited. Sleeping 1s until resetâ€¦\n",
      "[Attempt 1] Rate limited. Sleeping 37s until resetâ€¦\n",
      "[Attempt 2] Rate limited. Sleeping 1s until resetâ€¦\n",
      "[Attempt 1] Rate limited. Sleeping 35s until resetâ€¦\n",
      "[Attempt 2] Rate limited. Sleeping 1s until resetâ€¦\n",
      "[Attempt 1] Rate limited. Sleeping 35s until resetâ€¦\n",
      "[Attempt 2] Rate limited. Sleeping 1s until resetâ€¦\n",
      "[Attempt 1] Rate limited. Sleeping 36s until resetâ€¦\n",
      "[Attempt 2] Rate limited. Sleeping 1s until resetâ€¦\n",
      "[Attempt 1] Rate limited. Sleeping 36s until resetâ€¦\n",
      "[Attempt 2] Rate limited. Sleeping 1s until resetâ€¦\n",
      "[Attempt 1] Rate limited. Sleeping 36s until resetâ€¦\n",
      "[Attempt 2] Rate limited. Sleeping 1s until resetâ€¦\n",
      "[Attempt 1] Rate limited. Sleeping 36s until resetâ€¦\n",
      "[Attempt 2] Rate limited. Sleeping 1s until resetâ€¦\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Get the synonyms from the file\n",
    "get_synonyms_from_file(synonyms_file, input_dataframe,CZI_df=CZI)\n",
    "# Find the nearest language for each software\n",
    "input_dataframe['language'] = input_dataframe.apply(\n",
    "    lambda row: find_nearest_language_for_softwares(row['paragraph'], row['name']), axis=1\n",
    ")\n",
    "results = input_dataframe['doi'].apply(get_authors)\n",
    "input_dataframe['authors'] = results.apply(lambda x: ','.join(x.get('authors', [])) if isinstance(x, dict) else '')\n",
    "# Get candidate URLs for each software\n",
    "input_dataframe=get_candidate_urls(input_dataframe, candidates_cache_file)\n",
    "#Fill all missing values with Nan\n",
    "input_dataframe.fillna(value=np.nan, inplace=True)\n",
    "# Save the updated DataFrame to a new CSV file (optional)\n",
    "if output_file_corpus is not None and output_file_corpus != \"\":\n",
    "    input_dataframe.to_csv(output_file_corpus, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6395460e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Processing: https://github.com/swagger-api/swagger-codegen\n",
      "Failed to extract metadata for https://github.com/swagger-api/swagger-codegen: Command '['poetry', 'run', 'somef', 'describe', '-r', 'https://github.com/swagger-api/swagger-codegen', '-o', 'C:\\\\Users\\\\Jelena\\\\AppData\\\\Local\\\\Temp\\\\tmpmkc00mrh.json', '-t', '0.93', '-m', '-kt', '\\\\\\\\?\\\\D:\\\\MASTER\\\\TMF\\\\somef\\\\temp']' returned non-zero exit status 1.\n",
      "ğŸ” Processing: https://github.com/LatticeX-Foundation/Rosetta\n",
      "Failed to extract metadata for https://github.com/LatticeX-Foundation/Rosetta: Command '['poetry', 'run', 'somef', 'describe', '-r', 'https://github.com/LatticeX-Foundation/Rosetta', '-o', 'C:\\\\Users\\\\Jelena\\\\AppData\\\\Local\\\\Temp\\\\tmp90hzh3lw.json', '-t', '0.93', '-m', '-kt', '\\\\\\\\?\\\\D:\\\\MASTER\\\\TMF\\\\somef\\\\temp']' returned non-zero exit status 1.\n",
      "ğŸ” Processing: https://pypi.org/project/sph/\n",
      "ğŸ” Processing: https://github.com/danjulio/MPPT-Solar-Charger\n",
      "ğŸ” Processing: https://cran.r-project.org/package=STAND\n",
      "ğŸ” Processing: https://cran.r-project.org/package=symengine\n",
      "ğŸ” Processing: https://github.com/KurtBestor/Hitomi-Downloader\n",
      "ğŸ” Processing: https://github.com/nutriverse/zscorer\n",
      "ğŸ” Processing: https://cran.r-project.org/package=nlnet\n",
      "ğŸ” Processing: https://pypi.org/project/pandaa/\n",
      "ğŸ” Processing: https://github.com/FaridSafi/react-native-gifted-form\n",
      "ğŸ” Processing: https://cran.r-project.org/package=svgViewR\n",
      "ğŸ” Processing: https://github.com/semuconsulting/PyGPSClient\n",
      "ğŸ” Processing: https://github.com/smistad/FAST\n",
      "ğŸ” Processing: https://pypi.org/project/tau/\n",
      "ğŸ” Processing: https://cran.r-project.org/package=SPSL\n",
      "ğŸ” Processing: https://pypi.org/project/shortbred\n",
      "ğŸ” Processing: https://cran.r-project.org/package=rando\n",
      "ğŸ” Processing: https://pypi.org/project/rts/\n",
      "ğŸ” Processing: https://cran.r-project.org/package=censusr\n",
      "ğŸ” Processing: https://cran.r-project.org/package=tetragon\n",
      "ğŸ” Processing: https://github.com/TongfeiLiu/C3Net-for-building-extraction\n",
      "ğŸ” Processing: https://github.com/xxcisxxc/SIMLR-python\n",
      "ğŸ” Processing: https://github.com/typesense/showcase-airbnb-geosearch\n",
      "ğŸ” Processing: https://github.com/mtliba/ATSal\n",
      "ğŸ” Processing: https://cran.r-project.org/package=languageserversetup\n",
      "ğŸ” Processing: https://cran.r-project.org/package=waspasR\n",
      "ğŸ” Processing: https://cran.r-project.org/package=bridgedist\n",
      "ğŸ” Processing: https://github.com/Edinburgh-Genome-Foundry/DnaChisel\n",
      "ğŸ” Processing: https://github.com/cran/mvSLOUCH\n",
      "ğŸ” Processing: https://github.com/li-valen/MicroPantry\n",
      "ğŸ” Processing: https://cran.r-project.org/web/packages/mvSLOUCH/index.html\n",
      "ğŸ” Processing: https://github.com/unity3d-jp/unitychan-crs\n",
      "ğŸ” Processing: https://cran.r-project.org/package=genomicper\n",
      "ğŸ” Processing: https://github.com/nolimits4web/atropos\n",
      "ğŸ” Processing: https://cran.r-project.org/package=rotatogram\n",
      "ğŸ” Processing: https://cran.r-project.org/package=crypto2\n",
      "ğŸ” Processing: https://cran.r-project.org/package=bayesWatch\n",
      "ğŸ” Processing: https://github.com/chrisroberts/vagabond\n",
      "ğŸ” Processing: https://github.com/briansmith/ring\n",
      "ğŸ” Processing: https://github.com/flipperdevices/qFlipper\n",
      "ğŸ” Processing: https://github.com/tum-pbs/pbdl-book\n",
      "ğŸ” Processing: https://cran.r-project.org/package=tau\n",
      "ğŸ” Processing: https://pypi.org/project/ring\n",
      "ğŸ” Processing: https://github.com/DLR-RM/rl-baselines3-zoo\n",
      "ğŸ” Processing: https://cran.r-project.org/package=clayringsmiletus\n",
      "ğŸ” Processing: https://github.com/EquiFox/KsDumper\n",
      "ğŸ” Processing: https://github.com/adria-repo/FrF2mix\n",
      "ğŸ” Processing: https://github.com/zmactep/ProtParam.jl\n",
      "ğŸ” Processing: https://github.com/thharter/GNLM\n",
      "ğŸ” Processing: https://cran.r-project.org/package=rdflib\n",
      "ğŸ” Processing: https://github.com/clearlinux-pkgs/R-prabclus\n",
      "ğŸ” Processing: https://cran.r-project.org/web/packages/table1/index.html\n",
      "ğŸ” Processing: https://cran.r-project.org/package=epiflows\n",
      "ğŸ” Processing: https://pypi.org/project/ri\n",
      "ğŸ” Processing: https://github.com/marvync/Survey-Analysis-Linker-Cronbach\n",
      "ğŸ” Processing: https://cran.r-project.org/package=gridExtra\n",
      "ğŸ” Processing: https://github.com/TheActuarialDataScientist/LOESS\n",
      "ğŸ” Processing: https://github.com/homfen/dataTables.treeGrid.js\n",
      "ğŸ” Processing: https://github.com/conda-forge/r-optimalcutpoints-feedstock\n",
      "ğŸ” Processing: https://cran.r-project.org/package=googleComputeEngineR\n",
      "ğŸ” Processing: https://github.com/tisztamo/Catwalk.jl\n",
      "Failed to extract metadata for https://github.com/tisztamo/Catwalk.jl: Command '['poetry', 'run', 'somef', 'describe', '-r', 'https://github.com/tisztamo/Catwalk.jl', '-o', 'C:\\\\Users\\\\Jelena\\\\AppData\\\\Local\\\\Temp\\\\tmp6ospbf1r.json', '-t', '0.93', '-m', '-kt', '\\\\\\\\?\\\\D:\\\\MASTER\\\\TMF\\\\somef\\\\temp']' returned non-zero exit status 1.\n",
      "ğŸ” Processing: https://cran.r-project.org/package=hms\n",
      "ğŸ” Processing: https://github.com/jwindle/BayesLogit\n",
      "ğŸ” Processing: https://github.com/Werneror/Poetry\n",
      "ğŸ” Processing: https://cran.r-project.org/package=SoyNAM\n",
      "ğŸ” Processing: https://cran.r-project.org/package=ciphertext\n",
      "ğŸ” Processing: https://github.com/pandaac/pandaac\n",
      "ğŸ” Processing: https://cran.r-project.org/package=brickset\n",
      "ğŸ” Processing: https://cran.r-project.org/package=sortable\n",
      "ğŸ” Processing: https://github.com/Project-MONAI/GenerativeModels\n",
      "Failed to extract metadata for https://github.com/Project-MONAI/GenerativeModels: Command '['poetry', 'run', 'somef', 'describe', '-r', 'https://github.com/Project-MONAI/GenerativeModels', '-o', 'C:\\\\Users\\\\Jelena\\\\AppData\\\\Local\\\\Temp\\\\tmphecutunl.json', '-t', '0.93', '-m', '-kt', '\\\\\\\\?\\\\D:\\\\MASTER\\\\TMF\\\\somef\\\\temp']' returned non-zero exit status 1.\n",
      "ğŸ” Processing: https://cran.r-project.org/package=parzer\n",
      "ğŸ” Processing: https://pypi.org/project/neurodocker\n",
      "ğŸ” Processing: https://github.com/kuanghuei/SCAN\n",
      "ğŸ” Processing: https://github.com/chokcoco/iCSS\n",
      "ğŸ” Processing: https://cran.r-project.org/web/packages/LS2W/index.html\n",
      "ğŸ” Processing: https://cran.r-project.org/web/packages/L0Learn/index.html\n",
      "ğŸ” Processing: https://cran.r-project.org/package=mapview\n",
      "ğŸ” Processing: https://github.com/Heavy-Division/B78XH\n",
      "ğŸ” Processing: https://github.com/unitedstates/contact-congress\n",
      "ğŸ” Processing: https://github.com/rock3125/sentence2vec\n",
      "ğŸ” Processing: https://github.com/MrBIMC/SELinuxModeChanger\n",
      "ğŸ” Processing: https://cran.r-project.org/package=NMVANOVA\n",
      "ğŸ” Processing: https://cran.r-project.org/package=amazons3R\n",
      "ğŸ” Processing: https://cran.r-project.org/package=pGPx\n",
      "ğŸ” Processing: https://github.com/sureJiang/MSRocketGiftAnimation\n",
      "ğŸ” Processing: https://cran.r-project.org/package=metap\n",
      "ğŸ” Processing: https://github.com/jerrylin0809/pac-bayesian-dendrogram-cut\n",
      "ğŸ” Processing: https://github.com/wmvanvliet/numpydoc-types\n",
      "ğŸ” Processing: https://github.com/rexrainbow/phaser3-rex-notes\n",
      "ğŸ” Processing: https://github.com/andrewhinh/admirer\n",
      "ğŸ” Processing: https://cran.r-project.org/package=minic\n",
      "ğŸ” Processing: https://github.com/dwinter/pafr\n",
      "ğŸ” Processing: https://pypi.org/project/gnomon/\n",
      "ğŸ” Processing: https://cran.r-project.org/package=oceCens\n",
      "ğŸ” Processing: https://cran.r-project.org/package=neuroimaGene\n",
      "ğŸ” Processing: https://cran.r-project.org/package=DiceView\n",
      "ğŸ” Processing: https://github.com/ropensci/textreuse\n",
      "ğŸ” Processing: https://cran.r-project.org/package=midoc\n",
      "ğŸ” Processing: https://cran.r-project.org/package=simET\n",
      "ğŸ” Processing: https://github.com/hongweipeng/GreenGrapes\n",
      "ğŸ” Processing: https://cran.r-project.org/package=Rpoet\n",
      "ğŸ” Processing: https://github.com/cran/classifierplots\n",
      "ğŸ” Processing: https://github.com/numpy/numpydoc\n",
      "ğŸ” Processing: https://cran.r-project.org/package=swa\n",
      "ğŸ” Processing: https://github.com/ErhardMenker/kMeans4EViews\n",
      "ğŸ” Processing: https://github.com/gd3kr/BlenderGPT\n",
      "ğŸ” Processing: https://cran.r-project.org/package=tabit\n",
      "ğŸ” Processing: https://cran.r-project.org/web/packages/cprobit/index.html\n",
      "ğŸ” Processing: https://cran.r-project.org/package=LPS\n",
      "ğŸ” Processing: https://github.com/getmaxun/maxun\n",
      "ğŸ” Processing: https://github.com/hajimehoshi/ebiten\n",
      "ğŸ” Processing: https://cran.r-project.org/package=GUIProfiler\n",
      "ğŸ” Processing: https://cran.r-project.org/package=SimVitD\n",
      "ğŸ” Processing: https://github.com/gpiozero/gpiozero\n",
      "ğŸ” Processing: https://github.com/Hamza-Rashed/OnlineExaminer\n",
      "ğŸ” Processing: https://github.com/nevyn/SPAsync\n",
      "ğŸ” Processing: https://cran.r-project.org/package=msce\n",
      "ğŸ” Processing: https://cran.r-project.org/package=minimap\n",
      "ğŸ” Processing: https://cran.r-project.org/package=Markovchart\n",
      "ğŸ” Processing: https://github.com/viiri/fmdrv\n",
      "ğŸ” Processing: https://github.com/codeschool/WatchUsBuild-ImageStreamingAppWithNodePubSubServer\n",
      "ğŸ” Processing: https://github.com/CNFeffery/awesome-feffery-dash\n",
      "ğŸ” Processing: https://github.com/iMammal/KerasBinaryClassifierplots\n",
      "ğŸ” Processing: https://github.com/OktaSecurityLabs/sgt\n",
      "ğŸ” Processing: https://github.com/login-securite/lsassy\n",
      "ğŸ” Processing: https://cran.r-project.org/package=imagerExtra\n",
      "ğŸ” Processing: https://github.com/SilviaMessana/HW3_CMLS\n",
      "ğŸ” Processing: https://github.com/oakes/iglu\n",
      "ğŸ” Processing: https://cran.r-project.org/web/packages/BASS/index.html\n",
      "ğŸ” Processing: https://cran.r-project.org/package=oai\n",
      "ğŸ” Processing: https://github.com/Tyrrrz/DiscordChatExporter\n",
      "ğŸ” Processing: https://github.com/minio/minio\n",
      "ğŸ” Processing: https://github.com/poteto/hiring-without-whiteboards\n",
      "ğŸ” Processing: https://cran.r-project.org/package=airship\n",
      "ğŸ” Processing: https://cran.r-project.org/package=languagelayeR\n",
      "ğŸ” Processing: https://github.com/andersroos/glo\n",
      "ğŸ” Processing: https://github.com/pld-linux/clusterit\n",
      "ğŸ” Processing: https://github.com/cran2367/sgt\n",
      "ğŸ” Processing: https://cran.r-project.org/web/packages/ICS/index.html\n",
      "ğŸ” Processing: https://github.com/ryanbgriffiths/ICRA2024PaperList\n",
      "ğŸ” Processing: https://cran.r-project.org/package=fingerprint\n",
      "ğŸ” Processing: https://github.com/EmbarkStudios/rust-ecosystem\n",
      "ğŸ” Processing: https://cran.r-project.org/package=crso\n",
      "ğŸ” Processing: https://github.com/DeepakumarSubbian/Deepview\n",
      "ğŸ” Processing: https://github.com/Ccantey/GeoSearch-Tweepy\n",
      "ğŸ” Processing: https://github.com/nunesmatt/LS2Wstat\n",
      "ğŸ” Processing: https://cran.r-project.org/package=SAME\n",
      "ğŸ” Processing: https://github.com/processing/processing\n",
      "ğŸ” Processing: https://cran.r-project.org/package=factset.analyticsapi.engines\n",
      "ğŸ” Processing: https://github.com/HKUST-Aerial-Robotics/VINS-Fusion\n",
      "Failed to extract metadata for https://github.com/HKUST-Aerial-Robotics/VINS-Fusion: Command '['poetry', 'run', 'somef', 'describe', '-r', 'https://github.com/HKUST-Aerial-Robotics/VINS-Fusion', '-o', 'C:\\\\Users\\\\Jelena\\\\AppData\\\\Local\\\\Temp\\\\tmp9413uxe4.json', '-t', '0.93', '-m', '-kt', '\\\\\\\\?\\\\D:\\\\MASTER\\\\TMF\\\\somef\\\\temp']' returned non-zero exit status 1.\n",
      "ğŸ” Processing: https://github.com/SchmollerLab/Cell_ACDC\n",
      "ğŸ” Processing: https://github.com/aaugustin/django-sesame\n",
      "ğŸ” Processing: https://github.com/jacobwindsor/MetabMaster\n",
      "ğŸ” Processing: https://github.com/BrewPi/firmware\n",
      "Failed to extract metadata for https://github.com/BrewPi/firmware: Command '['poetry', 'run', 'somef', 'describe', '-r', 'https://github.com/BrewPi/firmware', '-o', 'C:\\\\Users\\\\Jelena\\\\AppData\\\\Local\\\\Temp\\\\tmpbw2_pqtl.json', '-t', '0.93', '-m', '-kt', '\\\\\\\\?\\\\D:\\\\MASTER\\\\TMF\\\\somef\\\\temp']' returned non-zero exit status 1.\n",
      "ğŸ” Processing: https://github.com/crock/myLoop-client\n",
      "ğŸ” Processing: https://github.com/mxber2022/MetaPredict\n",
      "ğŸ” Processing: https://cran.r-project.org/package=RDS\n",
      "ğŸ” Processing: https://github.com/modxcms/revolution\n",
      "ğŸ” Processing: https://cran.r-project.org/package=OceanView\n",
      "ğŸ” Processing: https://pypi.org/project/windows/\n",
      "ğŸ” Processing: https://github.com/stan-dev/rstanarm\n",
      "ğŸ” Processing: https://github.com/Rican7/define\n",
      "ğŸ” Processing: https://pypi.org/project/DAMN\n",
      "ğŸ” Processing: https://github.com/layumi/Person_reID_baseline_pytorch\n",
      "ğŸ” Processing: https://github.com/ConnorAGeis/FRF2023\n",
      "ğŸ” Processing: https://github.com/afilazzola/CommEcolFunctions\n",
      "ğŸ” Processing: https://cran.r-project.org/web/packages/pafr/index.html\n",
      "ğŸ” Processing: https://github.com/charmbracelet/glow\n",
      "ğŸ” Processing: https://github.com/VictorTaelin/UrnaCripto\n",
      "ğŸ” Processing: https://github.com/JudasDie/Comparison\n",
      "ğŸ” Processing: https://github.com/yomajkel/ImageStream\n",
      "ğŸ” Processing: https://github.com/adereth/dactyl-keyboard\n",
      "ğŸ” Processing: https://cran.r-project.org/package=backports\n",
      "ğŸ” Processing: https://github.com/xiaolai/most-common-american-idioms\n",
      "ğŸ” Processing: https://github.com/GerardWalace/BVSE\n",
      "ğŸ” Processing: https://cran.r-project.org/package=CLME\n",
      "ğŸ” Processing: https://pypi.org/project/AFEM\n",
      "ğŸ” Processing: https://github.com/paulfitz/mlsql\n",
      "ğŸ” Processing: https://github.com/yehux/Coot\n",
      "ğŸ” Processing: https://cran.r-project.org/package=DatabaseConnector\n",
      "ğŸ” Processing: https://cran.r-project.org/package=languageR\n",
      "ğŸ” Processing: https://cran.r-project.org/package=dbhydroR\n",
      "ğŸ” Processing: https://github.com/Findeton/deepview\n",
      "ğŸ” Processing: https://cran.r-project.org/package=holobiont\n",
      "ğŸ” Processing: https://github.com/uctoronto/SHAN\n",
      "ğŸ” Processing: https://cran.r-project.org/package=newsmd\n",
      "ğŸ” Processing: https://github.com/chris4540/StudyMaskedLMForQG\n",
      "ğŸ” Processing: https://github.com/french-paragon/BayesianNeuralNetwork-Tutorial-Metarepos\n",
      "ğŸ” Processing: https://cran.r-project.org/package=AzureStor\n",
      "ğŸ” Processing: https://cran.r-project.org/package=rNeighborQTL\n",
      "ğŸ” Processing: https://cran.r-project.org/package=EviewsR\n",
      "ğŸ” Processing: https://cran.r-project.org/package=designit\n",
      "ğŸ” Processing: https://github.com/UTokyoMDcenter/MatchingMarkets\n",
      "ğŸ” Processing: https://github.com/fdb/frequensea\n",
      "ğŸ” Processing: http://github.com/davisagli/eye\n",
      "ğŸ” Processing: https://cran.r-project.org/package=GPoM\n",
      "ğŸ” Processing: https://cran.r-project.org/package=cito\n",
      "ğŸ” Processing: https://github.com/InlineTwin/Repetier-Host\n",
      "ğŸ” Processing: https://cran.r-project.org/package=kendallRandomWalks\n",
      "ğŸ” Processing: https://cran.r-project.org/package=DALSM\n",
      "ğŸ” Processing: https://cran.r-project.org/package=TESS\n",
      "ğŸ” Processing: https://cran.r-project.org/web/packages/HI/index.html\n",
      "ğŸ” Processing: https://cran.r-project.org/web/packages/ExpDes/index.html\n",
      "ğŸ” Processing: https://cran.r-project.org/package=NAEPirtparams\n",
      "ğŸ” Processing: https://github.com/alexdrone/Render\n",
      "ğŸ” Processing: https://github.com/PKU-Alignment/align-anything\n",
      "ğŸ” Processing: https://github.com/Flowseal/zapret-discord-youtube\n",
      "ğŸ” Processing: https://pypi.org/project/adcc\n",
      "ğŸ” Processing: https://cran.r-project.org/package=RGIFT\n",
      "ğŸ” Processing: https://cran.r-project.org/package=c3net\n",
      "ğŸ” Processing: https://cran.r-project.org/package=drord\n",
      "ğŸ” Processing: https://github.com/cran/micropan\n",
      "ğŸ” Processing: https://github.com/WCRP-CORDEX/simulation-status\n",
      "ğŸ” Processing: https://cran.r-project.org/package=IMD\n",
      "ğŸ” Processing: https://cran.r-project.org/package=micropan\n",
      "ğŸ” Processing: https://cran.r-project.org/package=BiSEp\n",
      "ğŸ” Processing: https://github.com/adam-katona/evolvability_map_elites\n",
      "ğŸ” Processing: https://cran.r-project.org/package=KSD\n",
      "ğŸ” Processing: https://github.com/milk-org/ImageStreamIO\n",
      "ğŸ” Processing: https://cran.r-project.org/package=tablesgg\n",
      "ğŸ” Processing: https://pypi.org/project/hi/\n",
      "ğŸ” Processing: https://cran.r-project.org/package=PGEE\n",
      "ğŸ” Processing: https://cran.r-project.org/package=Cronbach\n",
      "ğŸ” Processing: https://github.com/Zeruel87/Cameo-mod\n",
      "ğŸ” Processing: https://github.com/kassambara/factoextra\n",
      "ğŸ” Processing: https://github.com/Textualize/rich\n",
      "ğŸ” Processing: https://github.com/hyhbdu/repo-cmls2uqe\n",
      "ğŸ” Processing: https://cran.r-project.org/package=bvpa\n",
      "ğŸ” Processing: https://pypi.org/project/jetpack/\n",
      "ğŸ” Processing: https://github.com/Popmotion/popmotion\n",
      "Failed to extract metadata for https://github.com/Popmotion/popmotion: Command '['poetry', 'run', 'somef', 'describe', '-r', 'https://github.com/Popmotion/popmotion', '-o', 'C:\\\\Users\\\\Jelena\\\\AppData\\\\Local\\\\Temp\\\\tmpwsiny06u.json', '-t', '0.93', '-m', '-kt', '\\\\\\\\?\\\\D:\\\\MASTER\\\\TMF\\\\somef\\\\temp']' returned non-zero exit status 1.\n",
      "ğŸ” Processing: https://github.com/ElofssonLab/TOPCONS2\n",
      "ğŸ” Processing: https://cran.r-project.org/package=acfMPeriod\n",
      "ğŸ” Processing: https://github.com/sunshowers-code/lifetime-variance\n",
      "ğŸ” Processing: https://cran.r-project.org/package=fma\n",
      "ğŸ” Processing: https://github.com/larssnip/micropan\n",
      "ğŸ” Processing: https://github.com/sean-mccorkle/GenomeViewR\n",
      "ğŸ” Processing: https://github.com/dalance/procs\n",
      "ğŸ” Processing: https://github.com/Mohan-Zhang-u/PenSimPy\n",
      "ğŸ” Processing: https://github.com/d3/d3\n",
      "ğŸ” Processing: https://cran.r-project.org/package=Information\n",
      "ğŸ” Processing: https://cran.r-project.org/package=SPCAvRP\n",
      "ğŸ” Processing: https://github.com/sickcodes/Docker-OSX\n"
     ]
    }
   ],
   "source": [
    "input_dataframe = pd.read_csv(output_file_corpus)\n",
    "metadata_cache = dictionary_with_candidate_metadata(input_dataframe, metadata_cache_file, somef_path)\n",
    "input_dataframe= make_pairs(input_dataframe,output_path_pairs)\n",
    "\n",
    "add_metadata(input_dataframe,metadata_cache, output_path_updated_with_metadata)\n",
    "input_dataframe= compute_similarity_test(input_dataframe,output_path_similarities)\n",
    "\n",
    "model_input = input_dataframe[['name_metric', 'paragraph_metric','language_metric','synonym_metric','author_metric']].copy()\n",
    "model_input.to_csv(model_input_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4061868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading model\n",
    "with open(model_path, \"rb\") as f:\n",
    "    model = cloudpickle.load(f)\n",
    "predictions = model.predict(model_input)\n",
    "# Add predictions to the input DataFrame``\n",
    "input_dataframe['prediction'] = predictions\n",
    "# Save the final DataFrame with predictions to a new CSV file\n",
    "if output_path_similarities is not None:\n",
    "    input_dataframe.to_csv(output_path_similarities, index=False)\n",
    "grouped = input_dataframe.groupby(['name', 'paragraph', 'doi']).apply(aggregate_group).reset_index()\n",
    "grouped.to_csv(output_path_aggregated_groups, index=False)\n",
    "print(\"Processing complete. Output files generated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
