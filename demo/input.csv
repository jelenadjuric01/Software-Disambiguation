name;candidate_urls;doi;paragraph
BioMark;https://cran.r-project.org/web/packages/BioMark/index.html;10.1186/1471-2164-13-521;Genotype calling was carried out using the SDS 2.3 software (Life Technologies, Carlsbad California) or the BioMark 3.0.2 software (Fluidigm, South San Francisco, California)
BioMark;https://cran.r-project.org/web/packages/BioMark/index.html;10.1534/g3.115.020222;Genotypes were called using the BioMark software v3.0.2 (Fluidigm, South San Francisco, CA)
BioMark;https://cran.r-project.org/web/packages/BioMark/index.html;10.1371/journal.pone.0001662;Data was analyzed using the BioMark digital array software and the numbers of positive chambers were corrected to estimate the true number of copies [32]
BioMark;https://cran.r-project.org/web/packages/BioMark/index.html;10.1186/s12862-017-1109-6;"Data from the gene expression analysis were processed using the Fluidigm-integrated software (Fluidigm Real-Time PCR analysis; BioMark Version 4.1.2)"
BioMark;https://cran.r-project.org/web/packages/BioMark/index.html;10.3390/ijms17030402;The BioMark software (Fluidigm, South San Francisco, CA, USA) can generate PCR amplification curves and analyze the threshold values of the 36,960 individual partitions (48 × 770)
Factoshiny;https://cran.r-project.org/web/packages/Factoshiny/index.html;10.7717/peerj.12031;The PCA was performed in R version 4.0.3 with the function “PCAshiny” in the “Factoshiny” package (Vaissie, Monge & Husson, 2021)
Factoshiny;https://cran.r-project.org/web/packages/Factoshiny/index.html;10.1038/s41598-021-98634-0;Factoshiny software package running within RStudio was used for HCPC analysis
Factoshiny;https://cran.r-project.org/web/packages/Factoshiny/index.html;10.1186/s12864-021-07902-w;The FactoMineR [158] R package was used to perform the analysis and Factoshiny [159] was used to generate PCA plots.
Factoshiny;https://cran.r-project.org/web/packages/Factoshiny/index.html;10.1186/s12866-019-1678-1;PCA was used to identify correlations among the strains using the genetic information and data from the isolation sources generated in the current study and the FactoMineR and Factoshiny packages (version 1.42) in R (version 3.5.2) software (https://cran.r-project.org/)
Factoshiny;https://cran.r-project.org/web/packages/Factoshiny/index.html;10.3389/fnut.2021.592340;Factoshiny package running within RStudio platform was used for HCPC (48, 49).
vhica;https://cran.r-project.org/web/packages/vhica/index.html;10.6026/97320630017479;"""The ENC values of the S, M, L segments of the CCHF virus were calculated in R Studio programming software, """"vhica"""" library [13]"""
HH;https://cran.r-project.org/web/packages/HH/index.html;10.1371/journal.pone.0186285;Statements evaluated with a forced Likert scale were plotted using package “HH” [23] in the open-source software program R [24].
HH;https://cran.r-project.org/web/packages/HH/index.html;10.1093/aobpla/ply009;"Covariates were then checked for multicolinearity using the variance inflation factor (function ‘vif’ in package ‘HH’; Heiberg 2016)"
HH;https://cran.r-project.org/web/packages/HH/index.html;10.1186/s12859-019-3019-7;To keep HH-suite sustainable and expandable in the longer term, we extensively refactored code by improving code reuse with the help of new classes with inheritance, replacing POSIX threads (pthreads) with OpenMP parallelization, removing global variables, moving from make to cmake, and moving the HH-suite project to GitHub (https://github.com/soedinglab/hh-suite)
HH;https://cran.r-project.org/web/packages/HH/index.html;10.5334/aogh.2809;For the Training Needs Assessment (TNA), a parametric T-test, using GraphPad, was employed to explore the statistically significant difference between score A (importance of activity to job) and score B (ability of respondent to perform the activity), as recommended by the HH tool authors [1718]
HH;https://cran.r-project.org/web/packages/HH/index.html;10.3390/s16060804;Then, based on the location coordinates, network connectivity scheme and deployment methodology, the installation and configuration process is assisted by means of the CMT-HH, while the operational release is finally verified by the CMT web application, which registers and presents the output models of the in-field commissioning activities for further system optimization and feedback analysis.
locfit;https://cran.r-project.org/web/packages/locfit/index.html;10.1371/journal.pone.0075029;Parameters’ posterior distributions were estimated using a local linear regression method [58] and plotted in R using the package locfit [59]
locfit;https://cran.r-project.org/web/packages/locfit/index.html;10.1093/aje/kwy114;We directly estimated seroprevalence according to age from the IgG serological data using a nonparametric model with local polynomial estimators, given its flexibility in allowing nonmonotonicity (“locfit” library (26) in R (R Foundation for Statistical Computing, Vienna, Austria)) (16) (see Web Appendix 1, Web Figure 1, available at https://academic.oup.com/aje for details)
locfit;https://cran.r-project.org/web/packages/locfit/index.html;10.1038/s41598-020-77162-3;We interpolated locfit output using interp1.m function and applied z-score normalization to get the normalized density per cortical state per second
locfit;https://cran.r-project.org/web/packages/locfit/index.html;10.1002/jrsm.1185;As there is some variability due to the random sampling, we used the R (R Core Team, 2012) package locfit (Loader, 2012) to smoothly estimate the mean
locfit;https://cran.r-project.org/web/packages/locfit/index.html;10.18632/aging.102925;"Statistical analyses were performed using R (Version 3.5.1, R Core Team 2018 [88]; locfit package version 1.5-9.1 [89]; ggplot2 package [90] for visualizations) with α set to 0.05."
varSel;https://cran.r-project.org/web/packages/varSel/index.html;10.1002/ece3.6786;Whereas these methods aim at identifying the best subset of the available variables, our implementations address different problems: varSel removes variables to reduce collinearity, and reduceVar removes variables that contribute least to the model to increase parsimony
mvmeta;https://cran.r-project.org/web/packages/mvmeta/index.html;10.1016/j.mex.2020.100834;Stata code for fitting the model is presented in the Appendix using mvmeta which performs inferences based on either Maximum Likelihood (ML9), the Restricted Maximum Likelihood (REML10) or the multivariate method of moments (MM11), which is the method of choice due to its non-iterative nature [12].
mvmeta;https://cran.r-project.org/web/packages/mvmeta/index.html;10.7717/peerj.1461;"The network meta-analysis was conducted using STATA network package and mvmeta (Higgins et al., 2012; White, 2011) (The STATA .do file for HbA1 is presented in Supplementary Document—Statistical Analyses)"
mvmeta;https://cran.r-project.org/web/packages/mvmeta/index.html;10.1371/journal.pone.0243865;"A random-effects NMA based on a frequentist framework was performed using STATA software (version 15; StataCorp LP, College Station, TX) based on mvmeta with NMA graphical tools developed by Chaimani and colleagues [26]."
mvmeta;https://cran.r-project.org/web/packages/mvmeta/index.html;10.1186/s12872-019-1165-5;Network meta-analysis was conducted using the mvmeta software package in STATA14 software
mvmeta;https://cran.r-project.org/web/packages/mvmeta/index.html;10.1371/journal.pmed.1002617;All statistical analyses were performed with R software (version 3.4.3) using functions from the packages dlnm (first-stage regression) and mvmeta (second-stage meta-analysis).
speedglm;https://cran.r-project.org/web/packages/speedglm/index.html;10.1093/eurpub/ckx090;Analyses were done with R (version 3.0.2) and using the speedglm package.
speedglm;https://cran.r-project.org/web/packages/speedglm/index.html;10.1001/jamanetworkopen.2021.5723;"Statistical analysis was performed using R software, version 3.5.0 (R Foundation for Statistical Computing) with the analysis packages epade, version 0.3.8; forestplot, version 1.7.2; rms, version 5.1-2; ggplot2, version 3.1.0; reshape2, version 1.4.3; and speedglm, version 0.3-2"
thief;https://cran.r-project.org/web/packages/thief/index.html,https://github.com/robjhyndman/thief;10.1001/jamanetworkopen.2020.37227;All statistical analyses were performed with R Studio version 1.3.1073 and R versions 4.0.2 and 4.0.3 (R Project for Statistical Computing) with the following packages: Metrics, forecastHybrid, thief, forecast, cowplot, lubridate, forcats, stringr, dplyr, purrr, readr, tidyr, tibble, ggplot2, and tidyverse
chngpt;https://cran.r-project.org/web/packages/chngpt/index.html;10.1186/s12859-017-1863-x;chngpt is an open source software and can be downloaded from the Comprehensive R Archive Network
chngpt;https://cran.r-project.org/web/packages/chngpt/index.html;10.3389/fpls.2020.00636;Linear and intercept-only (null) models were fit with the lm function and step and hinge functions were fit with the chngpt package (Fong et al., 2017)
chngpt;https://cran.r-project.org/web/packages/chngpt/index.html;10.1007/s11357-020-00205-0;All analyses were conducted in STATA 16.0 (StataCorp 2019), and double-checked in R (R Core Team R 2017) using packages chngpt (Fong et al
chngpt;https://cran.r-project.org/web/packages/chngpt/index.html;10.1186/s12859-017-1863-x;"Our chngpt package complements the segmented package by making three unique contributions: (1) it supports all four types of threshold effects in Fig. 1, and supports models with interaction terms between predictors subjected to thresholding and predictors not subjected to thresholding [10]; (2) the search method in segmented employs a first order approximation of the non-smooth criterion function [11], while chngpt offers two alternative search methods: exact, which optimizes the exact criterion function, "
chngpt;https://cran.r-project.org/web/packages/chngpt/index.html;10.1186/s12859-017-1863-x;A second example illustrating the use of chngpt for fitting thresholded linear regression models can be found in the Additional file 1: Section B.
ESEfinder;https://github.com/MahyarHosseini/ESEfinder;10.1186/1756-0500-1-86;ESEfinder 3.0 [21] was used to scan the genomic region containing SNPs found only among affected individuals in the screening panel for the identification of splice enhancer binding sites in the wildtype sequence
ESEfinder;https://github.com/MahyarHosseini/ESEfinder;10.1242/dmm.036616;The c.1226 A>G mutation, with its flanking sequences, was predicted as a potential ESE motif using ESEfinder software, and the motif sequence carrying the mutant G allele presented a higher weighted majority vote (WMV) score than that carrying the A allele (3.19 versus 2.82), suggesting that the G allele potentially increased binding affinity for SRSF2 (a member of the family of pre-mRNA splicing factors) and contributed to a high incidence of alternative splicing (AS)
ESEfinder;https://github.com/MahyarHosseini/ESEfinder;10.1186/1471-2164-9-265;ESEfinder uses a position specific weight matrix
ESEfinder;https://github.com/MahyarHosseini/ESEfinder;10.1038/tp.2015.154;An in silico structural analysis of exon 3b of the human DLG1 gene using ESEfinder, FAS-ESS, and RESQUE-ESS indicated the presence of an exonic splicing enhancer (ESE) consensus (TGAAAGAAT) in exon 3b (Figure 4)
ESEfinder;https://github.com/MahyarHosseini/ESEfinder;10.1371/journal.pgen.1003058;ESEfinder 3.0 [34]was used to identify putative splicing factor binding motifs disrupted by rs11716445.
GenStat;https://github.com/richardtjornhammar/GenStat;10.3389/fpls.2018.00011;A simple linear regression with groups was performed using GenStat-12 software (VSN International Ltd., Cambridge, England)
GenStat;https://github.com/richardtjornhammar/GenStat;10.1093/jxb/ery170;ANOVA was carried out on all parameters at each growth stage using GenStat for Windows, 17th Edition (VSN International Ltd)
GenStat;https://github.com/richardtjornhammar/GenStat;10.3390/foods10010096;Separate linear mixed models were fitted by restricted maximum likelihood for liking, premiumness and frequency of consumption data using GenStat for Windows 16th Edition, (VSN International Hemel Hempstead, UK)
GenStat;https://github.com/richardtjornhammar/GenStat;10.7717/peerj.7527;Data were analysed statistically using GenStat 12.1 (VSN International Ltd, Hemel Hempstead, Hertforshire, UK)
GenStat;https://github.com/richardtjornhammar/GenStat;10.1186/s12917-017-1169-2;Data were analysed with the statistical software GenStat 16.1 (VSN International, Hemel Hempstead, UK), using two sample t-tests and logistic regression
SAM;https://github.com/s-macke/SAM;10.1186/1471-2105-7-399;The accuracies of models using S2N or SAM (77.7%) were the second highest
SAM;https://github.com/s-macke/SAM;10.15252/msb.156172;The orientation of the joins was obtained from the sequence arrangement in the paired-end libraries manifested in the SAM file bitwise FLAG
SAM;https://github.com/s-macke/SAM;10.1038/s41598-020-60595-1;We set the cutoffs of FDR of the SAM and limma to 0.05 and 0.01, respectively.
SAM;https://github.com/s-macke/SAM;10.1007/s40520-020-01646-5;Differentially expressed mRNAs were identified by ANOVA and by Significance analysis of microarrays (SAM)
SAM;https://github.com/s-macke/SAM;10.1371/journal.pone.0012362;Utilizing the expression data from these five cases, we identified 2674 mRNAs that were significantly dysregulated in ULMs (SAM, FDR<5%, Figure 1A)
SPC;https://github.com/Tcat1024/SPC;10.1002/acm2.12993;Treatment review with the guidance of a SPC tool allows for an objective and consistent clinical decision to apply adaptive radiotherapy.
SPC;https://github.com/Tcat1024/SPC;10.1136/bmjqs-2018-009048;Control charts are the main analytical tool used in SPC.18 A control chart shows a time series of how the measure varies over time
SPC;https://github.com/Tcat1024/SPC;10.3390/ijms22031320;Sparse principal component analysis (sPCA) was performed on the Log2 (fold change) values using SPC from the PMA package in R
SPC;https://github.com/Tcat1024/SPC;10.3389/fnsys.2014.00006;"As well as comparing SPC (Blatt et al., 1996; Quiroga et al., 2004) with GAC on surrogate data (section Tests with Surrogate Data, Table 4) we tested it on our own data but found that it frequently was unable to separate distributions that were connected by narrow bridges of low density"
SPC;https://github.com/Tcat1024/SPC;10.1208/s12248-019-0354-6;When σ is unknown, SPC software will, by default, estimate sigma by where is the average observed moving range and 2/ √ (π) is the expected value for the range between two values from a standard Normal Distribution
Simulator;https://github.com/illidanlab/Simulator;10.1186/1471-2334-11-37;For this reason the simulation scenario that we study in this application of the Simulator does not aim to realistically reproduce the timing of the spreading pattern of the 2009 H1N1 pandemic
Simulator;https://github.com/illidanlab/Simulator;10.1186/1471-2474-10-8;The THR Simulator can incorporate several parameters for analysis at the same time
Simulator;https://github.com/illidanlab/Simulator;10.3389/fnhum.2019.00417;"The selected VR games which met the above software criteria were: (1) “Job Simulator” (Session 1); (2) “The Lab” (Session 2); and (3) “Rick and Morty: Virtual Rick-ality” (Session 3)"
Simulator;https://github.com/illidanlab/Simulator;10.3390/brainsci9100261;Therapeutic Equine Simulator System (TESS, Racewood Ltd., Tarporley, UK) is a horse simulator, custom made for Equiphoria (Figure 1a,b), which includes the biomechanical characteristics of five of Equiphoria’s horses dedicated to physical therapy
Simulator;https://github.com/illidanlab/Simulator;10.3389/fmicb.2021.631244;The remaining coral fragments were maintained in 9 outdoor flow-through holding tanks in the Red Sea Simulator (Bellworthy and Fine, 2018) until the 15N2 incubation experiments (described below) on the following day
HFSS;https://github.com/LyingCortex/HFSS;10.3390/mi12040453;The coplanar waveguide (CPW)-fed antenna was designed using ANSYS high-frequency structural simulator (HFSS), which operates at 3.04–10.70 GHz and 15.18–18 GHz (upper K u band) with a return loss < −10 dB and a VSWR < 2
HFSS;https://github.com/LyingCortex/HFSS;10.3390/ijerph17197231;Case studies and brand testimonials indicate that these novel techniques are widely employed by HFSS products and brands.
HFSS;https://github.com/LyingCortex/HFSS;10.3390/s20216142;In simulations, both focusing lenses with 3D unit cell structures were implemented in HFSS and the focusing gain was calculated
HFSS;https://github.com/LyingCortex/HFSS;10.3390/s19143134;The simulations conducted with HFSS to obtain such results required using εr = 22, tanδ = 0.001 and h = 0.04 mm thickness
HFSS;https://github.com/LyingCortex/HFSS;10.1038/s41598-020-69547-1;In this simulations, ten layers with the same thickness of 1 mm above the tag have been tested with the same permittivity as the air and only the permittivity of one of them has been changed to 2 at each step determined by layer number in parts (d) and (e) [images in parts (a), (b), and (c) are obtained from HFSS]
catwalk;https://github.com/qlik-oss/catwalk;10.1021/acschemneuro.0c00794;In the catwalk analyses, a small number of postprocedure changes were observed, but these were not consistent
catwalk;https://github.com/qlik-oss/catwalk;10.1371/journal.pone.0068584;Gait performance was assessed and recorded using the catwalk analysis software
catwalk;https://github.com/qlik-oss/catwalk;10.1371/journal.pone.0023244;Effects on rotarod performance are assessed between days 35 to 60, analysis of hind-limb muscle volume and immunohistochemistry to assess the degree of gastrocnemius innervation at day 60 in half of the cohort and the remaining cohort being assessed for motor function using the catwalk gait analysis system and for time to onset
catwalk;https://github.com/qlik-oss/catwalk;10.1016/j.freeradbiomed.2013.04.018;The catwalk gait analysis system (Noldus Instruments, version 7.1) was used to capture gait parameters in groups of 5 G93A—transgenic mice and 7 nontransgenic mice
catwalk;https://github.com/qlik-oss/catwalk;10.1371/journal.pone.0023244;4/ Assess the remaining 7 mice per group, 3 times per week for onset of clinical signs from 60 days of age to day 90 (if necessary) and gait analysis using the catwalk gait analysis system at 63, 77 and 91 days of age (9, 11, and 13 weeks)
MATLAB;https://github.com/aludnam/MATLAB;10.1371/journal.pone.0158375;Figure created by the authors using prefecture boundary data from [18] and MATLAB software.
MATLAB;https://github.com/aludnam/MATLAB;10.1038/srep11531;"Amplified waveforms were averaged in EEGLAB 6.0 (MATLAB toolbox, EEGLAB 6.0) by filtering the data with a digital finite impulse response filter (band-pass with 1–50 Hz); 180 epochs were averaged with a 1000 ms epoch and a 100 ms pre-epoch per f-VEP"
MATLAB;https://github.com/aludnam/MATLAB;10.1128/JVI.02190-20;The statistical significance of the overlap between both methods was evaluated on MATLAB by running simulations of randomly distributed elements in both groups
MATLAB;https://github.com/aludnam/MATLAB;10.1038/s41598-018-31591-3;MATLAB (The MathWorks, Natick, MA) functions then were used to extract the 3D volume corresponding to the positioned MRS voxel to obtain within-voxel gray matter (GM), white matter (WM) and cerebrospinal fluid (CSF) tissue content for each subject
MATLAB;https://github.com/aludnam/MATLAB;10.1038/s41598-021-83398-4;Experimental data were modeled in MATLAB (The MathWorks) using a modified version of the Korhonen model of neonatal rat ventricular CMs (see Fig. 5, expanded methods, Supplementary Fig. 11 and Supplementary Tables 2–7 for model details)
Aliquot;https://github.com/MatthewJohnMorris/Aliquot;10.1371/journal.pone.0234676;Aliquot and timespan interact with FxD separately, with the exception of the 4-way interaction for the non-Prime females
Aliquot;https://github.com/MatthewJohnMorris/Aliquot;10.1371/journal.pgen.1005308;Aliquot for zero time point was taken
Aliquot;https://github.com/MatthewJohnMorris/Aliquot;10.1007/s00266-020-01762-7; Aliquot
Aliquot;https://github.com/MatthewJohnMorris/Aliquot;10.1128/JCM.01611-19;Aliquot 5 was kept as a backup aliquot for any repeat runs resulting from invalid results and also for running a subset of the samples on the early callout mode on the ID Now platform
Aliquot;https://github.com/MatthewJohnMorris/Aliquot;10.3791/820;Aliquot prep: 
Jenga;https://github.com/CatsFromMars/Jenga;10.2196/resprot.4189;Subjects assigned to the control group will be invited to practise a variety of psychosocial activities including a range of table games (eg, Chinese checkers, Jenga, board games etc)
Jenga;https://github.com/CatsFromMars/Jenga;10.1186/s11556-018-0199-5;Jenga is a physical and mental skill game that players take turns removing one block at a time from at any level of a tower constructed of 54 wooden blocks, and then place the block removed on the topmost of the tower
Jenga;https://github.com/CatsFromMars/Jenga;10.3389/fnbot.2018.00086;The dataset contains 48 first-person videos of people performing four types of activities (playing cards, playing chess, solving a puzzle, and playing Jenga) Figure 10
Jenga;https://github.com/CatsFromMars/Jenga;10.1371/journal.pcbi.1007210;judging the stability of towers of blocks, as in the game Jenga), and ask whether people can also make systematic and accurate predictions about flowing and splashing liquids, such as water or honey
Jenga;https://github.com/CatsFromMars/Jenga;10.1021/acsnano.1c01882;Much like the shape of building blocks would affect the disassembly of a tower, as in the board game Jenga, the shape and valency of the capsid building blocks (capsomers) affect the assembly and disassembly behavior of the virus
Axe;https://pypi.org/project/Axe,https://github.com/soasme/axe;10.1186/s12859-021-04267-5;Axe uses a set of pre-computed prefix trees to find a match within a given Hamming distance and can partially handle barcodes that differ in length
Axe;https://pypi.org/project/Axe,https://github.com/soasme/axe;10.1186/s12870-018-1575-z;Raw reads were assigned to individual samples in accordance with their nucleotide barcode, using Axe package [60]
Axe;https://pypi.org/project/Axe,https://github.com/soasme/axe;10.7717/peerj.7170;"Popular tools include FASTX-Toolkit (Gordon & Hannon, 2010), Axe (Murray & Borevitz, 2018), Flexbar (Dodt et al., 2012; Roehr, Dieterich & Reinert, 2017), Cutadapt (Martin, 2011), and AdapterRemoval (Lindgreen, 2012; Schubert, Lindgreen & Orlando, 2016), Trimmomatic (Bolger, Lohse & Usadel, 2014), Skewer (Jiang et al., 2014), and GBSX (Herten et al., 2015)"
Axe;https://pypi.org/project/Axe,https://github.com/soasme/axe;10.3390/genes10010009;Paired-end reads were demultiplexed and barcodes were trimmed using Axe [79] with a maximum mismatch of 1
ecopy;https://pypi.org/project/ecopy,https://github.com/Auerilas/ecopy;10.1186/s12915-020-00804-5;We then used this information to generate a Bray-Curtis distance matrix using the ecopy package in Python
ecopy;https://pypi.org/project/ecopy,https://github.com/Auerilas/ecopy;10.1002/ece3.7299;The abundances were square‐root transformed (to match the transformation of the abundance matrix used in the Bray–Curtis calculation), and the analysis was conducted in Python using ecopy's simper function.
ecopy;https://pypi.org/project/ecopy,https://github.com/Auerilas/ecopy;10.3389/fmicb.2020.01847;Richness and Good’s coverage for the Phaeocystis assemblage was calculated with 100 permutations using the “ecopy” (Lemoine, 2015) and “scikit-bio” packages on Python 3.6.1
ecopy;https://pypi.org/project/ecopy,https://github.com/Auerilas/ecopy;10.1128/mBio.00521-21;We then used this matrix to compute distance metrics between each genome based on protein content using the ecopy package in Python (method=‘jaccard’, transform=‘1’) and performing a principal-coordinate analysis (PCoA) using the skbio package
libensemble;https://pypi.org/project/libensemble,https://github.com/Libensemble/libensemble;10.1208/s12248-020-00471-y;The implementation of a multi-start algorithm (24) such as libensemble (25) may be a possible extension for the presented research to overcome these challenges
stringdb;https://pypi.org/project/stringdb,https://github.com/gpp-rnd/stringdb;10.1186/s12920-017-0245-6;KEGG, GO, and PPI enrichments for the gene groups were obtained using the stringdb package in R [16, 17]
stringdb;https://pypi.org/project/stringdb,https://github.com/gpp-rnd/stringdb;10.3390/biomedicines9070795;(a) The PPI network of identified menin’s interactome was constructed by stringdb websever
stringdb;https://pypi.org/project/stringdb,https://github.com/gpp-rnd/stringdb;10.1371/journal.pone.0199461;Protein–protein (PP) interactions including physical and functional association across our set of genes were identified in stringdb 10.0 [45]
WeBIAS;https://pypi.org/project/WeBIAS;10.1186/s13104-015-1622-x;Although these features make WeBIAS useful in complex environments, it can be very easily deployed on a single server
WeBIAS;https://pypi.org/project/WeBIAS;10.1186/s13321-020-0408-x;In efforts to facilitate easier dissemination of bioinformatic applications as web server, Daniluk et al. [278] introduced the WeBIAS platform, which is a self-contained solution that helps to make command-line programs accessible via web forms
WeBIAS;https://pypi.org/project/WeBIAS;10.1186/s13104-015-1622-x;WeBIAS manages its own user authentication and authorization
WeBIAS;https://pypi.org/project/WeBIAS;10.1186/s13104-015-1622-x;Nevertheless, they usually have a usable application, which can be easily adapted for WeBIAS.
WeBIAS;https://pypi.org/project/WeBIAS;10.1186/s13104-015-1622-x;WeBIAS uses its database to store these
plottools;https://pypi.org/project/plottools,https://github.com/BrechtBa/plottools;10.1186/1752-0509-3-109;Data was retrieved from the UCSC DAS server using DASMiner API, and the plot can be easily prepared using plottools, a GUI tool to make graphics in Matlab (see file Fig4B_histonesPlots_CancervsNormal.fig in the examples folder of the distributed source code)
Imagery;https://pypi.org/project/Imagery,https://github.com/prakashclt;10.1371/journal.pone.0218378;Then, they were asked to imagine the same different types of walking accompanied by a simultaneous stepping in place performed with a posture and a manner both coherent with the actual execution of that movement (dynamic Motor Imagery, dMI)
Imagery;https://pypi.org/project/Imagery,https://github.com/prakashclt;10.3389/fpsyg.2012.00360;Imagery does not add any new basic elements (e.g., a light tower) but computes, for example, second order aspects such as path lengths
Imagery;https://pypi.org/project/Imagery,https://github.com/prakashclt;10.1371/journal.pone.0163407;DNR GPS), and the Google Earth and Landsat Imagery are freely accessible they provide ideal tools for citizen science-based projects.
Imagery;https://pypi.org/project/Imagery,https://github.com/prakashclt;10.3390/jimaging6120137;Imagery © [2010, 2012, 2015, 2016] DigitalGlobe, Inc
Imagery;https://pypi.org/project/Imagery,https://github.com/prakashclt;10.1371/journal.pone.0234868;Imagery represents results from 50% KDE overlap analysis relative to other features in the GoM
pycsa;https://pypi.org/project/pycsa,https://github.com/structurely/csa;10.1371/journal.pone.0210177;To search globally optimal alignments, we used the CSA algorithm and it was implemented using pycsa [35]
rmarkdown;https://cran.r-project.org/web/packages/rmarkdown/index.html,https://github.com/rstudio/rmarkdown;10.12688/f1000research.6379.2;The package includes R Markdown templates which are processed using rmarkdown and knitr to produce HTML or PDF reports
rmarkdown;https://cran.r-project.org/web/packages/rmarkdown/index.html,https://github.com/rstudio/rmarkdown;10.3389/fmolb.2021.635074;The final, user-friendly HTML reports were produced using R markdown packages rmarkdown 2.6, knitr 1.30 and kableExtra 1.3.1.
rmarkdown;https://cran.r-project.org/web/packages/rmarkdown/index.html,https://github.com/rstudio/rmarkdown;10.3390/genes12071044;The CircIMPACT tool is developed based on R [39] (R version 3.6.3 or later are recommended), which also depends on several R packages (knitr [40], rmarkdown [41], data.table [42], dplyr [43], tydyverse [44], Rtsne [45], kableExtra [46], sparkline, magrittr [47], caret [48])
lubridate;https://cran.r-project.org/web/packages/lubridate/index.html,https://github.com/tidyverse/lubridate;10.2807/1560-7917.ES.2021.26.25.2000036;"Data were extracted, merged, analysed and compared using Stata (version 14, StataCorp, College Station, Texas, United States (US)), Microsoft Excel 2013, PowerPivot for Excel and R statistical software version 3.4.3 (R Foundation, Vienna, Austria; packages: “lubridate”, “ggplot2”, “foreign”, “multcomp”)."
lubridate;https://cran.r-project.org/web/packages/lubridate/index.html,https://github.com/tidyverse/lubridate;10.1038/s41598-019-42288-6;3.1.1) with the R packages “raster” (v 2.5-2), “ncdf” (v 1.6.8), “rgdal” (v 1.1-6), “RNetCDF” (v 1.8-2), “lubridate” (v 1.5.3), “RODBC” (v 1.3–10) and “geosphere” (v 1.5–1)
lubridate;https://cran.r-project.org/web/packages/lubridate/index.html,https://github.com/tidyverse/lubridate;10.1001/jamanetworkopen.2020.37227;All statistical analyses were performed with R Studio version 1.3.1073 and R versions 4.0.2 and 4.0.3 (R Project for Statistical Computing) with the following packages: Metrics, forecastHybrid, thief, forecast, cowplot, lubridate, forcats, stringr, dplyr, purrr, readr, tidyr, tibble, ggplot2, and tidyverse
knitr;https://cran.r-project.org/web/packages/knitr/index.html;10.1016/j.xpro.2021.100768;knitr (v1.24)
knitr;https://cran.r-project.org/web/packages/knitr/index.html;10.1371/journal.pone.0243927;With knitr package, a new Markdown file is created and converted into different file formats such as PDF, HTML, Word etc
knitr;https://cran.r-project.org/web/packages/knitr/index.html;10.3390/clinpract11030070;We used reporting tools based on the standards of replicable research using the R’s package “knitr” [31]
dplyr;https://cran.r-project.org/web/packages/dplyr/index.html,https://github.com/tidyverse/dplyr;10.7717/peerj.4251;The package depends on existing R packages dplyr (Wickham & Francois, 2015), minpack.lm (Elzhov et al., 2015), fBasics (Wuertz, Setz & Chalabi, 2014), and ggplot2 (Wickham, 2009).
dplyr;https://cran.r-project.org/web/packages/dplyr/index.html,https://github.com/tidyverse/dplyr;10.3389/fmicb.2020.00052;The figures generated during sraX analysis are achieved using R v.3.6.1 and the additional following packages: ggplot2 (Wickham, 2016), dplyr (Wickham et al., 2019), and gridExtra (Auguie, 2017)
dplyr;https://cran.r-project.org/web/packages/dplyr/index.html,https://github.com/tidyverse/dplyr;10.1002/ece3.5580;Packages utilized include dplyr (Wickham, Francois, Henry, & Müller, 2019), dunn.test (Dinno, 2017), ggplot2 (Wickham, 2016), reshape2 (Wickham, 2007), RColorBrewer (Neuwirth, 2014), Rmisc (Hope, 2013), and wesanderson (Ram & Wickham, 2018).
data.table;https://cran.r-project.org/web/packages/data.table/index.html,https://github.com/Rdatatable/data.table;10.1371/journal.pone.0239197;In writing these scripts, we used the following packages: readr [76], dplyr [77], ggplot2 [78], tidyr [79], reshape2 [80], ggrepel [81], cowplot [82], data.table [83], UpSetR [84], BSgenome.Hsapiens.UCSC.hg38 [85, 86], and Rtsne [87].
data.table;https://cran.r-project.org/web/packages/data.table/index.html,https://github.com/Rdatatable/data.table;10.2196/20329;For data preparation and descriptive statistics, we used the packages haven [35], dplyr [36], tidyr [37], car [38], ggplot2 [39], lsmeans [34], lmerTest [40], and data.table [41].
data.table;https://cran.r-project.org/web/packages/data.table/index.html,https://github.com/Rdatatable/data.table;10.1371/journal.pbio.3001296;Other R packages used in the analyses and data visualisation were the following: data.table [52], dplyr [53], gridExtra [54], mapdata [55], mcmcplots [56], MCMCvis [57], plyr [58], RColorBrewer [59], rgdal [60], readxl [61], tidyverse [62], viridis [63], and writexl [64].
stringr;https://cran.r-project.org/web/packages/stringr/index.html,https://github.com/tidyverse/stringr;10.1128/AEM.01096-17;BMiner, a companion application for parsing, viewing, and analyzing multiple BTyper files in aggregate, was created with the following dependencies: R version 3.3.2 (92) and R packages shiny version 1.01 (93), ggplot2 version 2.2.1 (94), readr version 1.1.0 (95), stringr version 1.2.0 (96), vegan version 2.4-2 (97), plyr version 1.8.4 (98), dplyr version 0.5.0 (99), cluster version 2.0.6 (100), ggrepel version 0.6.5 (101), and magrittr version 1.5 (102)
stringr;https://cran.r-project.org/web/packages/stringr/index.html,https://github.com/tidyverse/stringr;10.1186/s12920-021-01079-7;R packages tidyverse and stringr were used for data analysis, and graphs were plotted using ggplot2
stringr;https://cran.r-project.org/web/packages/stringr/index.html,https://github.com/tidyverse/stringr;10.1186/s13148-020-0824-9;Quality control (QC) and all statistical analyses were performed using the R version 3.5.2 statistical analysis software, and the R-packages SWAN, missmethyl, minfi, limma, IlluminaHumanMethylation450kanno.ilmn12.hg19, IlluminaHumanMethylation450kmanifest, IlluminaHumanMethylationEPICmanifest, IlluminaHumanMethylationEPICanno.ilm10b2.hg19, bumphunter, RColorBrewer, matrixStats, minfiData, Gviz, DMRcate, and stringr.
shiny;https://cran.r-project.org/web/packages/shiny/index.html;10.1186/s13104-019-4179-2;The current implementation depends on the following R packages: TCC, shiny, shinyBS, shinycssloaders, shinydashboard, shinyWidgets, plotly, dplyr, DT, heatmaply, tidyr, utils, rmarkdown, data.table, RColorBrewer, knitr, cluster, and MASS
shiny;https://cran.r-project.org/web/packages/shiny/index.html;10.1186/s12859-019-3251-1;The input files for R shiny report should be transferred into the ‘data’ folder under the shiny app folder
shiny;https://cran.r-project.org/web/packages/shiny/index.html;10.1371/journal.pone.0233282;We also created a shiny application [82] allowing for further visual exploration of the data by muscle, by condition, and by participant, in the 3D space formed by three (to be chosen) muscles
ggplot2;https://cran.r-project.org/web/packages/ggplot2/index.html,https://github.com/tidyverse/ggplot2;10.1186/s12864-019-5750-x;All graphs were plotted with R (3.4.2) [103], RStudio (1.1.383) [104], and ggplot2 (2.2.1) [105].
ggplot2;https://cran.r-project.org/web/packages/ggplot2/index.html,https://github.com/tidyverse/ggplot2;10.1186/s12864-018-4559-3;A smooth curve is fitted by using the geom_loess function in the ggplot2 package
ggplot2;https://cran.r-project.org/web/packages/ggplot2/index.html,https://github.com/tidyverse/ggplot2;10.3389/fmicb.2021.666936;The number of enzymes/functions was converted to “1” if present and to “0” if absent, and a presence/absence heatmap was then constructed using the “ggplot2” package.
tidyr;https://cran.r-project.org/web/packages/tidyr/index.html,https://github.com/tidyverse/tidyr;10.1007/s10389-021-01543-9;The following packages were used for data processing, analysis, and data visualisation: tidyverse (Wickham 2017), tidyr (Wickham and Henry 2019), pysch (Revelle 2018), MASS (Venables and Ripley 2002), and apaTables (Stanley 2018).
tidyr;https://cran.r-project.org/web/packages/tidyr/index.html,https://github.com/tidyverse/tidyr;10.1186/s12920-019-0504-9;To reformat, summarize, and visualize the data, the following R packages were used: ggplot2, dplyr, tidyr, GenVisR, and reshape2
tidyr;https://cran.r-project.org/web/packages/tidyr/index.html,https://github.com/tidyverse/tidyr;10.1186/s12974-021-02235-7;"Data visualization and statistical analyses were completed using R 3.6.2 (R Core Team, 2019) with the following packages: dplyr (v0.8.5 [64];), tidyr (v1.0.2 [65];), rstatix (v0.5.0 [66];), DescTools (v0.99.34 [67];), sjstats (v0.17.9 [68];), ReadqPCR and NormqPCR [62], ggplot2 [69], gridExtra (v2.3 [70];), pheatmap (v1.0.12 [71];), and viridis (v0.5.1 [72];)."
readr;https://cran.r-project.org/web/packages/readr/index.html,https://github.com/tidyverse/readr;10.1038/s42003-021-02366-w;Statistical analyses were performed with the R environment 4.02 v3.4.4: with DESeq2, readr, and tximport libraries loaded
readr;https://cran.r-project.org/web/packages/readr/index.html,https://github.com/tidyverse/readr;10.7717/peerj.6486;The following packages were used: readr (Wickham et al., 2017), magrittr (Bache & Wickham, 2014), tidyverse (Wickham, 2017), and ggplot2 (Wickham, 2009).
readr;https://cran.r-project.org/web/packages/readr/index.html,https://github.com/tidyverse/readr;10.1186/s12859-020-03922-7;The R packages required to install and run annoFuse are reshape2, dplyr, tidyr, ggplot2, qdapRegex, ggpubr, tibble, ggthemes, EnsDb.Hsapiens.v86, grid, readr, grDevices, stats, utils, stringr, shiny, shinydashboard, rintrojs, shinythemes, DT, rmarkdown, and methods, with the optional package: knitr
pytorch;https://pypi.org/project/pytorch;10.3389/fnins.2020.00919;Further preprocessing can be directly applied using the utils python package provided, making the data readily available to exploit in popular python machine learning packages as pytorch and tensorflow.
pytorch;https://pypi.org/project/pytorch;10.3390/s20205762;All transformations can be implemented by pytorch and were performed during training on each data batch according to the mentioned probabilities
pytorch;https://pypi.org/project/pytorch;10.3390/s21061983;All the proposed method and models were implemented using pytorch and fastai [51]
Django;https://pypi.org/project/Django,https://github.com/django/django;10.1093/database/baz101;The annotation tool was written using the Django web-framework (V.: 2.0.1) with a PostgreSQL (V.: 9.6.9) backend
Django;https://pypi.org/project/Django,https://github.com/django/django;10.3389/fninf.2021.713899;The EBRAINS NeuroFeatureExtract consists of a full stack web-based application implemented via the Python-based Django web framework and deployed on a dedicated Virtual Machine (VM) hosted on the CINECA supercomputing center and accessible/configurable through the OpenStack interface
Django;https://pypi.org/project/Django,https://github.com/django/django;10.3390/s18113891;The atmospheric environmental monitoring system software is created in the Django framework [21], which stores data using a MySQL database and communicates with the terminal collection device via Socket communication
requests;https://pypi.org/project/requests,https://github.com/psf/requests;10.1186/s12911-020-1046-y;Project name: Prikbord Project home page:http://prikbord.science.ru.nl/Operating system: Linux Programming language: Python, javascript Other requirements: Django 1.5.11 or higher, MongoDB 2.6.10, pymongo 2.7.2 or higher, requests 2.13.0 or higher License: GNU GPL Any restrictions to use by non-academics: licence needed
requests;https://pypi.org/project/requests,https://github.com/psf/requests;10.3389/fvets.2021.674730;Using requests and BeautifulSoup packages in Python, all the PDF files with the titles containing “MRK” by avoiding cases sensitivity of uppercase or lowercase for each letter (e.g., “mRK,” “MrK,” “mrk,” etc.) from the years 2018, 2019, and 2020 were automatically collected and saved in a separate folder for further steps
requests;https://pypi.org/project/requests,https://github.com/psf/requests;10.1016/j.dib.2021.107360;We used the json and requests packages [35,36]to collect data and the scikit-learn package [37] to impute missing values
scikit-learn;https://pypi.org/project/scikit-learn,https://github.com/scikit-learn/scikit-learn;10.3389/fmicb.2020.00383;We performed random forest classification using the implementation of this method in Python’s scikit-learn package
scikit-learn;https://pypi.org/project/scikit-learn,https://github.com/scikit-learn/scikit-learn;10.1186/s13073-021-00919-6;For taxonomic classification, a scikit-learn [44] naive Bayes classifier was created against the taxonomic classification from ARB-SILVA [45] 132 release (99% OTU data set), which was trained for the used primers
scikit-learn;https://pypi.org/project/scikit-learn,https://github.com/scikit-learn/scikit-learn;10.7554/eLife.46935;scikit-learn (Pedregosa et al., 2011).
matplotlib;https://pypi.org/project/matplotlib,https://github.com/matplotlib/matplotlib;10.3389/fncir.2014.00005;Figures and data visualization were done using matplotlib (Hunter, 2007) and Inkscape (Andler et al., 2004–2014)
matplotlib;https://pypi.org/project/matplotlib,https://github.com/matplotlib/matplotlib;10.1186/s13321-019-0351-x;Additionally, basic Python computing libraries employed include numpy [21, 22] and pandas [23, 24] (high-performance data structures and analysis), scikit-learn [25] (machine learning), as well as matplotlib [26] and seaborn [27] (plotting)
matplotlib;https://pypi.org/project/matplotlib,https://github.com/matplotlib/matplotlib;10.3390/pharmaceutics12111071;The analysis was performed in Python, using numpy and matplotlib.
numpy;https://pypi.org/project/numpy,https://github.com/numpy/numpy;10.1371/journal.pone.0225900;In particular, indexing is possible via square brackets […] and mostly follows the conventions of numpy [45], the de facto standard for numerics in Python
numpy;https://pypi.org/project/numpy,https://github.com/numpy/numpy;10.1371/journal.pone.0249624;Numerical arrays were stored using the numpy package [35]
numpy;https://pypi.org/project/numpy,https://github.com/numpy/numpy;10.7717/peerj.2823;"Python packages used for analysis include numpy (Oliphant, 2007; Van der Walt, Colbert & Varoquaux, 2011), matplotlib (Hunter, 2007), sqlalchemy (Bayer, 2014), pandas (McKinney, 2010), macroecotools (Xiao et al., 2016), and retriever (Morris & White, 2013)"
pandas;https://pypi.org/project/pandas,https://github.com/pandas-dev/pandas;10.7717/peerj-cs.687;Step 2: Load data by using the pandas library
pandas;https://pypi.org/project/pandas,https://github.com/pandas-dev/pandas;10.1093/bib/bbab055;Other requirements: Bowtie (developed with 1.1.2), biopython (Python2-1.76, Python3-1.76 or higher), numpy (Python2-1.16-1.18, Python3-1.16 or higher), pandas (Python2-0.24.2, Python3-0.24.2 or higher)
pandas;https://pypi.org/project/pandas,https://github.com/pandas-dev/pandas;10.3390/s19061361;To do this, we used the programming language Python and five libraries: scipy, numpy, matplotlib, pandas, and sklearn.
tensorflow;https://pypi.org/project/tensorflow;10.1186/s12880-021-00551-1;Other requirements: matplotlib, pytorch, fastai (v1.0.61), gif, tensorflow, altair, fastai2, pydicom, kornia, scikit-image, torchio.
tensorflow;https://pypi.org/project/tensorflow;10.3389/fnins.2019.01321;The DL model was written in tensorflow 1.4 (Abadi et al., 2016) and the interprettensor library (https://github.com/VigneshSrinivasan10/interprettensor).
tensorflow;https://pypi.org/project/tensorflow;10.1186/s40537-020-00387-6;With tensorflow version 1.14.0 and python version 3.7.4
BeautifulSoup;https://pypi.org/project/BeautifulSoup;10.1186/s12859-020-3540-8;For the prior knowledge from UniProt KB, we use Bioservices, urllib, BeautifulSoup tool does finish a series of processes
BeautifulSoup;https://pypi.org/project/BeautifulSoup;10.1038/s41597-020-00682-0;Wikipedia is accessed through the MediaWiki API using Python, and the BeautifulSoup, json, and requests packages
BeautifulSoup;https://pypi.org/project/BeautifulSoup;10.1186/s40537-021-00476-0;In this paper, the Python programming language, with packages made by BeautifulSoup and Selenium, was used to write an algorithm and purposely collect desired variables for apartment listings in the capital city of Vilnius with sell and rent operations
Flask;https://pypi.org/project/Flask,https://github.com/pallets/flask/;10.3390/ijms22157811;The server side is run by a Flask application server, also implemented in Python
Flask;https://pypi.org/project/Flask,https://github.com/pallets/flask/;10.3390/diagnostics10060421;This application was developed using the Dash Framework (Plotly’s Python-based micro Web Framework using Flask as a Server)
Flask;https://pypi.org/project/Flask,https://github.com/pallets/flask/;10.1038/sdata.2018.23;"The back-end of the website was developed with Flask; the front-end of the website was developed with JavaScript, HTML, and CSS"
beautifulsoup4;https://pypi.org/project/beautifulsoup4;10.3390/s20010190;Our API for the acquisition of weather data operates by scraping the web page of the automatic Brazilian weather stations [5] using the libraries requests [67] and beautifulsoup4 [68], as well the frameworks Django [69] and Django rest [70]
