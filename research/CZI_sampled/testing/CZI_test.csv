name;ground truth;candidate_urls;doi;paragraph
Axe;https://github.com/kdm9/axe;https://pypi.org/project/Axe,https://github.com/soasme/axe;10.1186/s12859-021-04267-5;Axe uses a set of pre-computed prefix trees to find a match within a given Hamming distance and can partially handle barcodes that differ in length
Axe;https://github.com/kdm9/axe;https://pypi.org/project/Axe,https://github.com/soasme/axe;10.1186/s12870-018-1575-z;Raw reads were assigned to individual samples in accordance with their nucleotide barcode, using Axe package [60]
Axe;https://github.com/kdm9/axe;https://pypi.org/project/Axe,https://github.com/soasme/axe;10.7717/peerj.7170;"Popular tools include FASTX-Toolkit (Gordon & Hannon, 2010), Axe (Murray & Borevitz, 2018), Flexbar (Dodt et al., 2012; Roehr, Dieterich & Reinert, 2017), Cutadapt (Martin, 2011), and AdapterRemoval (Lindgreen, 2012; Schubert, Lindgreen & Orlando, 2016), Trimmomatic (Bolger, Lohse & Usadel, 2014), Skewer (Jiang et al., 2014), and GBSX (Herten et al., 2015)"
Axe;https://github.com/kdm9/axe;https://pypi.org/project/Axe,https://github.com/soasme/axe;10.3390/genes10010009;Paired-end reads were demultiplexed and barcodes were trimmed using Axe [79] with a maximum mismatch of 1
BeautifulSoup;https://pypi.org/project/beautifulsoup4/,https://github.com/wention/BeautifulSoup4,https://pypi.org/project/BeautifulSoup/;https://pypi.org/project/BeautifulSoup;10.1186/s12859-020-3540-8;For the prior knowledge from UniProt KB, we use Bioservices, urllib, BeautifulSoup tool does finish a series of processes
BeautifulSoup;https://pypi.org/project/beautifulsoup4/,https://github.com/wention/BeautifulSoup4,https://pypi.org/project/BeautifulSoup/;https://pypi.org/project/BeautifulSoup;10.1038/s41597-020-00682-0;Wikipedia is accessed through the MediaWiki API using Python, and the BeautifulSoup, json, and requests packages
BeautifulSoup;https://pypi.org/project/beautifulsoup4/,https://github.com/wention/BeautifulSoup4,https://pypi.org/project/BeautifulSoup/;https://pypi.org/project/BeautifulSoup;10.1186/s40537-021-00476-0;In this paper, the Python programming language, with packages made by BeautifulSoup and Selenium, was used to write an algorithm and purposely collect desired variables for apartment listings in the capital city of Vilnius with sell and rent operations
beautifulsoup4;https://pypi.org/project/beautifulsoup4/,https://github.com/wention/BeautifulSoup4;https://pypi.org/project/beautifulsoup4;10.3390/s20010190;Our API for the acquisition of weather data operates by scraping the web page of the automatic Brazilian weather stations [5] using the libraries requests [67] and beautifulsoup4 [68], as well the frameworks Django [69] and Django rest [70]
BioMark;;https://cran.r-project.org/web/packages/BioMark/index.html;10.1186/1471-2164-13-521;Genotype calling was carried out using the SDS 2.3 software (Life Technologies, Carlsbad California) or the BioMark 3.0.2 software (Fluidigm, South San Francisco, California)
BioMark;;https://cran.r-project.org/web/packages/BioMark/index.html;10.1534/g3.115.020222;Genotypes were called using the BioMark software v3.0.2 (Fluidigm, South San Francisco, CA)
BioMark;;https://cran.r-project.org/web/packages/BioMark/index.html;10.1371/journal.pone.0001662;Data was analyzed using the BioMark digital array software and the numbers of positive chambers were corrected to estimate the true number of copies [32]
BioMark;;https://cran.r-project.org/web/packages/BioMark/index.html;10.1186/s12862-017-1109-6;"Data from the gene expression analysis were processed using the Fluidigm-integrated software (Fluidigm Real-Time PCR analysis; BioMark Version 4.1.2)"
BioMark;;https://cran.r-project.org/web/packages/BioMark/index.html;10.3390/ijms17030402;The BioMark software (Fluidigm, South San Francisco, CA, USA) can generate PCR amplification curves and analyze the threshold values of the 36,960 individual partitions (48 × 770)
catwalk;https://github.com/qlik-oss/catwalk;https://github.com/qlik-oss/catwalk;10.1021/acschemneuro.0c00794;In the catwalk analyses, a small number of postprocedure changes were observed, but these were not consistent
catwalk;https://github.com/qlik-oss/catwalk;https://github.com/qlik-oss/catwalk;10.1371/journal.pone.0068584;Gait performance was assessed and recorded using the catwalk analysis software
catwalk;https://github.com/qlik-oss/catwalk;https://github.com/qlik-oss/catwalk;10.1371/journal.pone.0023244;Effects on rotarod performance are assessed between days 35 to 60, analysis of hind-limb muscle volume and immunohistochemistry to assess the degree of gastrocnemius innervation at day 60 in half of the cohort and the remaining cohort being assessed for motor function using the catwalk gait analysis system and for time to onset
catwalk;https://github.com/qlik-oss/catwalk;https://github.com/qlik-oss/catwalk;10.1016/j.freeradbiomed.2013.04.018;The catwalk gait analysis system (Noldus Instruments, version 7.1) was used to capture gait parameters in groups of 5 G93A—transgenic mice and 7 nontransgenic mice
catwalk;https://github.com/qlik-oss/catwalk;https://github.com/qlik-oss/catwalk;10.1371/journal.pone.0023244;4/ Assess the remaining 7 mice per group, 3 times per week for onset of clinical signs from 60 days of age to day 90 (if necessary) and gait analysis using the catwalk gait analysis system at 63, 77 and 91 days of age (9, 11, and 13 weeks)
chngpt;https://cran.r-project.org/web/packages/chngpt/index.html,https://github.com/cran/chngpt,https://github.com/youyifong/chngpt;https://cran.r-project.org/web/packages/chngpt/index.html;10.1186/s12859-017-1863-x;chngpt is an open source software and can be downloaded from the Comprehensive R Archive Network
chngpt;https://cran.r-project.org/web/packages/chngpt/index.html,https://github.com/cran/chngpt,https://github.com/youyifong/chngpt;https://cran.r-project.org/web/packages/chngpt/index.html;10.3389/fpls.2020.00636;Linear and intercept-only (null) models were fit with the lm function and step and hinge functions were fit with the chngpt package (Fong et al., 2017)
chngpt;https://cran.r-project.org/web/packages/chngpt/index.html,https://github.com/cran/chngpt,https://github.com/youyifong/chngpt;https://cran.r-project.org/web/packages/chngpt/index.html;10.1007/s11357-020-00205-0;All analyses were conducted in STATA 16.0 (StataCorp 2019), and double-checked in R (R Core Team R 2017) using packages chngpt (Fong et al
chngpt;https://cran.r-project.org/web/packages/chngpt/index.html,https://github.com/cran/chngpt,https://github.com/youyifong/chngpt;https://cran.r-project.org/web/packages/chngpt/index.html;10.1186/s12859-017-1863-x;"Our chngpt package complements the segmented package by making three unique contributions: (1) it supports all four types of threshold effects in Fig. 1, and supports models with interaction terms between predictors subjected to thresholding and predictors not subjected to thresholding [10]; (2) the search method in segmented employs a first order approximation of the non-smooth criterion function [11], while chngpt offers two alternative search methods: exact, which optimizes the exact criterion function, "
chngpt;https://cran.r-project.org/web/packages/chngpt/index.html,https://github.com/cran/chngpt,https://github.com/youyifong/chngpt;https://cran.r-project.org/web/packages/chngpt/index.html;10.1186/s12859-017-1863-x;A second example illustrating the use of chngpt for fitting thresholded linear regression models can be found in the Additional file 1: Section B.
data.table;https://cran.r-project.org/package=data.table,https://github.com/Rdatatable/data.table,https://github.com/cran/data.table;https://cran.r-project.org/web/packages/data.table/index.html,https://github.com/Rdatatable/data.table;10.1371/journal.pone.0239197;In writing these scripts, we used the following packages: readr [76], dplyr [77], ggplot2 [78], tidyr [79], reshape2 [80], ggrepel [81], cowplot [82], data.table [83], UpSetR [84], BSgenome.Hsapiens.UCSC.hg38 [85, 86], and Rtsne [87].
data.table;https://cran.r-project.org/package=data.table,https://github.com/Rdatatable/data.table,https://github.com/cran/data.table;https://cran.r-project.org/web/packages/data.table/index.html,https://github.com/Rdatatable/data.table;10.2196/20329;For data preparation and descriptive statistics, we used the packages haven [35], dplyr [36], tidyr [37], car [38], ggplot2 [39], lsmeans [34], lmerTest [40], and data.table [41].
data.table;https://cran.r-project.org/package=data.table,https://github.com/Rdatatable/data.table,https://github.com/cran/data.table;https://cran.r-project.org/web/packages/data.table/index.html,https://github.com/Rdatatable/data.table;10.1371/journal.pbio.3001296;Other R packages used in the analyses and data visualisation were the following: data.table [52], dplyr [53], gridExtra [54], mapdata [55], mcmcplots [56], MCMCvis [57], plyr [58], RColorBrewer [59], rgdal [60], readxl [61], tidyverse [62], viridis [63], and writexl [64].
Django;https://pypi.org/project/Django/,https://github.com/django/django;https://pypi.org/project/Django,https://github.com/django/django;10.1093/database/baz101;The annotation tool was written using the Django web-framework (V.: 2.0.1) with a PostgreSQL (V.: 9.6.9) backend
Django;https://pypi.org/project/Django/,https://github.com/django/django;https://pypi.org/project/Django,https://github.com/django/django;10.3389/fninf.2021.713899;The EBRAINS NeuroFeatureExtract consists of a full stack web-based application implemented via the Python-based Django web framework and deployed on a dedicated Virtual Machine (VM) hosted on the CINECA supercomputing center and accessible/configurable through the OpenStack interface
Django;https://pypi.org/project/Django/,https://github.com/django/django;https://pypi.org/project/Django,https://github.com/django/django;10.3390/s18113891;The atmospheric environmental monitoring system software is created in the Django framework [21], which stores data using a MySQL database and communicates with the terminal collection device via Socket communication
dplyr;https://cran.r-project.org/package=dplyr,https://github.com/tidyverse/dplyr,https://github.com/cran/dplyr;https://cran.r-project.org/web/packages/dplyr/index.html,https://github.com/tidyverse/dplyr;10.7717/peerj.4251;The package depends on existing R packages dplyr (Wickham & Francois, 2015), minpack.lm (Elzhov et al., 2015), fBasics (Wuertz, Setz & Chalabi, 2014), and ggplot2 (Wickham, 2009).
dplyr;https://cran.r-project.org/package=dplyr,https://github.com/tidyverse/dplyr,https://github.com/cran/dplyr;https://cran.r-project.org/web/packages/dplyr/index.html,https://github.com/tidyverse/dplyr;10.3389/fmicb.2020.00052;The figures generated during sraX analysis are achieved using R v.3.6.1 and the additional following packages: ggplot2 (Wickham, 2016), dplyr (Wickham et al., 2019), and gridExtra (Auguie, 2017)
dplyr;https://cran.r-project.org/package=dplyr,https://github.com/tidyverse/dplyr,https://github.com/cran/dplyr;https://cran.r-project.org/web/packages/dplyr/index.html,https://github.com/tidyverse/dplyr;10.1002/ece3.5580;Packages utilized include dplyr (Wickham, Francois, Henry, & Müller, 2019), dunn.test (Dinno, 2017), ggplot2 (Wickham, 2016), reshape2 (Wickham, 2007), RColorBrewer (Neuwirth, 2014), Rmisc (Hope, 2013), and wesanderson (Ram & Wickham, 2018).
ecopy;https://pypi.org/project/ecopy/,https://github.com/Auerilas/ecopy;https://pypi.org/project/ecopy,https://github.com/Auerilas/ecopy;10.1186/s12915-020-00804-5;We then used this information to generate a Bray-Curtis distance matrix using the ecopy package in Python
ecopy;https://pypi.org/project/ecopy/,https://github.com/Auerilas/ecopy;https://pypi.org/project/ecopy,https://github.com/Auerilas/ecopy;10.1002/ece3.7299;The abundances were square?root transformed (to match the transformation of the abundance matrix used in the Bray–Curtis calculation), and the analysis was conducted in Python using ecopy's simper function.
ecopy;https://pypi.org/project/ecopy/,https://github.com/Auerilas/ecopy;https://pypi.org/project/ecopy,https://github.com/Auerilas/ecopy;10.3389/fmicb.2020.01847;Richness and Good’s coverage for the Phaeocystis assemblage was calculated with 100 permutations using the “ecopy” (Lemoine, 2015) and “scikit-bio” packages on Python 3.6.1
ecopy;https://pypi.org/project/ecopy/,https://github.com/Auerilas/ecopy;https://pypi.org/project/ecopy,https://github.com/Auerilas/ecopy;10.1128/mBio.00521-21;We then used this matrix to compute distance metrics between each genome based on protein content using the ecopy package in Python (method=‘jaccard’, transform=‘1’) and performing a principal-coordinate analysis (PCoA) using the skbio package
ESEfinder;;https://github.com/MahyarHosseini/ESEfinder;10.1186/1756-0500-1-86;ESEfinder 3.0 [21] was used to scan the genomic region containing SNPs found only among affected individuals in the screening panel for the identification of splice enhancer binding sites in the wildtype sequence
ESEfinder;;https://github.com/MahyarHosseini/ESEfinder;10.1242/dmm.036616;The c.1226 A>G mutation, with its flanking sequences, was predicted as a potential ESE motif using ESEfinder software, and the motif sequence carrying the mutant G allele presented a higher weighted majority vote (WMV) score than that carrying the A allele (3.19 versus 2.82), suggesting that the G allele potentially increased binding affinity for SRSF2 (a member of the family of pre-mRNA splicing factors) and contributed to a high incidence of alternative splicing (AS)
ESEfinder;;https://github.com/MahyarHosseini/ESEfinder;10.1186/1471-2164-9-265;ESEfinder uses a position specific weight matrix
ESEfinder;;https://github.com/MahyarHosseini/ESEfinder;10.1038/tp.2015.154;An in silico structural analysis of exon 3b of the human DLG1 gene using ESEfinder, FAS-ESS, and RESQUE-ESS indicated the presence of an exonic splicing enhancer (ESE) consensus (TGAAAGAAT) in exon 3b (Figure 4)
ESEfinder;;https://github.com/MahyarHosseini/ESEfinder;10.1371/journal.pgen.1003058;ESEfinder 3.0 [34]was used to identify putative splicing factor binding motifs disrupted by rs11716445.
Factoshiny;https://cran.r-project.org/web/packages/Factoshiny/index.html,https://github.com/cran/Factoshiny,https://github.com/husson/Factoshiny;https://cran.r-project.org/web/packages/Factoshiny/index.html;10.7717/peerj.12031;The PCA was performed in R version 4.0.3 with the function “PCAshiny” in the “Factoshiny” package (Vaissie, Monge & Husson, 2021)
Factoshiny;https://cran.r-project.org/web/packages/Factoshiny/index.html,https://github.com/cran/Factoshiny,https://github.com/husson/Factoshiny;https://cran.r-project.org/web/packages/Factoshiny/index.html;10.1038/s41598-021-98634-0;Factoshiny software package running within RStudio was used for HCPC analysis
Factoshiny;https://cran.r-project.org/web/packages/Factoshiny/index.html,https://github.com/cran/Factoshiny,https://github.com/husson/Factoshiny;https://cran.r-project.org/web/packages/Factoshiny/index.html;10.1186/s12864-021-07902-w;The FactoMineR [158] R package was used to perform the analysis and Factoshiny [159] was used to generate PCA plots.
Factoshiny;https://cran.r-project.org/web/packages/Factoshiny/index.html,https://github.com/cran/Factoshiny,https://github.com/husson/Factoshiny;https://cran.r-project.org/web/packages/Factoshiny/index.html;10.1186/s12866-019-1678-1;PCA was used to identify correlations among the strains using the genetic information and data from the isolation sources generated in the current study and the FactoMineR and Factoshiny packages (version 1.42) in R (version 3.5.2) software (https://cran.r-project.org/)
Factoshiny;https://cran.r-project.org/web/packages/Factoshiny/index.html,https://github.com/cran/Factoshiny,https://github.com/husson/Factoshiny;https://cran.r-project.org/web/packages/Factoshiny/index.html;10.3389/fnut.2021.592340;Factoshiny package running within RStudio platform was used for HCPC (48, 49).
Flask;https://pypi.org/project/Flask/,https://github.com/pallets/flask;https://pypi.org/project/Flask,https://github.com/pallets/flask/;10.3390/ijms22157811;The server side is run by a Flask application server, also implemented in Python
Flask;https://pypi.org/project/Flask/,https://github.com/pallets/flask;https://pypi.org/project/Flask,https://github.com/pallets/flask/;10.3390/diagnostics10060421;This application was developed using the Dash Framework (Plotly’s Python-based micro Web Framework using Flask as a Server)
Flask;https://pypi.org/project/Flask/,https://github.com/pallets/flask;https://pypi.org/project/Flask,https://github.com/pallets/flask/;10.1038/sdata.2018.23;"The back-end of the website was developed with Flask; the front-end of the website was developed with JavaScript, HTML, and CSS"
GenStat;;https://github.com/richardtjornhammar/GenStat;10.3389/fpls.2018.00011;A simple linear regression with groups was performed using GenStat-12 software (VSN International Ltd., Cambridge, England)
GenStat;;https://github.com/richardtjornhammar/GenStat;10.1093/jxb/ery170;ANOVA was carried out on all parameters at each growth stage using GenStat for Windows, 17th Edition (VSN International Ltd)
GenStat;;https://github.com/richardtjornhammar/GenStat;10.3390/foods10010096;Separate linear mixed models were fitted by restricted maximum likelihood for liking, premiumness and frequency of consumption data using GenStat for Windows 16th Edition, (VSN International Hemel Hempstead, UK)
GenStat;;https://github.com/richardtjornhammar/GenStat;10.7717/peerj.7527;Data were analysed statistically using GenStat 12.1 (VSN International Ltd, Hemel Hempstead, Hertforshire, UK)
GenStat;;https://github.com/richardtjornhammar/GenStat;10.1186/s12917-017-1169-2;Data were analysed with the statistical software GenStat 16.1 (VSN International, Hemel Hempstead, UK), using two sample t-tests and logistic regression
ggplot2;https://cran.r-project.org/package=ggplot2,https://github.com/tidyverse/ggplot2,https://github.com/cran/ggplot2;https://cran.r-project.org/web/packages/ggplot2/index.html,https://github.com/tidyverse/ggplot2;10.1186/s12864-019-5750-x;All graphs were plotted with R (3.4.2) [103], RStudio (1.1.383) [104], and ggplot2 (2.2.1) [105].
ggplot2;https://cran.r-project.org/package=ggplot2,https://github.com/tidyverse/ggplot2,https://github.com/cran/ggplot2;https://cran.r-project.org/web/packages/ggplot2/index.html,https://github.com/tidyverse/ggplot2;10.1186/s12864-018-4559-3;A smooth curve is fitted by using the geom_loess function in the ggplot2 package
ggplot2;https://cran.r-project.org/package=ggplot2,https://github.com/tidyverse/ggplot2,https://github.com/cran/ggplot2;https://cran.r-project.org/web/packages/ggplot2/index.html,https://github.com/tidyverse/ggplot2;10.3389/fmicb.2021.666936;The number of enzymes/functions was converted to “1” if present and to “0” if absent, and a presence/absence heatmap was then constructed using the “ggplot2” package.
HFSS;;https://github.com/LyingCortex/HFSS;10.3390/s20216142;In simulations, both focusing lenses with 3D unit cell structures were implemented in HFSS and the focusing gain was calculated
HFSS;;https://github.com/LyingCortex/HFSS;10.3390/s19143134;The simulations conducted with HFSS to obtain such results required using ?r = 22, tan? = 0.001 and h = 0.04 mm thickness
HFSS;;https://github.com/LyingCortex/HFSS;10.1038/s41598-020-69547-1;In this simulations, ten layers with the same thickness of 1 mm above the tag have been tested with the same permittivity as the air and only the permittivity of one of them has been changed to 2 at each step determined by layer number in parts (d) and (e) [images in parts (a), (b), and (c) are obtained from HFSS]
HH;https://cran.r-project.org/web/packages/HH/index.html,https://github.com/cran/HH;https://cran.r-project.org/web/packages/HH/index.html;10.1371/journal.pone.0186285;Statements evaluated with a forced Likert scale were plotted using package “HH” [23] in the open-source software program R [24].
HH;https://cran.r-project.org/web/packages/HH/index.html,https://github.com/cran/HH;https://cran.r-project.org/web/packages/HH/index.html;10.1093/aobpla/ply009;"Covariates were then checked for multicolinearity using the variance inflation factor (function ‘vif’ in package ‘HH’; Heiberg 2016)"
HH;https://cran.r-project.org/web/packages/HH/index.html,https://github.com/cran/HH;https://cran.r-project.org/web/packages/HH/index.html;10.5334/aogh.2809;For the Training Needs Assessment (TNA), a parametric T-test, using GraphPad, was employed to explore the statistically significant difference between score A (importance of activity to job) and score B (ability of respondent to perform the activity), as recommended by the HH tool authors [1718]
knitr;https://cran.r-project.org/package=knitr,https://github.com/yihui/knitr,https://github.com/cran/knitr;https://cran.r-project.org/web/packages/knitr/index.html;10.1016/j.xpro.2021.100768;knitr (v1.24)
knitr;https://cran.r-project.org/package=knitr,https://github.com/yihui/knitr,https://github.com/cran/knitr;https://cran.r-project.org/web/packages/knitr/index.html;10.1371/journal.pone.0243927;With knitr package, a new Markdown file is created and converted into different file formats such as PDF, HTML, Word etc
knitr;https://cran.r-project.org/package=knitr,https://github.com/yihui/knitr,https://github.com/cran/knitr;https://cran.r-project.org/web/packages/knitr/index.html;10.3390/clinpract11030070;We used reporting tools based on the standards of replicable research using the R’s package “knitr” [31]
libensemble;https://pypi.org/project/libensemble/,https://github.com/Libensemble/libensemble;https://pypi.org/project/libensemble,https://github.com/Libensemble/libensemble;10.1208/s12248-020-00471-y;The implementation of a multi-start algorithm (24) such as libensemble (25) may be a possible extension for the presented research to overcome these challenges
locfit;https://cran.r-project.org/web/packages/locfit/index.html,https://github.com/cran/locfit;https://cran.r-project.org/web/packages/locfit/index.html;10.1371/journal.pone.0075029;Parameters’ posterior distributions were estimated using a local linear regression method [58] and plotted in R using the package locfit [59]
locfit;https://cran.r-project.org/web/packages/locfit/index.html,https://github.com/cran/locfit;https://cran.r-project.org/web/packages/locfit/index.html;10.1093/aje/kwy114;We directly estimated seroprevalence according to age from the IgG serological data using a nonparametric model with local polynomial estimators, given its flexibility in allowing nonmonotonicity (“locfit” library (26) in R (R Foundation for Statistical Computing, Vienna, Austria)) (16) (see Web Appendix 1, Web Figure 1, available at https://academic.oup.com/aje for details)
locfit;https://cran.r-project.org/web/packages/locfit/index.html,https://github.com/cran/locfit;https://cran.r-project.org/web/packages/locfit/index.html;10.1038/s41598-020-77162-3;We interpolated locfit output using interp1.m function and applied z-score normalization to get the normalized density per cortical state per second
locfit;https://cran.r-project.org/web/packages/locfit/index.html,https://github.com/cran/locfit;https://cran.r-project.org/web/packages/locfit/index.html;10.1002/jrsm.1185;As there is some variability due to the random sampling, we used the R (R Core Team, 2012) package locfit (Loader, 2012) to smoothly estimate the mean
locfit;https://cran.r-project.org/web/packages/locfit/index.html,https://github.com/cran/locfit;https://cran.r-project.org/web/packages/locfit/index.html;10.18632/aging.102925;"Statistical analyses were performed using R (Version 3.5.1, R Core Team 2018 [88]; locfit package version 1.5-9.1 [89]; ggplot2 package [90] for visualizations) with ? set to 0.05."
lubridate;https://cran.r-project.org/package=lubridate,https://github.com/tidyverse/lubridate,https://github.com/cran/lubridate;https://cran.r-project.org/web/packages/lubridate/index.html,https://github.com/tidyverse/lubridate;10.2807/1560-7917.ES.2021.26.25.2000036;"Data were extracted, merged, analysed and compared using Stata (version 14, StataCorp, College Station, Texas, United States (US)), Microsoft Excel 2013, PowerPivot for Excel and R statistical software version 3.4.3 (R Foundation, Vienna, Austria; packages: “lubridate”, “ggplot2”, “foreign”, “multcomp”)."
lubridate;https://cran.r-project.org/package=lubridate,https://github.com/tidyverse/lubridate,https://github.com/cran/lubridate;https://cran.r-project.org/web/packages/lubridate/index.html,https://github.com/tidyverse/lubridate;10.1038/s41598-019-42288-6;3.1.1) with the R packages “raster” (v 2.5-2), “ncdf” (v 1.6.8), “rgdal” (v 1.1-6), “RNetCDF” (v 1.8-2), “lubridate” (v 1.5.3), “RODBC” (v 1.3–10) and “geosphere” (v 1.5–1)
lubridate;https://cran.r-project.org/package=lubridate,https://github.com/tidyverse/lubridate,https://github.com/cran/lubridate;https://cran.r-project.org/web/packages/lubridate/index.html,https://github.com/tidyverse/lubridate;10.1001/jamanetworkopen.2020.37227;All statistical analyses were performed with R Studio version 1.3.1073 and R versions 4.0.2 and 4.0.3 (R Project for Statistical Computing) with the following packages: Metrics, forecastHybrid, thief, forecast, cowplot, lubridate, forcats, stringr, dplyr, purrr, readr, tidyr, tibble, ggplot2, and tidyverse
MATLAB;;https://github.com/aludnam/MATLAB;10.1371/journal.pone.0158375;Figure created by the authors using prefecture boundary data from [18] and MATLAB software.
MATLAB;;https://github.com/aludnam/MATLAB;10.1038/srep11531;"Amplified waveforms were averaged in EEGLAB 6.0 (MATLAB toolbox, EEGLAB 6.0) by filtering the data with a digital finite impulse response filter (band-pass with 1–50?Hz); 180 epochs were averaged with a 1000?ms epoch and a 100?ms pre-epoch per f-VEP"
MATLAB;;https://github.com/aludnam/MATLAB;10.1128/JVI.02190-20;The statistical significance of the overlap between both methods was evaluated on MATLAB by running simulations of randomly distributed elements in both groups
MATLAB;;https://github.com/aludnam/MATLAB;10.1038/s41598-018-31591-3;MATLAB (The MathWorks, Natick, MA) functions then were used to extract the 3D volume corresponding to the positioned MRS voxel to obtain within-voxel gray matter (GM), white matter (WM) and cerebrospinal fluid (CSF) tissue content for each subject
MATLAB;;https://github.com/aludnam/MATLAB;10.1038/s41598-021-83398-4;Experimental data were modeled in MATLAB (The MathWorks) using a modified version of the Korhonen model of neonatal rat ventricular CMs (see Fig. 5, expanded methods, Supplementary Fig. 11 and Supplementary Tables 2–7 for model details)
matplotlib;https://pypi.org/project/matplotlib/,https://github.com/matplotlib/matplotlib;https://pypi.org/project/matplotlib,https://github.com/matplotlib/matplotlib;10.3389/fncir.2014.00005;Figures and data visualization were done using matplotlib (Hunter, 2007) and Inkscape (Andler et al., 2004–2014)
matplotlib;https://pypi.org/project/matplotlib/,https://github.com/matplotlib/matplotlib;https://pypi.org/project/matplotlib,https://github.com/matplotlib/matplotlib;10.1186/s13321-019-0351-x;Additionally, basic Python computing libraries employed include numpy [21, 22] and pandas [23, 24] (high-performance data structures and analysis), scikit-learn [25] (machine learning), as well as matplotlib [26] and seaborn [27] (plotting)
matplotlib;https://pypi.org/project/matplotlib/,https://github.com/matplotlib/matplotlib;https://pypi.org/project/matplotlib,https://github.com/matplotlib/matplotlib;10.3390/pharmaceutics12111071;The analysis was performed in Python, using numpy and matplotlib.
mvmeta;https://github.com/UCL/mvmeta;https://cran.r-project.org/web/packages/mvmeta/index.html;10.1016/j.mex.2020.100834;Stata code for fitting the model is presented in the Appendix using mvmeta which performs inferences based on either Maximum Likelihood (ML9), the Restricted Maximum Likelihood (REML10) or the multivariate method of moments (MM11), which is the method of choice due to its non-iterative nature [12].
mvmeta;https://github.com/UCL/mvmeta;https://cran.r-project.org/web/packages/mvmeta/index.html;10.7717/peerj.1461;"The network meta-analysis was conducted using STATA network package and mvmeta (Higgins et al., 2012; White, 2011) (The STATA .do file for HbA1 is presented in Supplementary Document—Statistical Analyses)"
mvmeta;https://github.com/UCL/mvmeta;https://cran.r-project.org/web/packages/mvmeta/index.html;10.1371/journal.pone.0243865;"A random-effects NMA based on a frequentist framework was performed using STATA software (version 15; StataCorp LP, College Station, TX) based on mvmeta with NMA graphical tools developed by Chaimani and colleagues [26]."
mvmeta;https://github.com/UCL/mvmeta;https://cran.r-project.org/web/packages/mvmeta/index.html;10.1186/s12872-019-1165-5;Network meta-analysis was conducted using the mvmeta software package in STATA14 software
mvmeta;https://cran.r-project.org/web/packages/mvmeta/index.html,https://github.com/gasparrini/mvmeta,https://github.com/cran/mmeta;https://cran.r-project.org/web/packages/mvmeta/index.html;10.1371/journal.pmed.1002617;All statistical analyses were performed with R software (version 3.4.3) using functions from the packages dlnm (first-stage regression) and mvmeta (second-stage meta-analysis).
numpy;https://pypi.org/project/numpy/,https://github.com/numpy/numpy;https://pypi.org/project/numpy,https://github.com/numpy/numpy;10.1371/journal.pone.0225900;In particular, indexing is possible via square brackets […] and mostly follows the conventions of numpy [45], the de facto standard for numerics in Python
numpy;https://pypi.org/project/numpy/,https://github.com/numpy/numpy;https://pypi.org/project/numpy,https://github.com/numpy/numpy;10.1371/journal.pone.0249624;Numerical arrays were stored using the numpy package [35]
numpy;https://pypi.org/project/numpy/,https://github.com/numpy/numpy;https://pypi.org/project/numpy,https://github.com/numpy/numpy;10.7717/peerj.2823;"Python packages used for analysis include numpy (Oliphant, 2007; Van der Walt, Colbert & Varoquaux, 2011), matplotlib (Hunter, 2007), sqlalchemy (Bayer, 2014), pandas (McKinney, 2010), macroecotools (Xiao et al., 2016), and retriever (Morris & White, 2013)"
pandas;https://github.com/pandas-dev/pandas,https://pypi.org/project/pandas/;https://pypi.org/project/pandas,https://github.com/pandas-dev/pandas;10.7717/peerj-cs.687;Step 2: Load data by using the pandas library
pandas;https://github.com/pandas-dev/pandas,https://pypi.org/project/pandas/;https://pypi.org/project/pandas,https://github.com/pandas-dev/pandas;10.1093/bib/bbab055;Other requirements: Bowtie (developed with 1.1.2), biopython (Python2-1.76, Python3-1.76 or higher), numpy (Python2-1.16-1.18, Python3-1.16 or higher), pandas (Python2-0.24.2, Python3-0.24.2 or higher)
pandas;https://github.com/pandas-dev/pandas,https://pypi.org/project/pandas/;https://pypi.org/project/pandas,https://github.com/pandas-dev/pandas;10.3390/s19061361;To do this, we used the programming language Python and five libraries: scipy, numpy, matplotlib, pandas, and sklearn.
plottools;;https://pypi.org/project/plottools,https://github.com/BrechtBa/plottools;10.1186/1752-0509-3-109;Data was retrieved from the UCSC DAS server using DASMiner API, and the plot can be easily prepared using plottools, a GUI tool to make graphics in Matlab (see file Fig4B_histonesPlots_CancervsNormal.fig in the examples folder of the distributed source code)
pycsa;https://pypi.org/project/pycsa/,https://github.com/structurely/csa;https://pypi.org/project/pycsa,https://github.com/structurely/csa;10.1371/journal.pone.0210177;To search globally optimal alignments, we used the CSA algorithm and it was implemented using pycsa [35]
pytorch;https://pypi.org/project/torch/,https://github.com/pytorch/pytorch;https://pypi.org/project/pytorch;10.3389/fnins.2020.00919;Further preprocessing can be directly applied using the utils python package provided, making the data readily available to exploit in popular python machine learning packages as pytorch and tensorflow.
pytorch;https://pypi.org/project/torch/,https://github.com/pytorch/pytorch;https://pypi.org/project/pytorch;10.3390/s20205762;All transformations can be implemented by pytorch and were performed during training on each data batch according to the mentioned probabilities
pytorch;https://pypi.org/project/torch/,https://github.com/pytorch/pytorch;https://pypi.org/project/pytorch;10.3390/s21061983;All the proposed method and models were implemented using pytorch and fastai [51]
readr;https://cran.r-project.org/package=readr,https://github.com/tidyverse/readr,https://github.com/cran/readr;https://cran.r-project.org/web/packages/readr/index.html,https://github.com/tidyverse/readr;10.1038/s42003-021-02366-w;Statistical analyses were performed with the R environment 4.02 v3.4.4: with DESeq2, readr, and tximport libraries loaded
readr;https://cran.r-project.org/package=readr,https://github.com/tidyverse/readr,https://github.com/cran/readr;https://cran.r-project.org/web/packages/readr/index.html,https://github.com/tidyverse/readr;10.7717/peerj.6486;The following packages were used: readr (Wickham et al., 2017), magrittr (Bache & Wickham, 2014), tidyverse (Wickham, 2017), and ggplot2 (Wickham, 2009).
readr;https://cran.r-project.org/package=readr,https://github.com/tidyverse/readr,https://github.com/cran/readr;https://cran.r-project.org/web/packages/readr/index.html,https://github.com/tidyverse/readr;10.1186/s12859-020-03922-7;The R packages required to install and run annoFuse are reshape2, dplyr, tidyr, ggplot2, qdapRegex, ggpubr, tibble, ggthemes, EnsDb.Hsapiens.v86, grid, readr, grDevices, stats, utils, stringr, shiny, shinydashboard, rintrojs, shinythemes, DT, rmarkdown, and methods, with the optional package: knitr
requests;https://pypi.org/project/requests/,https://github.com/psf/requests;https://pypi.org/project/requests,https://github.com/psf/requests;10.1186/s12911-020-1046-y;Project name: Prikbord Project home page:http://prikbord.science.ru.nl/Operating system: Linux Programming language: Python, javascript Other requirements: Django 1.5.11 or higher, MongoDB 2.6.10, pymongo 2.7.2 or higher, requests 2.13.0 or higher License: GNU GPL Any restrictions to use by non-academics: licence needed
requests;https://pypi.org/project/requests/,https://github.com/psf/requests;https://pypi.org/project/requests,https://github.com/psf/requests;10.3389/fvets.2021.674730;Using requests and BeautifulSoup packages in Python, all the PDF files with the titles containing “MRK” by avoiding cases sensitivity of uppercase or lowercase for each letter (e.g., “mRK,” “MrK,” “mrk,” etc.) from the years 2018, 2019, and 2020 were automatically collected and saved in a separate folder for further steps
requests;https://pypi.org/project/requests/,https://github.com/psf/requests;https://pypi.org/project/requests,https://github.com/psf/requests;10.1016/j.dib.2021.107360;We used the json and requests packages [35,36]to collect data and the scikit-learn package [37] to impute missing values
rmarkdown;https://cran.r-project.org/package=rmarkdown,https://github.com/rstudio/rmarkdown,https://github.com/cran/rmarkdown;https://cran.r-project.org/web/packages/rmarkdown/index.html,https://github.com/rstudio/rmarkdown;10.12688/f1000research.6379.2;The package includes R Markdown templates which are processed using rmarkdown and knitr to produce HTML or PDF reports
rmarkdown;https://cran.r-project.org/package=rmarkdown,https://github.com/rstudio/rmarkdown,https://github.com/cran/rmarkdown;https://cran.r-project.org/web/packages/rmarkdown/index.html,https://github.com/rstudio/rmarkdown;10.3389/fmolb.2021.635074;The final, user-friendly HTML reports were produced using R markdown packages rmarkdown 2.6, knitr 1.30 and kableExtra 1.3.1.
rmarkdown;https://cran.r-project.org/package=rmarkdown,https://github.com/rstudio/rmarkdown,https://github.com/cran/rmarkdown;https://cran.r-project.org/web/packages/rmarkdown/index.html,https://github.com/rstudio/rmarkdown;10.3390/genes12071044;The CircIMPACT tool is developed based on R [39] (R version 3.6.3 or later are recommended), which also depends on several R packages (knitr [40], rmarkdown [41], data.table [42], dplyr [43], tydyverse [44], Rtsne [45], kableExtra [46], sparkline, magrittr [47], caret [48])
SAM;https://cran.r-project.org/web/packages/samr/index.html,https://github.com/cran/samr,https://github.com/MikeJSeo/SAM;https://github.com/s-macke/SAM;10.1186/1471-2105-7-399;The accuracies of models using S2N or SAM (77.7%) were the second highest
SAM;;https://github.com/s-macke/SAM;10.15252/msb.156172;The orientation of the joins was obtained from the sequence arrangement in the paired-end libraries manifested in the SAM file bitwise FLAG
SAM;;https://github.com/s-macke/SAM;10.1038/s41598-020-60595-1;We set the cutoffs of FDR of the SAM and limma to 0.05 and 0.01, respectively.
SAM;https://cran.r-project.org/web/packages/samr/index.html,https://github.com/cran/samr,https://github.com/MikeJSeo/SAM;https://github.com/s-macke/SAM;10.1007/s40520-020-01646-5;Differentially expressed mRNAs were identified by ANOVA and by Significance analysis of microarrays (SAM)
scikit-learn;https://pypi.org/project/scikit-learn/,https://github.com/scikit-learn/scikit-learn;https://pypi.org/project/scikit-learn,https://github.com/scikit-learn/scikit-learn;10.3389/fmicb.2020.00383;We performed random forest classification using the implementation of this method in Python’s scikit-learn package
scikit-learn;https://pypi.org/project/scikit-learn/,https://github.com/scikit-learn/scikit-learn;https://pypi.org/project/scikit-learn,https://github.com/scikit-learn/scikit-learn;10.1186/s13073-021-00919-6;For taxonomic classification, a scikit-learn [44] naive Bayes classifier was created against the taxonomic classification from ARB-SILVA [45] 132 release (99% OTU data set), which was trained for the used primers
scikit-learn;https://pypi.org/project/scikit-learn/,https://github.com/scikit-learn/scikit-learn;https://pypi.org/project/scikit-learn,https://github.com/scikit-learn/scikit-learn;10.7554/eLife.46935;scikit-learn (Pedregosa et al., 2011).
shiny;https://cran.r-project.org/package=shiny,https://github.com/rstudio/shiny,https://github.com/cran/shiny;https://cran.r-project.org/web/packages/shiny/index.html;10.1186/s13104-019-4179-2;The current implementation depends on the following R packages: TCC, shiny, shinyBS, shinycssloaders, shinydashboard, shinyWidgets, plotly, dplyr, DT, heatmaply, tidyr, utils, rmarkdown, data.table, RColorBrewer, knitr, cluster, and MASS
shiny;https://cran.r-project.org/package=shiny,https://github.com/rstudio/shiny,https://github.com/cran/shiny;https://cran.r-project.org/web/packages/shiny/index.html;10.1186/s12859-019-3251-1;The input files for R shiny report should be transferred into the ‘data’ folder under the shiny app folder
shiny;https://cran.r-project.org/package=shiny,https://github.com/rstudio/shiny,https://github.com/cran/shiny;https://cran.r-project.org/web/packages/shiny/index.html;10.1371/journal.pone.0233282;We also created a shiny application [82] allowing for further visual exploration of the data by muscle, by condition, and by participant, in the 3D space formed by three (to be chosen) muscles
SPC;;https://github.com/Tcat1024/SPC;10.1002/acm2.12993;Treatment review with the guidance of a SPC tool allows for an objective and consistent clinical decision to apply adaptive radiotherapy.
SPC;https://cran.r-project.org/web/packages/spc/index.html,https://github.com/cran/spc;https://github.com/Tcat1024/SPC;10.1136/bmjqs-2018-009048;Control charts are the main analytical tool used in SPC.18 A control chart shows a time series of how the measure varies over time
SPC;https://cran.r-project.org/web/packages/spc/index.html,https://github.com/cran/spc;https://github.com/Tcat1024/SPC;10.3390/ijms22031320;Sparse principal component analysis (sPCA) was performed on the Log2 (fold change) values using SPC from the PMA package in R
SPC;;https://github.com/Tcat1024/SPC;10.3389/fnsys.2014.00006;"As well as comparing SPC (Blatt et al., 1996; Quiroga et al., 2004) with GAC on surrogate data (section Tests with Surrogate Data, Table 4) we tested it on our own data but found that it frequently was unable to separate distributions that were connected by narrow bridges of low density"
SPC;;https://github.com/Tcat1024/SPC;10.1208/s12248-019-0354-6;When ? is unknown, SPC software will, by default, estimate sigma by where is the average observed moving range and 2/???(?) is the expected value for the range between two values from a standard Normal Distribution
speedglm;https://cran.r-project.org/web/packages/speedglm/index.html,https://github.com/cran/speedglm;https://cran.r-project.org/web/packages/speedglm/index.html;10.1093/eurpub/ckx090;Analyses were done with R (version 3.0.2) and using the speedglm package.
speedglm;https://cran.r-project.org/web/packages/speedglm/index.html,https://github.com/cran/speedglm;https://cran.r-project.org/web/packages/speedglm/index.html;10.1001/jamanetworkopen.2021.5723;"Statistical analysis was performed using R software, version 3.5.0 (R Foundation for Statistical Computing) with the analysis packages epade, version 0.3.8; forestplot, version 1.7.2; rms, version 5.1-2; ggplot2, version 3.1.0; reshape2, version 1.4.3; and speedglm, version 0.3-2"
stringr;https://cran.r-project.org/package=stringr,https://github.com/tidyverse/stringr,https://github.com/cran/stringr;https://cran.r-project.org/web/packages/stringr/index.html,https://github.com/tidyverse/stringr;10.1128/AEM.01096-17;BMiner, a companion application for parsing, viewing, and analyzing multiple BTyper files in aggregate, was created with the following dependencies: R version 3.3.2 (92) and R packages shiny version 1.01 (93), ggplot2 version 2.2.1 (94), readr version 1.1.0 (95), stringr version 1.2.0 (96), vegan version 2.4-2 (97), plyr version 1.8.4 (98), dplyr version 0.5.0 (99), cluster version 2.0.6 (100), ggrepel version 0.6.5 (101), and magrittr version 1.5 (102)
stringr;https://cran.r-project.org/package=stringr,https://github.com/tidyverse/stringr,https://github.com/cran/stringr;https://cran.r-project.org/web/packages/stringr/index.html,https://github.com/tidyverse/stringr;10.1186/s12920-021-01079-7;R packages tidyverse and stringr were used for data analysis, and graphs were plotted using ggplot2
stringr;https://cran.r-project.org/package=stringr,https://github.com/tidyverse/stringr,https://github.com/cran/stringr;https://cran.r-project.org/web/packages/stringr/index.html,https://github.com/tidyverse/stringr;10.1186/s13148-020-0824-9;Quality control (QC) and all statistical analyses were performed using the R version 3.5.2 statistical analysis software, and the R-packages SWAN, missmethyl, minfi, limma, IlluminaHumanMethylation450kanno.ilmn12.hg19, IlluminaHumanMethylation450kmanifest, IlluminaHumanMethylationEPICmanifest, IlluminaHumanMethylationEPICanno.ilm10b2.hg19, bumphunter, RColorBrewer, matrixStats, minfiData, Gviz, DMRcate, and stringr.
tensorflow;https://pypi.org/project/tensorflow/,https://github.com/tensorflow/tensorflow;https://pypi.org/project/tensorflow;10.1186/s12880-021-00551-1;Other requirements: matplotlib, pytorch, fastai (v1.0.61), gif, tensorflow, altair, fastai2, pydicom, kornia, scikit-image, torchio.
tensorflow;https://pypi.org/project/tensorflow/,https://github.com/tensorflow/tensorflow;https://pypi.org/project/tensorflow;10.3389/fnins.2019.01321;The DL model was written in tensorflow 1.4 (Abadi et al., 2016) and the interprettensor library (https://github.com/VigneshSrinivasan10/interprettensor).
tensorflow;https://pypi.org/project/tensorflow/,https://github.com/tensorflow/tensorflow;https://pypi.org/project/tensorflow;10.1186/s40537-020-00387-6;With tensorflow version 1.14.0 and python version 3.7.4
thief;https://cran.r-project.org/web/packages/thief/index.html,https://github.com/robjhyndman/thief,https://github.com/cran/thief;https://cran.r-project.org/web/packages/thief/index.html,https://github.com/robjhyndman/thief;10.1001/jamanetworkopen.2020.37227;All statistical analyses were performed with R Studio version 1.3.1073 and R versions 4.0.2 and 4.0.3 (R Project for Statistical Computing) with the following packages: Metrics, forecastHybrid, thief, forecast, cowplot, lubridate, forcats, stringr, dplyr, purrr, readr, tidyr, tibble, ggplot2, and tidyverse
tidyr;https://cran.r-project.org/package=tidyr,https://github.com/tidyverse/tidyr,https://github.com/cran/tidyr;https://cran.r-project.org/web/packages/tidyr/index.html,https://github.com/tidyverse/tidyr;10.1007/s10389-021-01543-9;The following packages were used for data processing, analysis, and data visualisation: tidyverse (Wickham 2017), tidyr (Wickham and Henry 2019), pysch (Revelle 2018), MASS (Venables and Ripley 2002), and apaTables (Stanley 2018).
tidyr;https://cran.r-project.org/package=tidyr,https://github.com/tidyverse/tidyr,https://github.com/cran/tidyr;https://cran.r-project.org/web/packages/tidyr/index.html,https://github.com/tidyverse/tidyr;10.1186/s12920-019-0504-9;To reformat, summarize, and visualize the data, the following R packages were used: ggplot2, dplyr, tidyr, GenVisR, and reshape2
tidyr;https://cran.r-project.org/package=tidyr,https://github.com/tidyverse/tidyr,https://github.com/cran/tidyr;https://cran.r-project.org/web/packages/tidyr/index.html,https://github.com/tidyverse/tidyr;10.1186/s12974-021-02235-7;"Data visualization and statistical analyses were completed using R 3.6.2 (R Core Team, 2019) with the following packages: dplyr (v0.8.5 [64];), tidyr (v1.0.2 [65];), rstatix (v0.5.0 [66];), DescTools (v0.99.34 [67];), sjstats (v0.17.9 [68];), ReadqPCR and NormqPCR [62], ggplot2 [69], gridExtra (v2.3 [70];), pheatmap (v1.0.12 [71];), and viridis (v0.5.1 [72];)."
varSel;https://cran.r-project.org/web/packages/varSel/index.html,https://github.com/cran/varSel;https://cran.r-project.org/web/packages/varSel/index.html;10.1002/ece3.6786;Whereas these methods aim at identifying the best subset of the available variables, our implementations address different problems: varSel removes variables to reduce collinearity, and reduceVar removes variables that contribute least to the model to increase parsimony
vhica;https://cran.r-project.org/web/packages/vhica/index.html,https://github.com/cran/vhica,https://github.com/lerouzic/vhica;https://cran.r-project.org/web/packages/vhica/index.html;10.6026/97320630017479;"""The ENC values of the S, M, L segments of the CCHF virus were calculated in R Studio programming software, """"vhica"""" library [13]"""
WeBIAS;https://pypi.org/project/WeBIAS/,https://github.com/pawelld/webias;https://pypi.org/project/WeBIAS;10.1186/s13104-015-1622-x;Although these features make WeBIAS useful in complex environments, it can be very easily deployed on a single server
WeBIAS;https://pypi.org/project/WeBIAS/,https://github.com/pawelld/webias;https://pypi.org/project/WeBIAS;10.1186/s13321-020-0408-x;In efforts to facilitate easier dissemination of bioinformatic applications as web server, Daniluk et al. [278] introduced the WeBIAS platform, which is a self-contained solution that helps to make command-line programs accessible via web forms
WeBIAS;https://pypi.org/project/WeBIAS/,https://github.com/pawelld/webias;https://pypi.org/project/WeBIAS;10.1186/s13104-015-1622-x;WeBIAS manages its own user authentication and authorization
WeBIAS;https://pypi.org/project/WeBIAS/,https://github.com/pawelld/webias;https://pypi.org/project/WeBIAS;10.1186/s13104-015-1622-x;Nevertheless, they usually have a usable application, which can be easily adapted for WeBIAS.
WeBIAS;https://pypi.org/project/WeBIAS/,https://github.com/pawelld/webias;https://pypi.org/project/WeBIAS;10.1186/s13104-015-1622-x;WeBIAS uses its database to store these
