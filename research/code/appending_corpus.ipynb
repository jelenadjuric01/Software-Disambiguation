{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c163dafd",
   "metadata": {},
   "source": [
    "This notebook appends new corpuses that were sampled from CZI and then cleaned to the current one and saves it as a new version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bfb291ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8ac010f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_list(x):\n",
    "    \"\"\"Normalize a cell to a list of strings.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if pd.isna(x) or x == '':\n",
    "        return []\n",
    "    if isinstance(x, str):\n",
    "        return [u.strip() for u in x.split(',') if u.strip()]\n",
    "    return [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d1824dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_new_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Group & clean a new source DataFrame:\n",
    "      - Rename 'software_mention' → 'name'\n",
    "      - Build `candidate_urls` & `url (ground truth)` lists\n",
    "      - Group by (name, doi, paragraph) deduplicating URLs\n",
    "      - Rename back → 'software_mention', add 'annotator'\n",
    "    \"\"\"\n",
    "    # Rename for grouping\n",
    "    df.rename(columns={'software_mention': 'name'}, inplace=True)\n",
    "    # Ensure URL cols exist\n",
    "    url_cols = ['package_url']\n",
    "    for col in url_cols:\n",
    "        if col not in df.columns:\n",
    "            df[col] = ''\n",
    "    # Build lists\n",
    "    df['candidate_urls'] = df[url_cols].apply(\n",
    "        lambda row: [u.strip() for u in row if isinstance(u, str) and u.strip()],\n",
    "        axis=1\n",
    "    )\n",
    "    df['url (ground truth)'] = df.apply(\n",
    "        lambda row: [u.strip() for u in row[url_cols]\n",
    "                     if row.get('exact_match', False) and isinstance(u, str) and u.strip()],\n",
    "        axis=1\n",
    "    )\n",
    "    # Group & aggregate\n",
    "    grouped = df.groupby(['name', 'doi', 'paragraph'], as_index=False).agg({\n",
    "        'candidate_urls':       lambda lists: list(set(sum(lists, []))),\n",
    "        'url (ground truth)':   lambda lists: list(set(sum(lists, []))),\n",
    "        'authors_oa':           'first',\n",
    "        'authors':              'first',\n",
    "        'field/topic/keywords': 'first'\n",
    "    })\n",
    "    # Finalize\n",
    "    grouped['annotator'] = 'JelenaDuric'\n",
    "    return grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "318f660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_and_deduplicate(corpus_df: pd.DataFrame,\n",
    "                           new_grouped_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Append new grouped rows to corpus_df, normalize URL cells to lists,\n",
    "    then re-group on (software_mention, doi, paragraph) to de-dupe URLs,\n",
    "    preserve 'comments', then re-fill 'id' sequentially,\n",
    "    convert URL lists back to strings, and reorder columns.\n",
    "    \"\"\"\n",
    "    # Normalize URL lists\n",
    "    for col in ['candidate_urls', 'url (ground truth)']:\n",
    "        if col in corpus_df:\n",
    "            corpus_df[col] = corpus_df[col].apply(ensure_list)\n",
    "        new_grouped_df[col] = new_grouped_df[col].apply(ensure_list)\n",
    "\n",
    "    # Preserve any existing comments column, or create empty if missing\n",
    "    if 'comments' not in corpus_df.columns:\n",
    "        corpus_df['comments'] = ''\n",
    "    if 'comments' not in new_grouped_df.columns:\n",
    "        new_grouped_df['comments'] = ''\n",
    "\n",
    "    # Concatenate and dedupe\n",
    "    combined = pd.concat([corpus_df, new_grouped_df], ignore_index=True, sort=False)\n",
    "    deduped = combined.groupby(\n",
    "        ['name', 'doi', 'paragraph'], as_index=False\n",
    "    ).agg({\n",
    "        'authors_oa':           'first',\n",
    "        'authors':              'first',\n",
    "        'field/topic/keywords': 'first',\n",
    "        'url (ground truth)':   lambda lists: list(set(sum(lists, []))),\n",
    "        'annotator':            'first',\n",
    "        'comments':             'first',\n",
    "        'candidate_urls':       lambda lists: list(set(sum(lists, []))),\n",
    "    })\n",
    "\n",
    "    # Convert URL lists back to comma-separated strings\n",
    "    deduped['url (ground truth)'] = deduped['url (ground truth)'].apply(lambda lst: ','.join(lst))\n",
    "    deduped['candidate_urls']     = deduped['candidate_urls'].apply(lambda lst: ','.join(lst))\n",
    "\n",
    "    # Re-fill `id` sequentially\n",
    "    deduped.insert(0, 'id', range(1, len(deduped) + 1))\n",
    "\n",
    "    # Reorder columns exactly as requested\n",
    "    final_cols = [\n",
    "        'id',\n",
    "        'name',\n",
    "        'doi',\n",
    "        'paragraph',\n",
    "        'authors_oa',\n",
    "        'authors',\n",
    "        'field/topic/keywords',\n",
    "        'url (ground truth)',\n",
    "        'annotator',\n",
    "        'comments',\n",
    "        'candidate_urls'\n",
    "    ]\n",
    "    return deduped[final_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "48c7fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_corpus(corpus_df: pd.DataFrame,\n",
    "                  new_dfs: List[pd.DataFrame]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process multiple new DataFrames and merge into corpus_df:\n",
    "      1. preprocess_new_dataframe on each\n",
    "      2. concat all, then append_and_deduplicate\n",
    "      3. return updated DataFrame\n",
    "    \"\"\"\n",
    "    grouped_list = [preprocess_new_dataframe(df) for df in new_dfs]\n",
    "    all_new = pd.concat(grouped_list, ignore_index=True, sort=False)\n",
    "    return append_and_deduplicate(corpus_df, all_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ba519553",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_excel('../corpus_v1.xlsx')\n",
    "cran_top_10 = pd.read_csv('../cran_sampled_top_10.csv')\n",
    "cran = pd.read_csv('../cran_sampled.csv')\n",
    "pypi_top_10 = pd.read_csv('../pypi_sampled_top_10.csv')\n",
    "pypi = pd.read_csv('../pypi_sampled.csv')\n",
    "github = pd.read_csv('../github_sample_cleaned.csv', delimiter=';')\n",
    "new_df  = update_corpus(corpus, [cran_top_10,cran,pypi_top_10,pypi,github])\n",
    "new_df.to_excel('../corpus_v2.xlsx', index=False) \n",
    "# Save the final DataFrame to a CSV file\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
