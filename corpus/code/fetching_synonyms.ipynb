{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching synonyms from CZI and SoftwareKG dataset \n",
    "\n",
    "Considering that CZI has synonyms fetched from most used software websites (PyPi, CRAN, Bioconductor and SciCrunch) this notebook will for every software in the benchmark query the datasets and try to retrieve synonyms. \n",
    "\n",
    "First we save all unique software names (lowered) into a dictionary, the using a function get_synonyms_CIZ, we find all synonyms that have software_mention (lowered) the same as the key in the dictionary. Dictionary is used in order to speed up the process.\n",
    "\n",
    "Next, we query SoftwareKG graphs for synonyms (lowered). Again, the dictionary is used to speed up the process by querieng only once for the same name. This is done in get_synonyms_from_SoftwareKG function.\n",
    "\n",
    "CZI dataset was downloaded from https://datadryad.org/dataset/doi:10.5061/dryad.6wwpzgn2c#methods (disambiguated file).\n",
    "SoftwareKG SPARQL point: https://data.gesis.org/somesci/sparql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import json\n",
    "#Read files\n",
    "df = pd.read_csv(\"../CZI/synonyms_matrix.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df = pd.read_csv(\"../temp/v3.2/updated_with_metadata_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sparqlwrapper in c:\\users\\jelena\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: rdflib>=6.1.1 in c:\\users\\jelena\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sparqlwrapper) (7.0.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in c:\\users\\jelena\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rdflib>=6.1.1->sparqlwrapper) (0.6.1)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in c:\\users\\jelena\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rdflib>=6.1.1->sparqlwrapper) (3.1.4)\n",
      "Requirement already satisfied: six in c:\\users\\jelena\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from isodate<0.7.0,>=0.6.0->rdflib>=6.1.1->sparqlwrapper) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install sparqlwrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#check for null values and drop them\n",
    "#turning all names into strings\n",
    "print(df[\"software_mention\"].isnull().sum())\n",
    "df = df.dropna(subset=[\"software_mention\"])\n",
    "print(df[\"software_mention\"].isnull().sum())\n",
    "df['software_mention'] = df['software_mention'].astype(str)  # Convert all values to strings\n",
    "benchmark_df['name']=benchmark_df['name'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dictionary for the benchmark\n",
    "benchmark_dictonary = {name.lower(): set() for name in benchmark_df[\"name\"].unique()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that retirieves synonyms for each software mention\n",
    "def get_synonyms_from_CZI(df, dictionary):\n",
    "    for key in dictionary.keys():\n",
    "        if dictionary[key] != set():\n",
    "            continue\n",
    "        # Find matching rows in synonyms_df where the software mention matches the dictionary key\n",
    "        matches = df[df[\"software_mention\"].str.lower() == key][\"synonym\"].tolist()\n",
    "        # Store synonyms as a list\n",
    "        dictionary[key].update(matches)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "\n",
    "def get_synonyms_from_SoftwareKG(dictionary):\n",
    "    # Define the SPARQL endpoint\n",
    "    sparql = SPARQLWrapper(\"https://data.gesis.org/somesci/sparql\")\n",
    "    # Execute the query\n",
    "    for key in dictionary.keys():\n",
    "        if dictionary[key] != set():\n",
    "            continue\n",
    "        query = f\"\"\"\n",
    "    PREFIX nif: <http://persistence.uni-leipzig.org/nlp2rdf/ontologies/nif-core#>\n",
    "PREFIX sms: <http://data.gesis.org/somesci/>\n",
    "PREFIX its: <http://www.w3.org/2005/11/its/rdf#>\n",
    "\n",
    "SELECT DISTINCT ?synonym\n",
    "WHERE {{\n",
    "    # Find the software entity associated with the given spelling\n",
    "    ?sw_phrase a nif:Phrase ;\n",
    "               its:taClassRef [ rdfs:subClassOf sms:Software ] ;\n",
    "               its:taIdentRef ?sw_identity ;\n",
    "               nif:anchorOf \"{key}\" .  # Replace \"Excel\" with the desired software name\n",
    "\n",
    "    # Retrieve other spellings linked to the same software identity\n",
    "    ?other_phrase its:taIdentRef ?sw_identity ;\n",
    "                  nif:anchorOf ?synonym .\n",
    "    \n",
    "    FILTER (?synonym != \"{key}\")  # Exclude the original input spelling from results\n",
    "}}\n",
    "ORDER BY ?synonym\n",
    "    \"\"\"\n",
    "        try:\n",
    "            # Set query and return format\n",
    "            sparql.setQuery(query)\n",
    "            sparql.setReturnFormat(JSON)\n",
    "            results = sparql.query().convert()\n",
    "\n",
    "            # Process results\n",
    "            for result in results[\"results\"][\"bindings\"]:\n",
    "                synonym = result.get(\"synonym\", {}).get(\"value\")\n",
    "                if synonym:\n",
    "                    dictionary[key].add(synonym)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving synonyms for {key}: {e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms(dictionary, CZI = 1, SoftwareKG = 1):\n",
    "    if CZI == 1:\n",
    "        get_synonyms_from_CZI(df, dictionary)\n",
    "    if SoftwareKG == 1:\n",
    "        get_synonyms_from_SoftwareKG(dictionary)\n",
    "    dictionary = {key: list(value) for key, value in dictionary.items()}\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add synonyms column\n",
    "output_json_path = \"./synonym_dictionary.json\"\n",
    "if os.path.exists(output_json_path) and os.path.getsize(output_json_path) > 0:\n",
    "        with open(output_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                benchmark_dictonary = json.load(f)\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"⚠️ Warning: Could not decode existing JSON. Starting with empty cache.\")\n",
    "                benchmark_dictonary = {name.lower(): set() for name in benchmark_df[\"name\"].unique()}\n",
    "else:\n",
    "        benchmark_dictonary = {name.lower(): set() for name in benchmark_df[\"name\"].unique()}\n",
    "benchmark_dictonary= get_synonyms(benchmark_dictonary,1,1)\n",
    "# Save the updated dictionary to a JSON file\n",
    "with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(benchmark_dictonary, f, ensure_ascii=False, indent=4)\n",
    "#print(benchmark_dictonary)\n",
    "benchmark_df[\"synonyms\"] = (benchmark_df[\"name\"]\n",
    "    .str.lower()\n",
    "    .map(benchmark_dictonary)\n",
    "    .str.join(\",\")\n",
    ")\n",
    "\n",
    "# Save t\n",
    "benchmark_df.to_csv(\"../temp/v3.2/updated_with_metadata_file.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
