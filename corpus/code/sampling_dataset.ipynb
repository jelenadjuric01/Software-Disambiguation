{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b39f0cc1",
   "metadata": {},
   "source": [
    "This notebook will be used for sampling large dataset to get smaller one that will then be incorporated into the corpus, piece by piece. IDs will be chosen randomly and we can specify how much IDs we want. Then for each ID we fetch a few rows (we can specify how much) from preferably different papers. If there isn't enough different papers, some can be repeated, but the combination of the software mention (ID), doi and paragraph text in which the software is mentioned need to be unique. There is also an option to sample exact software mentions we ask for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d95030aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List,Optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba013862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1327602, 11)\n",
      "Index(['ID', 'software_mention', 'mapped_to', 'platform', 'package_url',\n",
      "       'homepage_url', 'other_urls', 'github_repo', 'exact_match', 'doi',\n",
      "       'paragraph'],\n",
      "      dtype='object')\n",
      "      ID software_mention mapped_to  platform                    package_url  \\\n",
      "0  SM900              XDS       XDS       NaN  https://github.com/ichfly/XDS   \n",
      "1  SM900              XDS       XDS       NaN  https://github.com/ichfly/XDS   \n",
      "2  SM900              XDS       XDS       NaN  https://github.com/ichfly/XDS   \n",
      "3  SM900              XDS       XDS       NaN  https://github.com/ichfly/XDS   \n",
      "4  SM900              XDS       XDS       NaN  https://github.com/ichfly/XDS   \n",
      "\n",
      "   homepage_url  other_urls                    github_repo  exact_match  \\\n",
      "0           NaN         NaN  https://github.com/ichfly/XDS         True   \n",
      "1           NaN         NaN  https://github.com/ichfly/XDS         True   \n",
      "2           NaN         NaN  https://github.com/ichfly/XDS         True   \n",
      "3           NaN         NaN  https://github.com/ichfly/XDS         True   \n",
      "4           NaN         NaN  https://github.com/ichfly/XDS         True   \n",
      "\n",
      "                           doi  \\\n",
      "0    10.1007/s13205-011-0037-1   \n",
      "1     10.1021/acscatal.0c05042   \n",
      "2   10.1021/acschembio.1c00411   \n",
      "3  10.1021/acsinfecdis.0c00819   \n",
      "4      10.1021/acsnano.0c09386   \n",
      "\n",
      "                                           paragraph  \n",
      "0  Other commonly used data-processing packages i...  \n",
      "1         All data were reduced and scaled using XDS  \n",
      "2  The data were processed using XDS with XDS-APP...  \n",
      "3  Data were processed using XDS or Dials and Aim...  \n",
      "4  Data were indexed and integrated using either ...  \n"
     ]
    }
   ],
   "source": [
    "github = pd.read_csv('D:/MASTER/TMF/Software-Disambiguation/corpus/github_from_CZI.csv')\n",
    "github = github[github['exact_match']]\n",
    "print(github.shape)\n",
    "print(github.columns)\n",
    "print(github.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f51da3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_ids(df: pd.DataFrame, num_ids: int, seed: int = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Sample `num_ids` unique IDs at random from df.ID.\n",
    "    \"\"\"\n",
    "    uniq_ids = df['ID'].unique()\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    return np.random.choice(uniq_ids, size=num_ids, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1836d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_ids_by_software(df: pd.DataFrame, software_names: List[str]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return the unique IDs from df where the 'software_mention' column\n",
    "    matches any of the names in software_names.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing at least the columns 'ID' and 'software_mention'.\n",
    "    software_names : List[str]\n",
    "        List of software names to look up in df['software_mention'].\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Array of unique IDs corresponding to the given software names.\n",
    "        If none match, returns an empty array.\n",
    "    \"\"\"\n",
    "    # Filter rows where software_mention is in the provided list\n",
    "    mask = df['software_mention'].isin(software_names)\n",
    "    \n",
    "    # Extract unique IDs\n",
    "    uniq_ids = df.loc[mask, 'ID'].unique()\n",
    "    \n",
    "    return uniq_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c13db72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_for_id(group: pd.DataFrame, n_per_id: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For a single-ID group:\n",
    "      - If there are >= n_per_id distinct DOIs, pick one row per DOI up to n_per_id.\n",
    "      - Otherwise, take one per DOI and then fill up to n_per_id by sampling additional rows.\n",
    "    Returns a DataFrame of up to n_per_id unique rows.\n",
    "    \"\"\"\n",
    "    unique_dois = group['doi'].unique()\n",
    "    picks = []\n",
    "\n",
    "    if len(unique_dois) >= n_per_id:\n",
    "        chosen = np.random.choice(unique_dois, size=n_per_id, replace=False)\n",
    "        for doi in chosen:\n",
    "            picks.append(group[group['doi'] == doi].sample(1))\n",
    "    else:\n",
    "        # one row per DOI\n",
    "        for doi in unique_dois:\n",
    "            picks.append(group[group['doi'] == doi].sample(1))\n",
    "        # fill up the rest\n",
    "        needed = n_per_id - len(unique_dois)\n",
    "        remaining = group.drop(pd.concat(picks).index)\n",
    "        if needed > 0 and len(remaining) > 0:\n",
    "            picks.append(remaining.sample(min(needed, len(remaining))))\n",
    "\n",
    "    return pd.concat(picks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e22edc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(\n",
    "    df: pd.DataFrame,\n",
    "    num_ids: int = 100,\n",
    "    n_per_id: int = 5,\n",
    "    seed: Optional[int] = None,\n",
    "    software_names: Optional[List[str]] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Orchestrate the sampling:\n",
    "      1. If `software_names` is a non-empty list, pick IDs for those software via get_ids_by_software.\n",
    "         Otherwise sample `num_ids` IDs at random via get_random_ids.\n",
    "      2. For each ID, sample up to `n_per_id` rows via sample_for_id.\n",
    "      3. Return the concatenated sample.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain columns 'ID' and 'software_mention'.\n",
    "    num_ids : int\n",
    "        How many IDs to randomly sample if `software_names` is empty.\n",
    "    n_per_id : int\n",
    "        How many rows to sample per ID.\n",
    "    seed : int or None\n",
    "        Random seed for reproducibility (only used when sampling randomly).\n",
    "    software_names : list of str, optional\n",
    "        If provided and non-empty, select IDs for these software names instead of random.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Sampled subset of `df`.\n",
    "    \"\"\"\n",
    "    # 1. choose IDs\n",
    "    if software_names:\n",
    "        # use the list of software names to pick IDs\n",
    "        selected_ids = get_ids_by_software(df, software_names)\n",
    "    else:\n",
    "        # fall back to random sampling\n",
    "        selected_ids = get_random_ids(df, num_ids, seed)\n",
    "\n",
    "    # 2. filter and sample\n",
    "    sub = df[df['ID'].isin(selected_ids)]\n",
    "    sampled = (\n",
    "        sub\n",
    "        .groupby('ID', group_keys=False)\n",
    "        .apply(sample_for_id, n_per_id=n_per_id)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return sampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaaf0247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jelena\\AppData\\Local\\Temp\\ipykernel_1064\\2785038069.py:46: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(sample_for_id, n_per_id=n_per_id)\n"
     ]
    }
   ],
   "source": [
    "github_sampled = sample_data(github, num_ids=10, n_per_id=5, seed=52)\n",
    "github_sampled.to_csv('D:/MASTER/TMF/Software-Disambiguation/corpus/github_sampled_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4becafd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(292233, 11)\n",
      "Index(['ID', 'software_mention', 'mapped_to', 'platform', 'package_url',\n",
      "       'homepage_url', 'other_urls', 'github_repo', 'exact_match', 'doi',\n",
      "       'paragraph'],\n",
      "      dtype='object')\n",
      "       ID software_mention mapped_to platform                 package_url  \\\n",
      "0  SM5081                0         0     Pypi  https://pypi.org/project/0   \n",
      "1  SM5081                0         0     Pypi  https://pypi.org/project/0   \n",
      "2  SM5081                0         0     Pypi  https://pypi.org/project/0   \n",
      "3  SM5081                0         0     Pypi  https://pypi.org/project/0   \n",
      "4  SM5081                0         0     Pypi  https://pypi.org/project/0   \n",
      "\n",
      "  homepage_url  other_urls github_repo  exact_match  \\\n",
      "0       [None]         NaN      [None]         True   \n",
      "1       [None]         NaN      [None]         True   \n",
      "2       [None]         NaN      [None]         True   \n",
      "3       [None]         NaN      [None]         True   \n",
      "4       [None]         NaN      [None]         True   \n",
      "\n",
      "                            doi  \\\n",
      "0  10.3934/microbiol.2019.4.308   \n",
      "1    10.1186/s13568-021-01212-w   \n",
      "2     10.1107/S0907444913017800   \n",
      "3    10.1186/s40478-021-01166-x   \n",
      "4           10.1155/2014/501841   \n",
      "\n",
      "                                           paragraph  \n",
      "0  The data generated from this study were analyz...  \n",
      "1  GATA protein sequences were aligned using Clus...  \n",
      "2  The presence of signal sequence and transmembr...  \n",
      "3  We characterized the gait of MBP29-hÎ±-syn mice...  \n",
      "4  Information on amino acid preferences and geom...  \n"
     ]
    }
   ],
   "source": [
    "pypi = pd.read_csv('D:/MASTER/TMF/Software-Disambiguation/corpus/pypi_from_CZI.csv')\n",
    "#pypi = pypi[pypi['exact_match']]\n",
    "print(pypi.shape)\n",
    "print(pypi.columns)\n",
    "print(pypi.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc020cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356373, 10)\n",
      "Index(['ID', 'software_mention', 'mapped_to', 'package_url', 'homepage_url',\n",
      "       'other_urls', 'github_repo', 'exact_match', 'doi', 'paragraph'],\n",
      "      dtype='object')\n",
      "        ID software_mention mapped_to  \\\n",
      "0  SM26805               A3        A3   \n",
      "1  SM26805               A3        A3   \n",
      "2  SM26805               A3        A3   \n",
      "3  SM26805               A3        A3   \n",
      "4  SM26805               A3        A3   \n",
      "\n",
      "                                         package_url homepage_url  other_urls  \\\n",
      "0  https://cran.r-project.org/web/packages/A3/ind...       [None]         NaN   \n",
      "1  https://cran.r-project.org/web/packages/A3/ind...       [None]         NaN   \n",
      "2  https://cran.r-project.org/web/packages/A3/ind...       [None]         NaN   \n",
      "3  https://cran.r-project.org/web/packages/A3/ind...       [None]         NaN   \n",
      "4  https://cran.r-project.org/web/packages/A3/ind...       [None]         NaN   \n",
      "\n",
      "  github_repo  exact_match                        doi  \\\n",
      "0         NaN         True    10.4102/phcfm.v8i1.1084   \n",
      "1         NaN         True   10.1186/1472-6947-12-150   \n",
      "2         NaN         True   10.1186/1472-6947-12-150   \n",
      "3         NaN         True   10.1186/1472-6947-12-150   \n",
      "4         NaN         True  10.1186/s40168-018-0526-0   \n",
      "\n",
      "                                           paragraph  \n",
      "0  The 5-why analysis and the A3 tool were used f...  \n",
      "1  As described earlier, VSM needs to be compleme...  \n",
      "2  This study was performed to assess the feasibi...  \n",
      "3  However, the study has achieved its purpose in...  \n",
      "4  Significance of the models and cross-validated...  \n"
     ]
    }
   ],
   "source": [
    "cran = pd.read_csv(\"D:/MASTER/TMF/Software-Disambiguation/corpus/cran_from_CZI.csv\")\n",
    "cran = cran[cran['exact_match']]\n",
    "print(cran.shape)\n",
    "print(cran.columns)\n",
    "print(cran.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e26c90eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jelena\\AppData\\Local\\Temp\\ipykernel_1064\\2785038069.py:46: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(sample_for_id, n_per_id=n_per_id)\n"
     ]
    }
   ],
   "source": [
    "pypi_sampled = sample_data(pypi, num_ids=10, n_per_id=5, seed=52)\n",
    "pypi_sampled.to_csv('D:/MASTER/TMF/Software-Disambiguation/corpus/pypi_sampled_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3d105d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jelena\\AppData\\Local\\Temp\\ipykernel_3168\\2785038069.py:46: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(sample_for_id, n_per_id=n_per_id)\n"
     ]
    }
   ],
   "source": [
    "pypi_sampled_top_10 = sample_data(pypi,\n",
    "    n_per_id=10,\n",
    "    software_names=[\"numpy\", \"tensorflow\", \"scikit-learn\", \"pandas\", \"matplotlib\",\"requests\",\n",
    "    \"beautifulsoup4\", \"flask\", \"django\", \"pytorch\",\"beautifulsoup\", \"flask\", \"django\",\"BeautifulSoup4\", \"Flask\", \"Django\",\"BeautifulSoup\", \"Beautiful Soup\"]\n",
    ")\n",
    "pypi_sampled_top_10.to_csv('D:/MASTER/TMF/Software-Disambiguation/corpus/pypi_sampled_top_10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f865cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jelena\\AppData\\Local\\Temp\\ipykernel_1064\\2785038069.py:46: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(sample_for_id, n_per_id=n_per_id)\n"
     ]
    }
   ],
   "source": [
    "cran_sampled = sample_data(cran, num_ids=10, n_per_id=5, seed=52)\n",
    "cran_sampled.to_csv('D:/MASTER/TMF/Software-Disambiguation/corpus/cran_sampled_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0de6c446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jelena\\AppData\\Local\\Temp\\ipykernel_3168\\2785038069.py:46: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(sample_for_id, n_per_id=n_per_id)\n"
     ]
    }
   ],
   "source": [
    "cran_sampled_top_10 = sample_data(cran,\n",
    "    n_per_id=10,\n",
    "    software_names=[\"ggplot2\", \"dplyr\", \"data.table\", \"tidyr\", \"readr\",\"stringr\",\n",
    "    \"lubridate\", \"shiny\", \"rmarkdown\", \"knitr\"]\n",
    ")\n",
    "cran_sampled_top_10.to_csv('D:/MASTER/TMF/Software-Disambiguation/corpus/cran_sampled_top_10.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
