{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b39f0cc1",
   "metadata": {},
   "source": [
    "This notebook will be used for sampling large dataset to get smaller one that will then be incorporated into the corpus, piece by piece. IDs will be chosen randomly and we can specify how much IDs we want. Then for each ID we fetch a few rows (we can specify how much) from preferably different papers. If there isn't enough different papers, some can be repeated, but the combination of the software mention (ID), doi and paragraph text in which the software is mentioned need to be unique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d95030aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba013862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1327602, 11)\n",
      "Index(['ID', 'software_mention', 'mapped_to', 'platform', 'package_url',\n",
      "       'homepage_url', 'other_urls', 'github_repo', 'exact_match', 'doi',\n",
      "       'paragraph'],\n",
      "      dtype='object')\n",
      "      ID software_mention mapped_to  platform                    package_url  \\\n",
      "0  SM900              XDS       XDS       NaN  https://github.com/ichfly/XDS   \n",
      "1  SM900              XDS       XDS       NaN  https://github.com/ichfly/XDS   \n",
      "2  SM900              XDS       XDS       NaN  https://github.com/ichfly/XDS   \n",
      "3  SM900              XDS       XDS       NaN  https://github.com/ichfly/XDS   \n",
      "4  SM900              XDS       XDS       NaN  https://github.com/ichfly/XDS   \n",
      "\n",
      "   homepage_url  other_urls                    github_repo  exact_match  \\\n",
      "0           NaN         NaN  https://github.com/ichfly/XDS         True   \n",
      "1           NaN         NaN  https://github.com/ichfly/XDS         True   \n",
      "2           NaN         NaN  https://github.com/ichfly/XDS         True   \n",
      "3           NaN         NaN  https://github.com/ichfly/XDS         True   \n",
      "4           NaN         NaN  https://github.com/ichfly/XDS         True   \n",
      "\n",
      "                           doi  \\\n",
      "0    10.1007/s13205-011-0037-1   \n",
      "1     10.1021/acscatal.0c05042   \n",
      "2   10.1021/acschembio.1c00411   \n",
      "3  10.1021/acsinfecdis.0c00819   \n",
      "4      10.1021/acsnano.0c09386   \n",
      "\n",
      "                                           paragraph  \n",
      "0  Other commonly used data-processing packages i...  \n",
      "1         All data were reduced and scaled using XDS  \n",
      "2  The data were processed using XDS with XDS-APP...  \n",
      "3  Data were processed using XDS or Dials and Aim...  \n",
      "4  Data were indexed and integrated using either ...  \n"
     ]
    }
   ],
   "source": [
    "github = pd.read_csv('D:/MASTER/TMF/Software-Disambiguation/corpus/github_from_CZI.csv')\n",
    "github = github[github['exact_match']]\n",
    "print(github.shape)\n",
    "print(github.columns)\n",
    "print(github.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f51da3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_ids(df: pd.DataFrame, num_ids: int, seed: int = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Sample `num_ids` unique IDs at random from df.ID.\n",
    "    \"\"\"\n",
    "    uniq_ids = df['ID'].unique()\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    return np.random.choice(uniq_ids, size=num_ids, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c13db72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_for_id(group: pd.DataFrame, n_per_id: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For a single-ID group:\n",
    "      - If there are >= n_per_id distinct DOIs, pick one row per DOI up to n_per_id.\n",
    "      - Otherwise, take one per DOI and then fill up to n_per_id by sampling additional rows.\n",
    "    Returns a DataFrame of up to n_per_id unique rows.\n",
    "    \"\"\"\n",
    "    unique_dois = group['doi'].unique()\n",
    "    picks = []\n",
    "\n",
    "    if len(unique_dois) >= n_per_id:\n",
    "        chosen = np.random.choice(unique_dois, size=n_per_id, replace=False)\n",
    "        for doi in chosen:\n",
    "            picks.append(group[group['doi'] == doi].sample(1))\n",
    "    else:\n",
    "        # one row per DOI\n",
    "        for doi in unique_dois:\n",
    "            picks.append(group[group['doi'] == doi].sample(1))\n",
    "        # fill up the rest\n",
    "        needed = n_per_id - len(unique_dois)\n",
    "        remaining = group.drop(pd.concat(picks).index)\n",
    "        if needed > 0 and len(remaining) > 0:\n",
    "            picks.append(remaining.sample(min(needed, len(remaining))))\n",
    "\n",
    "    return pd.concat(picks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e22edc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(df: pd.DataFrame,\n",
    "                num_ids: int = 100,\n",
    "                n_per_id: int = 5,\n",
    "                seed: int = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Orchestrate the sampling:\n",
    "      1. Pick `num_ids` random IDs.\n",
    "      2. For each ID, sample up to `n_per_id` rows via sample_for_id.\n",
    "      3. Return the concatenated sample.\n",
    "    \"\"\"\n",
    "    # 1. choose IDs\n",
    "    selected_ids = get_random_ids(df, num_ids, seed)\n",
    "    # 2. filter and sample\n",
    "    sub = df[df['ID'].isin(selected_ids)]\n",
    "    sampled = (\n",
    "        sub\n",
    "        .groupby('ID', group_keys=False)\n",
    "        .apply(sample_for_id, n_per_id=n_per_id)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return sampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eaaf0247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jelena\\AppData\\Local\\Temp\\ipykernel_16132\\56750381.py:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(sample_for_id, n_per_id=n_per_id)\n"
     ]
    }
   ],
   "source": [
    "github_sampled = sample_data(github, num_ids=100, n_per_id=5, seed=42)\n",
    "github_sampled.to_csv('D:/MASTER/TMF/Software-Disambiguation/corpus/github_sampled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4becafd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(292233, 11)\n",
      "Index(['ID', 'software_mention', 'mapped_to', 'platform', 'package_url',\n",
      "       'homepage_url', 'other_urls', 'github_repo', 'exact_match', 'doi',\n",
      "       'paragraph'],\n",
      "      dtype='object')\n",
      "       ID software_mention mapped_to platform                 package_url  \\\n",
      "0  SM5081                0         0     Pypi  https://pypi.org/project/0   \n",
      "1  SM5081                0         0     Pypi  https://pypi.org/project/0   \n",
      "2  SM5081                0         0     Pypi  https://pypi.org/project/0   \n",
      "3  SM5081                0         0     Pypi  https://pypi.org/project/0   \n",
      "4  SM5081                0         0     Pypi  https://pypi.org/project/0   \n",
      "\n",
      "  homepage_url  other_urls github_repo  exact_match  \\\n",
      "0       [None]         NaN      [None]         True   \n",
      "1       [None]         NaN      [None]         True   \n",
      "2       [None]         NaN      [None]         True   \n",
      "3       [None]         NaN      [None]         True   \n",
      "4       [None]         NaN      [None]         True   \n",
      "\n",
      "                            doi  \\\n",
      "0  10.3934/microbiol.2019.4.308   \n",
      "1    10.1186/s13568-021-01212-w   \n",
      "2     10.1107/S0907444913017800   \n",
      "3    10.1186/s40478-021-01166-x   \n",
      "4           10.1155/2014/501841   \n",
      "\n",
      "                                           paragraph  \n",
      "0  The data generated from this study were analyz...  \n",
      "1  GATA protein sequences were aligned using Clus...  \n",
      "2  The presence of signal sequence and transmembr...  \n",
      "3  We characterized the gait of MBP29-hÎ±-syn mice...  \n",
      "4  Information on amino acid preferences and geom...  \n"
     ]
    }
   ],
   "source": [
    "pypi = pd.read_csv('D:/MASTER/TMF/Software-Disambiguation/corpus/pypi_from_CZI.csv')\n",
    "pypi = pypi[pypi['exact_match']]\n",
    "print(pypi.shape)\n",
    "print(pypi.columns)\n",
    "print(pypi.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e26c90eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jelena\\AppData\\Local\\Temp\\ipykernel_16132\\56750381.py:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(sample_for_id, n_per_id=n_per_id)\n"
     ]
    }
   ],
   "source": [
    "pypi_sampled = sample_data(pypi, num_ids=100, n_per_id=5, seed=42)\n",
    "pypi_sampled.to_csv('D:/MASTER/TMF/Software-Disambiguation/corpus/pypi_sampled.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
