ID;software_mention;package_url;homepage_url;github_repo;exact_match;doi;paragraph
SM1000082;pytplot;https://pypi.org/project/pytplot,https://github.com/MAVENSDC/pytplot;['https://github.com/MAVENSDC/pytplot'];['https://github.com/MAVENSDC/pytplot'];TRUE;10.1007/s11214-018-0576-4;Under the PySPEDAS structure, “*_load_xxx” routines have been developed to access CDF files and import data to populate pytplot variables in a generic way
SM1003436;strand;https://cran.r-project.org/package=strand,https://github.com/strand-tech/strand;;;TRUE;10.1002/sim.8065;Only the data are required, a choice of gates and an indication of the amount of data to be apportioned as pilot data, to implement the essential form of the STRAND Chart using the R package “strand” (available from the author).
SM1003436;strand;https://pypi.org/project/strand,https://github.com/i2mint/strand;https://github.com/i2mint/strand;['https://github.com/i2mint/strand'];FALSE;10.1002/sim.8065;Only the data are required, a choice of gates and an indication of the amount of data to be apportioned as pilot data, to implement the essential form of the STRAND Chart using the R package “strand” (available from the author).
SM1007307;swirl;https://cran.r-project.org/package=swirl,https://swirlstats.com/;;;TRUE;10.1111/test.12258;The swirl R package aims to teach R programming and data science interactively and directly from within the R console
SM1007307;swirl;https://pypi.org/project/swirl,http://code.naeseth.com/swirl/;http://code.naeseth.com/swirl/;;FALSE;10.1111/test.12258;The swirl R package aims to teach R programming and data science interactively and directly from within the R console
SM107466;TreeToReads;https://pypi.org/project/TreeToReads,https://github.com/snacktavish/TreeToReads;['https://github.com/snacktavish/TreeToReads'];;TRUE;10.1186/s12859-017-1592-1;TreeToReads allows researchers to test the joint effects of multiple parameter values on the ability of any analysis pipeline to recover the signal and infer the correct tree
SM107466;TreeToReads;https://pypi.org/project/TreeToReads,https://github.com/snacktavish/TreeToReads;['https://github.com/snacktavish/TreeToReads'];;TRUE;10.1099/mgen.0.000261;Considering that TreeToReads does not simulate SVs, this result indicates that real, complex variants between the reference and root sequence used in the first benchmark surely caused many false-positive SNP calls and enabled realistic evaluation of the accuracy.
SM107466;TreeToReads;https://pypi.org/project/TreeToReads,https://github.com/snacktavish/TreeToReads;['https://github.com/snacktavish/TreeToReads'];;TRUE;10.7717/peerj.3893;The simulated dataset was created using the TreeToReads v 0.0.5 (McTavish et al., 2017), which takes as input a tree file (true phylogeny), an anchor genome, and a set of user-defined parameter values
SM107466;TreeToReads;https://pypi.org/project/TreeToReads,https://github.com/snacktavish/TreeToReads;['https://github.com/snacktavish/TreeToReads'];;TRUE;10.1186/s12859-017-1592-1;Anchoring an observed genome to a tip in a tree using TreeToReads allows us to test choices about selection of reference genomes in a way that is directly comparable to empirical data
SM107466;TreeToReads;https://pypi.org/project/TreeToReads,https://github.com/snacktavish/TreeToReads;['https://github.com/snacktavish/TreeToReads'];;TRUE;10.1186/s12859-017-1592-1;If ART is invoked in TreeToReads the program will output a folder labeled ‘fastq’ containing directories labeled with the names of each tip from the simulation tree, in which the simulated reads are deposited in.fastq.gz formats
SM1077143;kontroller;https://pypi.org/project/kontroller,https://github.com/caruccio/kontroller;;;FALSE;10.7554/eLife.27670;Using kontroller to automate the process, we performed a direct search on hardware to find the best distribution of control signals that was closest to the desired Gaussian distribution
SM1077143;kontroller;https://github.com/emonetlab/kontroller;;;TRUE;10.7554/eLife.27670;Using kontroller to automate the process, we performed a direct search on hardware to find the best distribution of control signals that was closest to the desired Gaussian distribution
SM1077143;kontroller;https://pypi.org/project/kontroller,https://github.com/caruccio/kontroller;;;FALSE;10.7554/eLife.27670;We wrote a general-purpose acquisition and control system called kontroller (available at https://github.com/emonetlab/kontroller) in MATLAB (Mathworks, Inc.) to control MFCs, valves and LEDs and to collect data from electrophysiology and the stimulus measurement.
SM1077143;kontroller;https://github.com/emonetlab/kontroller;;;TRUE;10.7554/eLife.27670;We wrote a general-purpose acquisition and control system called kontroller (available at https://github.com/emonetlab/kontroller) in MATLAB (Mathworks, Inc.) to control MFCs, valves and LEDs and to collect data from electrophysiology and the stimulus measurement.
SM146580;biopy;https://pypi.org/project/biopy,https://github.com/BioPyTeam/biopy;;;FALSE;10.1186/1471-2148-12-23;Tree files were summarized in biopy v0.1.2 [104], the posterior was resampled, and the variance among 100 random resampled species trees was visualized in DensiTree [105]
SM146580;biopy;https://pypi.org/project/biopy,https://github.com/BioPyTeam/biopy;;;FALSE;10.1186/1471-2148-13-221;The methods are implemented in biopy [9], and integrated with DensiTree, making it easy to examine the summary tree in the context of the full posterior.
SM146580;biopy;https://github.com/jheled/biopy;;;TRUE;10.1186/1471-2148-12-23;Tree files were summarized in biopy v0.1.2 [104], the posterior was resampled, and the variance among 100 random resampled species trees was visualized in DensiTree [105]
SM146580;biopy;https://github.com/jheled/biopy;;;TRUE;10.1186/1471-2148-13-221;The methods are implemented in biopy [9], and integrated with DensiTree, making it easy to examine the summary tree in the context of the full posterior.
SM146580;biopy;https://github.com/jheled/biopy;;;TRUE;10.1093/molbev/msx126;Simulated trees were generated using biopy, and trees sampled from a prior distribution were generated using StarBEAST2 with all new features enabled
SM146580;biopy;https://github.com/jheled/biopy;;;TRUE;10.1093/sysbio/syv118;Sequence alignments were also simulated using biopy for experiments 1 and 2, and Seq-Gen (Rambaut and Grass 1997) was used to simulate nucleotide alignments for experiment 3.
SM146580;biopy;https://pypi.org/project/biopy,https://github.com/BioPyTeam/biopy;;;FALSE;10.1093/molbev/msx126;Simulated trees were generated using biopy, and trees sampled from a prior distribution were generated using StarBEAST2 with all new features enabled
SM146580;biopy;https://pypi.org/project/biopy,https://github.com/BioPyTeam/biopy;;;FALSE;10.1093/sysbio/syv118;Sequence alignments were also simulated using biopy for experiments 1 and 2, and Seq-Gen (Rambaut and Grass 1997) was used to simulate nucleotide alignments for experiment 3.
SM146580;biopy;https://pypi.org/project/biopy,https://github.com/BioPyTeam/biopy;;;FALSE;10.1093/molbev/msx126;For all simulations, the version of biopy (Heled, unpublished data) used was 0.1.9
SM146580;biopy;https://github.com/jheled/biopy;;;TRUE;10.1093/molbev/msx126;For all simulations, the version of biopy (Heled, unpublished data) used was 0.1.9
SM16201;X!tandem;https://pypi.org/project/tandem,https://github.com/philippeller/dragoman;;;FALSE;10.1186/1471-2105-12-439;The results on elution peak identification coverage using MaxQuant and X!tandem are summarized in Table 4
SM16201;X!tandem;https://pypi.org/project/tandem,https://github.com/philippeller/dragoman;;;FALSE;10.1371/journal.pgen.1006909;Protein identification was performed with X!Tandem software (DB: X!tandem version 2013.09.01.1) against a protein database of B
SM16201;X!tandem;https://www.thegpm.org/tandem/;;;TRUE;10.1186/1471-2105-12-439;The results on elution peak identification coverage using MaxQuant and X!tandem are summarized in Table 4
SM16201;X!tandem;https://www.thegpm.org/tandem/;;;TRUE;10.1371/journal.pgen.1006909;Protein identification was performed with X!Tandem software (DB: X!tandem version 2013.09.01.1) against a protein database of B
SM16201;tandem;https://tandem.bu.edu/trf/trf.html,https://github.com/Benson-Genomics-Lab/TRF;;;TRUE;10.1186/s12864-021-07626-x;Furthermore, tandem repeat Finder version 4.07 [88], with default settings, was used to calculate tandem repeats in these cp genomes.
SM16201;tandem;https://tandem.bu.edu/trf/trf.html,https://github.com/Benson-Genomics-Lab/TRF;;;TRUE;10.1128/genomeA.01271-17;The obtained data were assembled de novo using the Hierarchical Genome Assembly Process (HGAP version 3.0) and annotated with Prodigal version 2.50 (2), tandem repeats finder software (3), tRNAscan-SE (4), and RNAmmer (5)
SM16201;tandem;https://tandem.bu.edu/trf/trf.html,https://github.com/Benson-Genomics-Lab/TRF;;;TRUE;10.1186/s12864-015-2324-4;The identification of tandem repeat sequences was performed with the software tandem repeats finder [34] using the whole-genome sequence of all W
SM16201;tandem;https://pypi.org/project/tandem,https://github.com/philippeller/dragoman;;;FALSE;10.1186/s12864-021-07626-x;Furthermore, tandem repeat Finder version 4.07 [88], with default settings, was used to calculate tandem repeats in these cp genomes.
SM16201;tandem;https://pypi.org/project/tandem,https://github.com/philippeller/dragoman;;;FALSE;10.1128/genomeA.01271-17;The obtained data were assembled de novo using the Hierarchical Genome Assembly Process (HGAP version 3.0) and annotated with Prodigal version 2.50 (2), tandem repeats finder software (3), tRNAscan-SE (4), and RNAmmer (5)
SM16201;tandem;https://pypi.org/project/tandem,https://github.com/philippeller/dragoman;;;FALSE;10.1186/s12864-015-2324-4;The identification of tandem repeat sequences was performed with the software tandem repeats finder [34] using the whole-genome sequence of all W
SM167372;ci;https://pypi.org/project/ci;['https://github.com/rossmacarthur/python-ci'];['https://github.com/rossmacarthur/python-ci'];TRUE;10.1186/s12968-021-00708-5;"LV volume assessment and FT strain analysis were performed using a dedicated software (ci 42 ; Circle Cardiovasacular Imaging, Calgary, Canada), and the global circumferential strain (GCS) and GCS rate were calculated from both cine CMR sequences"
SM167372;ci;https://pypi.org/project/ci;['https://github.com/rossmacarthur/python-ci'];['https://github.com/rossmacarthur/python-ci'];TRUE;10.12688/f1000research.18002.1;We use the continuous integration services travis.ci and appveyor to ensure that new versions of the code maintain all existing functionalities and give expected results on known datasets, including matching reference graphics tested using the visual regression testing implemented in vdiffr ( Henry )
SM167372;ci;https://pypi.org/project/ci;['https://github.com/rossmacarthur/python-ci'];['https://github.com/rossmacarthur/python-ci'];TRUE;10.1186/s12864-020-6714-x;Pipeline designers can define the Travis-ci test description document within the DolphinNext pipeline builder
SM167372;ci;https://pypi.org/project/ci;['https://github.com/rossmacarthur/python-ci'];['https://github.com/rossmacarthur/python-ci'];TRUE;10.1371/journal.pone.0078288;For confidence interval calculations with 500 repetitions (all other methods), the R function boot.ci(…) from the R boot package [55], [56] was used with the percentile method of bootstrap confidence interval calculation.
SM167372;ci;https://pypi.org/project/ci;['https://github.com/rossmacarthur/python-ci'];['https://github.com/rossmacarthur/python-ci'];TRUE;10.1098/rsif.2020.0500;To address this question, we applied a recently developed computational method, ra ndom ci rcuit pe rturbation (RACIPE), to a nine-component gene regulatory network (GRN) governing stemness, from which we identified robust gene states
SM168910;Pygments;https://pypi.org/project/Pygments;['https://pygments.org/'];['https://github.com/pygments/pygments'];TRUE;10.1186/s12864-016-3278-x;Code syntax was highlighted using Pygments version 2.2 [33].
SM174676;tripal;https://pypi.org/project/tripal;['https://github.com/galaxy-genome-annotation/python-tripal'];['https://github.com/galaxy-genome-annotation/python-tripal'];TRUE;10.1186/1471-2164-15-786;GFF3 files, sequences and BLAST results were loaded into the koala genome database with tools from the tripal toolkit
SM174676;tripal;https://pypi.org/project/tripal;['https://github.com/galaxy-genome-annotation/python-tripal'];['https://github.com/galaxy-genome-annotation/python-tripal'];TRUE;10.3389/fpls.2018.00418;The tripal toolkit for genome database construction
SM200861;Aeon;https://pypi.org/project/Aeon;['https://github.com/logicabrity/aeon'];['https://github.com/logicabrity/aeon'];TRUE;10.1186/s12910-019-0379-5;A brief summary of some of the results from the survey was previously published in Aeon magazine alongside an essay on the non-identity problem [7]
SM200861;Aeon;https://pypi.org/project/Aeon;['https://github.com/logicabrity/aeon'];['https://github.com/logicabrity/aeon'];TRUE;10.3390/mi9120617;The Aeon navigation system was proposed to achieve real-time X-ray monitoring and electromagnetic steering [20]
SM200861;Aeon;https://pypi.org/project/Aeon;['https://github.com/logicabrity/aeon'];['https://github.com/logicabrity/aeon'];TRUE;10.7717/peerj.9965;It features Intel Haswell processors with AVX2, Mellanox FDR InfiniBand interconnects, and Aeon storage (Moore et al., 2014)
SM200861;Aeon;https://pypi.org/project/Aeon;['https://github.com/logicabrity/aeon'];['https://github.com/logicabrity/aeon'];TRUE;10.7554/eLife.49855;The corresponding minimal cylinder radius that allows for the observation of significant , , 1.41 µm and 3.24 µm for Aeon, Connectom, and Prisma, respectively, is indicated by the vertical lines. In all plots, diffusivities and radii are expressed in  and , respectively.
SM203105;bitcoin;https://pypi.org/project/bitcoin;['http://github.com/vbuterin/pybitcointools'];['http://github.com/vbuterin/pybitcointools'];TRUE;10.3390/s19102395;The most direct way to solve this problem is block expansion, which is vulnerable to DDoS attacks (distributed denial of service) and thus has not been supported by the core development team of bitcoin
SM203105;bitcoin;https://pypi.org/project/bitcoin;['http://github.com/vbuterin/pybitcointools'];['http://github.com/vbuterin/pybitcointools'];TRUE;10.3390/s19081788;Therefore, bitcoin is strongly supported by blockchain that is an unassailable log, which keeps record of network transactions
SM203105;bitcoin;https://pypi.org/project/bitcoin;['http://github.com/vbuterin/pybitcointools'];['http://github.com/vbuterin/pybitcointools'];TRUE;10.1371/journal.pone.0169556;Since the launch of the first cryptocurrency, bitcoin, in 2009, dozens of other cryptocurrencies have been created
SM203105;bitcoin;https://pypi.org/project/bitcoin;['http://github.com/vbuterin/pybitcointools'];['http://github.com/vbuterin/pybitcointools'];TRUE;10.2196/13385;Although bitcoin can be used as a platform for preventing data tampering, it is not appropriate since it is an open network and massive computing power is necessary for proof of work (PoW) to obtain consensus [43]
SM203105;bitcoin;https://pypi.org/project/bitcoin;['http://github.com/vbuterin/pybitcointools'];['http://github.com/vbuterin/pybitcointools'];TRUE;10.1186/s12920-020-0725-y;They implemented a proof-of-concept system on top of Bitcoin by encoding the messages (i.e., API calls from clients and Replies from the server) between clients and the server into the transactions of bitcoin
SM204771;django-blastplus;https://pypi.org/project/django-blastplus;['https://github.com/michal-stuglik/django-blastplus'];['https://github.com/michal-stuglik/django-blastplus'];TRUE;10.1186/s12920-018-0430-2;The BLAST server was constructed by django-blastplus (version 0.4.0) and NCBI BLAST+ (version 2.3.0) [43]
SM231110;abies;https://pypi.org/project/abies;['https://github.com/AbiesDSP/Abies'];['https://github.com/AbiesDSP/Abies'];TRUE;10.1186/s12870-016-0952-8;abies 1.0 [3]
SM231110;abies;https://pypi.org/project/abies;['https://github.com/AbiesDSP/Abies'];['https://github.com/AbiesDSP/Abies'];TRUE;10.3389/fpls.2018.01625;abies 1.0 (complete) (Sundell et al., 2015)
SM231110;abies;https://pypi.org/project/abies;['https://github.com/AbiesDSP/Abies'];['https://github.com/AbiesDSP/Abies'];TRUE;10.3389/fpls.2019.01762;abies stand ( , ).
SM246726;object;https://pypi.org/project/object;[None];[None];TRUE;10.1186/s13104-019-4210-7;The Microsoft Access references required for adequate function of the DHP are: Visual Basic For Applications, Microsoft Access 14.0 object library (or newer), Microsoft Visual Basic for Applications Extensibility 5.3, OLE Automation, System_Windows_Forms, Microsoft ActiveX Data Objects 2.5 Library, Microsoft Scripting Runtime, mscorlib.dll, System, Microsoft Office 14.0 Access database engine Object Library (or newer), and Microsoft Windows Common Controls 6.0 (SP6)
SM247954;treehouse;https://pypi.org/project/treehouse;['https://github.com/jaraco/treehouse'];['https://github.com/jaraco/treehouse'];TRUE;10.1186/s13104-019-4577-5;Curated phylogenies currently available in treehouse’s database
SM247954;treehouse;https://pypi.org/project/treehouse;['https://github.com/jaraco/treehouse'];['https://github.com/jaraco/treehouse'];TRUE;10.1371/journal.pcbi.1007753;- The authors analysed 5 pediatric tumour datasets from UCSC treehouse compendium
SM247954;treehouse;https://pypi.org/project/treehouse;['https://github.com/jaraco/treehouse'];['https://github.com/jaraco/treehouse'];TRUE;10.1186/s13104-019-4577-5;We also anticipate treehouse to be a useful teaching tool.
SM247954;treehouse;https://pypi.org/project/treehouse;['https://github.com/jaraco/treehouse'];['https://github.com/jaraco/treehouse'];TRUE;10.1186/s13104-019-4577-5;B Treehouse’s user interface features a navigation bar (a) to toggle between phylogenies available in treehouse’s databases for animals, fungi, plants, and the tree of life (left) and a user provided phylogeny in userTree (right)
SM247954;treehouse;https://pypi.org/project/treehouse;['https://github.com/jaraco/treehouse'];['https://github.com/jaraco/treehouse'];TRUE;10.1186/s13104-019-4577-5;b To enable easy usage of treehouse, quick start directions are displayed
SM248407;ads;https://pypi.org/project/ads;['http://www.github.com/andycasey/ads/'];[None];TRUE;10.1186/s13104-015-1722-7;Data processing was performed using customised software (ads, Version 4.01, UK Labs, Kempten, Germany).
SM248407;ads;https://pypi.org/project/ads;['http://www.github.com/andycasey/ads/'];[None];TRUE;10.1002/ece3.4592;The L 12 (r)?function was calculated between 1 m and 10 m for distance r by using the package ads (Pélissier & Goreaud, 2015) for free statistical software R (R Core Team, 2017)
SM248407;ads;https://pypi.org/project/ads;['http://www.github.com/andycasey/ads/'];[None];TRUE;10.1155/2018/9319258;Strain gauge, force plate, EMG, and accelerometer signals were amplified using a custom-built universal amplifier (UMV, uk-labs, Kempen, Germany) and sampled at a rate of 1?kHz using the software package ads (version 1.12, uk-labs, Kempen, Germany), whereas the Locomètre signals were recorded without additional amplification using a software package provided by the manufacturer.
SM252564;SPLA;https://pypi.org/project/SPLA;[None];[None];TRUE;10.1186/s12893-016-0170-1;However, this is also stated when talking about the SILA/SPLA [27]
SM252564;SPLA;https://pypi.org/project/SPLA;[None];[None];TRUE;10.1186/s40644-020-00330-1;The present study found that EGFR mutations more frequently showed GGO in CT, consistent with the results of most previous studies in SPLA [14, 15, 26]
SM252564;SPLA;https://pypi.org/project/SPLA;[None];[None];TRUE;10.3390/ma13112439;[32] used the SPLA to determine the response of the conical composite structures to imperfection
SM252564;SPLA;https://pypi.org/project/SPLA;[None];[None];TRUE;10.1186/s13017-016-0096-z;Further studies are needed to achieve a general learning curve for SPLA.
SM252564;SPLA;https://pypi.org/project/SPLA;[None];[None];TRUE;10.1186/s13017-016-0096-z;Recent preliminary studies have not yet completely elucidate the learning curve of SPLA [8, 9]
SM263514;pyphysio;https://pypi.org/project/pyphysio;['https://github.com/MPBA/pyphysio'];['https://github.com/MPBA/pyphysio'];TRUE;10.3390/s20236778;The processing pipeline was developed in Python, based on pyphysio [39], and it is publicly available at https://gitlab.com/abp-san-public/wearable-clinical-devices.
SM263514;pyphysio;https://pypi.org/project/pyphysio;['https://github.com/MPBA/pyphysio'];['https://github.com/MPBA/pyphysio'];TRUE;10.3390/bs10010011;For the analysis of the physiological signals and the computation of the physiological synchrony, we used custom scripts based on pyphysio [33,34], physynch [35], and PySiology [36].
SM263514;pyphysio;https://pypi.org/project/pyphysio;['https://github.com/MPBA/pyphysio'];['https://github.com/MPBA/pyphysio'];TRUE;10.3390/s20226616;Future work should also consider additional HRV components such as the low frequency: high frequency ratio or percentage of consecutive normal R-peaks differing by at least 50 milliseconds, which can be analyzed using Kubios HRV [21] or open-source physiological signal analysis packages such as pyphysio [33].
SM263514;pyphysio;https://pypi.org/project/pyphysio;['https://github.com/MPBA/pyphysio'];['https://github.com/MPBA/pyphysio'];TRUE;10.3390/brainsci11030336;Physiological signals of EDA and ECG have been recorded with a Biopac MP160 at a 2000 Hz sampling rate and processed with Python’s “pyphysio” library [41] for indexes extraction.
SM263514;pyphysio;https://pypi.org/project/pyphysio;['https://github.com/MPBA/pyphysio'];['https://github.com/MPBA/pyphysio'];TRUE;10.1038/s41598-020-63596-2;The computation of synchrony was performed using a custom code based on pyphysio and physynch packages.
SM274329;eQTLseq;https://pypi.org/project/eQTLseq;['https://github.com/dvav/eQTLseq'];['https://github.com/dvav/eQTLseq'];TRUE;10.1093/bioinformatics/btx355; eQTLseq requires appropriately transformed expression data as input, when a Normal model is selected
SM274329;eQTLseq;https://pypi.org/project/eQTLseq;['https://github.com/dvav/eQTLseq'];['https://github.com/dvav/eQTLseq'];TRUE;10.1093/bioinformatics/btx355;All methods are implemented in the freely available Python software eQTLseq (https://github.com/dvav/eQTLseq).
SM274329;eQTLseq;https://pypi.org/project/eQTLseq;['https://github.com/dvav/eQTLseq'];['https://github.com/dvav/eQTLseq'];TRUE;10.1093/bioinformatics/btx355;eQTLseq (Fig
SM274329;eQTLseq;https://pypi.org/project/eQTLseq;['https://github.com/dvav/eQTLseq'];['https://github.com/dvav/eQTLseq'];TRUE;10.1093/bioinformatics/btx355;Availability and implementation All methods are implemented in the free software eQTLseq : https://github.com/dvav/eQTLseq Supplementary information Supplementary data are available at Bioinformatics online.
SM274329;eQTLseq;https://pypi.org/project/eQTLseq;['https://github.com/dvav/eQTLseq'];['https://github.com/dvav/eQTLseq'];TRUE;10.1093/bioinformatics/btx355;eQTLseq takes matrices X and Z (or Y, a transformed version of Z) as input and employs Gibbs sampling (Andrieu ) to estimate an M?×?K matrix of regression coefficients B
SM28139;venn;https://pypi.org/project/venn;['https://pypi.org/project/venn/'];[None];TRUE;10.3389/fmicb.2019.02736;Venn diagrams were calculated and plotted using venn version 1.7 R package
SM28139;venn;https://pypi.org/project/venn;['https://pypi.org/project/venn/'];[None];TRUE;10.3390/ijms21176060;A Venn diagram comparing the five experimental groups was generated with library “venn” (Dusa 2018) in R 3.5.1 (R Core Team 2018) [129].
SM28139;venn;https://pypi.org/project/venn;['https://pypi.org/project/venn/'];[None];TRUE;10.3389/fonc.2021.631803;The “edgeR” package was used to explore differential genes between high and low expression groups of m6A “eraser” FTO/ALKBH5, and the common differential expression genes were obtained using the “venn” package
SM28139;venn;https://pypi.org/project/venn;['https://pypi.org/project/venn/'];[None];TRUE;10.1371/journal.pbio.0050057;Venn diagram analyses were done using the venn package (v1.5) for the statistical programming package, R (http://www.stats.uwo.ca/faculty/murdoch/software).
SM28139;venn;https://pypi.org/project/venn;['https://pypi.org/project/venn/'];[None];TRUE;10.1371/journal.pone.0118867;Shared and private alleles were plotted with gplots R library with venn package [20].
SM293368;furious;https://pypi.org/project/furious;['http://github.com/Workiva/furious'];['http://github.com/Workiva/furious'];TRUE;10.3390/biom10111523;furious has also become a model to study spacer acquisition, revealing that new extrachromosomal spacers are preferentially acquired from broken DNA ends, supplied by plasmids with rolling-circle rather than theta replication [33]
SM300815;Adept;https://pypi.org/project/Adept;['https://github.com/fictivekin/adept-python'];['https://github.com/fictivekin/adept-python'];TRUE;10.1371/journal.pone.0072589;Peoplebot is produced by Adept Mobile Robots (USA) and is designed for service and human-robot interaction projects
SM300815;Adept;https://pypi.org/project/Adept;['https://github.com/fictivekin/adept-python'];['https://github.com/fictivekin/adept-python'];TRUE;10.3390/s17061232;The simulation experiments are implemented using MATLAB program based on a realistic model of the ActivMedia Pioneer 3 DX mobile robot (Adept MobileRobots, Amherst, NH, USA)
SM300815;Adept;https://pypi.org/project/Adept;['https://github.com/fictivekin/adept-python'];['https://github.com/fictivekin/adept-python'];TRUE;10.1155/2016/9845816;The autonomous robot (Figure 1) uses Pioneer P3-DX (Adept MobileRobots) as its platform
SM300815;Adept;https://pypi.org/project/Adept;['https://github.com/fictivekin/adept-python'];['https://github.com/fictivekin/adept-python'];TRUE;10.3390/s18082575;The proposed system is called Adept, and it uses three different technologies to solve both technical and economic issues for the “IoT.” Brody et al
SM300815;Adept;https://pypi.org/project/Adept;['https://github.com/fictivekin/adept-python'];['https://github.com/fictivekin/adept-python'];TRUE;10.3389/fonc.2019.00280;All ROI drawing and curve fitting was performed using proprietary software (Adept, Institute of Cancer Research, London, UK)
SM309217;struc;https://pypi.org/project/struc;['http://code.google.com/p/struc'];[None];TRUE;10.1093/bib/bbab038;For the top 1, 10 and 100 predicted contacts, DeepHomo obtained the precisions of 61.0%, 55.6% and 40.2%, respectively, compared with 29.7%, 16.3% and 4.8% for DCA_DI, 32.0%, 24.0% and 8.2% for DCA_APC, 7.3%, 6.6% and 4.9% for BIPSPI_seq, and 24.0%, 23.8% and 18.4% for BIPSPI_struc (Table 1)
SM309217;struc;https://pypi.org/project/struc;['http://code.google.com/p/struc'];[None];TRUE;10.1093/bib/bbab038;The performance of DeepHomo, two DCA-based approaches (DCA_DI and DCA_APC) and two machine learning-based methods (BIPSPI_seq and BIPSPI_struc) on the CASP-CAPRI of 28 realistic homo-dimeric targets
SM313072;ngCGH;https://pypi.org/project/ngCGH;['http://github.com/seandavi/ngCGH'];['http://github.com/seandavi/ngCGH'];TRUE;10.18632/oncotarget.15932;"We also evaluated the ability of the CNA calling tools (CODEX, ngCGH, and falcon) that subcategorize gain and loss events (amplification, +2; duplication, +1; deletion, -1; homozygous deletion, -2) (Supplementary Figure 3) to estimate amplifications and homozygous deletions"
SM313072;ngCGH;https://pypi.org/project/ngCGH;['http://github.com/seandavi/ngCGH'];['http://github.com/seandavi/ngCGH'];TRUE;10.1002/cam4.3370;For copy number analysis, We used version 0.4.4 of the ngCGH python package to generate aCGH?like data from the WES data
SM313072;ngCGH;https://pypi.org/project/ngCGH;['http://github.com/seandavi/ngCGH'];['http://github.com/seandavi/ngCGH'];TRUE;10.18632/oncotarget.11922;For copy number analysis from the exome sequencing data, ngCGH and RankSegmentation statistical algorithm in NEXUS software v7.5 were used
SM313072;ngCGH;https://pypi.org/project/ngCGH;['http://github.com/seandavi/ngCGH'];['http://github.com/seandavi/ngCGH'];TRUE;10.18632/oncotarget.23975;The ngCGH python package was used to generate aCGH-like data from whole exome sequencing (WES)
SM313072;ngCGH;https://pypi.org/project/ngCGH;['http://github.com/seandavi/ngCGH'];['http://github.com/seandavi/ngCGH'];TRUE;10.1371/journal.pcbi.1004873;Tools have been developed for copy number analysis of these datasets, as well, including CNVer [6], ExomeCNV [7], exomeCopy [8], CONTRA [9], CoNIFER [10], ExomeDepth [11], VarScan 2 [12], XHMM [13], ngCGH [14], EXCAVATOR [15], CANOES [16], PatternCNV [17], CODEX [18], and recent versions of Control-FREEC [19] and cn.MOPS [20]
SM316501;speckle;https://pypi.org/project/speckle;['https://github.com/specklworks/pyspeckle'];['https://github.com/specklworks/pyspeckle'];TRUE;10.1186/1476-7120-11-20;Inter-observer reliability was very strong for longitudinal strain (r?=?0.91, average difference 0.5?±?3%) and good for circumferential strain (r?=?0.8, average difference 0.65%?±?4.8%) and was similar to previously reported inter-observer reliability of speckle software [13]
SM316501;speckle;https://pypi.org/project/speckle;['https://github.com/specklworks/pyspeckle'];['https://github.com/specklworks/pyspeckle'];TRUE;10.1186/s12947-020-00201-6;The analysis was performed using speckle-tracking software, which is an image analysis method able to estimate the deformation of tissue by calculating the most likely displacement of pixel groups between frames [35, 36]
SM316501;speckle;https://pypi.org/project/speckle;['https://github.com/specklworks/pyspeckle'];['https://github.com/specklworks/pyspeckle'];TRUE;10.1371/journal.pone.0212770;Overnight fasting cardiac and peripheral vascular examinations including 2D color Doppler echocardiography, speckle tracking strain software and peripheral vascular tests including Doppler, pulse volume/cuff pressure recorders and phleborheography (PRG) were performed by an experienced cardiologist as clinical practice purposes to exclude cardiovascular lesions such as heart failure or vascular thrombosis, without charging either to patients or national health insurance.
SM33148;sst;https://pypi.org/project/sst;['http://testutils.org/sst'];[None];TRUE;10.1111/acel.13148;Chp files were generated by sst?rma normalization from Affymetrix CEL file using Expression Console Software
SM33148;sst;https://pypi.org/project/sst;['http://testutils.org/sst'];[None];TRUE;10.1371/journal.pone.0059866;sst has a point mutation that converts a glutamine at position 109 to a stop codon
SM33148;sst;https://pypi.org/project/sst;['http://testutils.org/sst'];[None];TRUE;10.1371/journal.pone.0129674;To compare our algorithm with the five programs (kaksi, plasse, stick, stlsstr and sst) that we are not able to obtain a local copy we have uploaded to a web server [23] a set of 100 x-ray protein structures (set ??) with the first 50 structures having resolutions between 1.0Å–2.0Å and the rest having resolutions ? 2.5Å(1AKG,1BGF,1EZW,1GSU,1I1N,1K1B,1NTE,1O98,1PVM,1SJD,1UKF,1VZY,1XGW,1YQD,2ASC, 2BJI, 2CWH,2FD5,2GB2, 2GG6,2H1V,2I2C,2NSF, 2POK,2VBA,2W6K,2WRA,2X7H,2YSK,2ZJ3,3C9U,3EDF, 3GG7,3HG7,3IDV,3LCC,3LFJ,3
SM33148;sst;https://pypi.org/project/sst;['http://testutils.org/sst'];[None];TRUE;10.1371/journal.pone.0129674;Due to the difficulty of obtaining a local copy for the programs palsse, stick, xtlsstr, kaksi and sst we have tested them on the set ?? of 100 selected x-ray structures by uploading each one to a web server [23] to obtain their assignments (Table 4)
SM343510;abf;https://pypi.org/project/abf;[None];[None];TRUE;10.3390/metabo11050305;As the Waters QTOF data have a supplementary function, corresponding to the lock spray analysis, a package must be downloaded on the Waters web site and installed in the abf converter software
SM349247;timedata;https://pypi.org/project/timedata;['https://github.com/rec/timedata'];['https://github.com/rec/timedata'];TRUE;10.1186/s12934-021-01598-z;"""timedata?<-?read.csv(""""timeworksheet.csv"""", sep="""","""", header=TRUE, check.names?=?FALSE)"""
SM35267;QCluster;https://pypi.org/project/QCluster;['https://github.com/QsonLabs/qcluster'];['https://github.com/QsonLabs/qcluster'];TRUE;10.1186/s13015-014-0029-x;We apply QCluster using different distances, to the whole set of reads and then we measure the quality of the clusters produced by evaluating the extent to which the partitioning agrees with the natural splitting of the sequences
SM35267;QCluster;https://pypi.org/project/QCluster;['https://github.com/QsonLabs/qcluster'];['https://github.com/QsonLabs/qcluster'];TRUE;10.1186/s13015-014-0029-x;These statistics are implemented in a software called QCluster (http://www.dei.unipd.it/~ciompin/main/qcluster.html).
SM35267;QCluster;https://pypi.org/project/QCluster;['https://github.com/QsonLabs/qcluster'];['https://github.com/QsonLabs/qcluster'];TRUE;10.1186/s13015-014-0029-x;All these measures are implemented in a software called QCluster
SM35267;QCluster;https://pypi.org/project/QCluster;['https://github.com/QsonLabs/qcluster'];['https://github.com/QsonLabs/qcluster'];TRUE;10.1186/s13015-014-0029-x;Both these approximations are implemented within the software QCluster and tests are presented in the Experimental Results section.
SM35267;QCluster;https://pypi.org/project/QCluster;['https://github.com/QsonLabs/qcluster'];['https://github.com/QsonLabs/qcluster'];TRUE;10.1186/s13015-014-0029-x;Starting from this software we developed QCluster by incorporating the computation of the -type statistics described above using both AWP and AQP prior probability estimators and the redistribution of quality values.
SM366486;arcgis;https://pypi.org/project/arcgis;['https://developers.arcgis.com/python/'];[None];TRUE;10.1002/ece3.4292;Sidescan sonar data were accessed using the arcgis 10.1 software package for visualization and interpretation in order to determine the spatial extent of S. spinulosa reef
SM366486;arcgis;https://pypi.org/project/arcgis;['https://developers.arcgis.com/python/'];[None];TRUE;10.1111/eva.12161;Landscape composition (percentage of a given buffer covered by each habitat type) was calculated using hawth’s tools (Beyer 2004) in arcgis 9.2
SM366486;arcgis;https://pypi.org/project/arcgis;['https://developers.arcgis.com/python/'];[None];TRUE;10.1111/zph.12827;"provinces) of the study area, the distribution of the animal samples was depicted using the arcgis software (version 10.3; ESRI, Redlands, CA, USA)"
SM366486;arcgis;https://pypi.org/project/arcgis;['https://developers.arcgis.com/python/'];[None];TRUE;10.1111/ppl.12144;Data were mapped using arcgis (Version 9.3, ESRI, Redlands, CA)
SM366486;arcgis;https://pypi.org/project/arcgis;['https://developers.arcgis.com/python/'];[None];TRUE;10.1111/eva.12240;Spatial mapping of plant traits and canonical variates predicted from regression models was completed using the grid algebra function (raster calculator) of the arcgis 9.3 Spatial Analyst extension (ESRI, Redlands, CA, USA)
SM395048;summarytools;https://pypi.org/project/summarytools;['https://github.com/6chaoran/jupyter-summarytools'];['https://github.com/6chaoran/jupyter-summarytools'];TRUE;10.1371/journal.pone.0228262;The analyses were carried out using the packages summarytools and MASS (function polr) in R.
SM395048;summarytools;https://pypi.org/project/summarytools;['https://github.com/6chaoran/jupyter-summarytools'];['https://github.com/6chaoran/jupyter-summarytools'];TRUE;10.1186/s41155-021-00194-9;All the analysis was conducted in the R software (R Core Team, 2021) using the packages summarytools (Comtois, 2021), polycor (Fox, 2019), GGally (Schloerke et al., 2021), CTT (Willse, 2018), lavaan (Rosseel, 2012), nFactors (Raiche & Magis, 2020), psych (Revelle, 2020)
SM395048;summarytools;https://pypi.org/project/summarytools;['https://github.com/6chaoran/jupyter-summarytools'];['https://github.com/6chaoran/jupyter-summarytools'];TRUE;10.1371/journal.pone.0239639;Various R packages [76] run in R-studio v.1.2.5033 were used for statistical analyses and plot construction: summarytools library [77] was used for obtaining basal descriptive statistics, ggplot2 library [78] was used to analyze Pearson correlation and plot the result as well as for creating boxplots and histograms, posthoc.kruskal.dunn.test function in the PMCMR library [79] was used for the posthoc Dunn’s test, the FSA library [80] was used to conduct the Mann-Whitney U test, the prcomp function [76] was 
SM395048;summarytools;https://pypi.org/project/summarytools;['https://github.com/6chaoran/jupyter-summarytools'];['https://github.com/6chaoran/jupyter-summarytools'];TRUE;10.2196/25124;R 3.2.2 (R Development Core Team) software [23] was used on every statistical step of this work: discretization of continuous variables (package car [24]), descriptive and comparative analyses (packages gmodels [25] and epitools [26]), missing data analysis (package summarytools [27]), missing data imputation (package DMwR [28]), hierarchical clustering (package stats [23]), Bayesian network inference (packages bnlearn [29] and gRain [30]), and ROC curve analysis (package pROC [31])
SM395048;summarytools;https://pypi.org/project/summarytools;['https://github.com/6chaoran/jupyter-summarytools'];['https://github.com/6chaoran/jupyter-summarytools'];TRUE;10.3390/jpm11060512;R-package ‘dplyr’ was used for data manipulation [28], and R-package ‘summarytools’ was used for frequencies tables, cross-tabulation, and other descriptive statistics [29]
SM397327;hab;https://pypi.org/project/hab;[None];[None];TRUE;10.1089/zeb.2018.1628;These tanks are in the same aquaria room as the Z-hab stand-alone systems
SM397327;hab;https://pypi.org/project/hab;[None];[None];TRUE;10.1371/journal.pone.0195480;We evaluated models with k-fold cross validation [67] using the hab package [68]
SM397327;hab;https://pypi.org/project/hab;[None];[None];TRUE;10.1002/ece3.7190;We also assessed the predictive ability of each final model with k?fold cross?validation using the hab package (Basille, 2015)
SM407625;geobr;https://pypi.org/project/geobr;['https://github.com/ipeaGIT/geobr'];['https://github.com/ipeaGIT/geobr'];TRUE;10.3390/pathogens10080988;Geographical maps and general plots were generated using R v3.6.1 [68], and the ggplot2 v3.3.2 [69], geobr v.1.4 [70], and sf v0.9.8 [71] packages
SM407625;geobr;https://pypi.org/project/geobr;['https://github.com/ipeaGIT/geobr'];['https://github.com/ipeaGIT/geobr'];TRUE;10.1371/journal.pntd.0009700;We produced the maps using R software, geobr package [31, 32], (MIT license https://ipeagit.github.io/geobr/).
SM407625;geobr;https://pypi.org/project/geobr;['https://github.com/ipeaGIT/geobr'];['https://github.com/ipeaGIT/geobr'];TRUE;10.1371/journal.pone.0257235;Maps data obtained using geobr, an open-source respository of public domain, official spatial data sets of Brazil [24].
SM410629;pyqi;https://pypi.org/project/pyqi;['http://bipy.github.io/pyqi'];[None];TRUE;10.7717/peerj.4395;Other requirements include GoogleAppEnginePipeline 1.9.22.1, pyqi 0.3.1, requests 2.10.0, requests-toolbelt 0.6.2, mailjet-rest 1.2.2, biom-format 1.1.2, ete3 3.0.0 (for tree generation–see below for details), webapp2 2.5.2, numpy 1.6.1, matplotlib 1.2.0, jinja2 2.6, ssl 2.7.11
SM410629;pyqi;https://pypi.org/project/pyqi;['http://bipy.github.io/pyqi'];[None];TRUE;10.1093/gigascience/gix129;0.8.1), pyqi (v
SM41455;FPE;https://pypi.org/project/FPE;[None];[None];TRUE;10.1371/journal.pone.0206875;This numerical solution allows use of a model that is more general than those used in XCOM or FPE due to the fact that leg length is not fixed, but depends only on the location of the COM relative to the foot
SM41455;FPE;https://pypi.org/project/FPE;[None];[None];TRUE;10.3389/fpsyt.2013.00074;renowned judgments involving the reference to neuroscience data in FPE (6–8)
SM41455;FPE;https://pypi.org/project/FPE;[None];[None];TRUE;10.3390/s19183869;To counter this, tweak (T) is an additional piece of information that is used as an input in FPE with certain types of data, and it need not be kept secret
SM41455;FPE;https://pypi.org/project/FPE;[None];[None];TRUE;10.1007/s13280-016-0832-3;This study builds on FPE that examines social divisions of labor in natural resource management by stressing the importance of the role of place or location in these divisions
SM41455;FPE;https://pypi.org/project/FPE;[None];[None];TRUE;10.1186/s12918-018-0573-y;Therefore, we try to use protein modularity to assess the essential proteins predicted by FPE
SM426250;d3plot;https://pypi.org/project/d3plot;['https://github.com/yuhangwang/d3plot'];['https://github.com/yuhangwang/d3plot'];TRUE;10.1098/rsta.2009.0052;Once boundary conditions were applied, the model was solved within LS-DYNA and the results interpreted using the d3plot post-processor (Ove/Arup).
SM442171;sasa;https://pypi.org/project/sasa;['https://code.google.com/p/sasa-tool/'];[None];TRUE;10.3389/fmolb.2019.00025;Shaw Research was converted to Gromacs format and SASA was calculated for 1,044,000 frames using gmx sasa tool from the Gromacs package (Abraham et al., 2015)
SM442171;sasa;https://pypi.org/project/sasa;['https://code.google.com/p/sasa-tool/'];[None];TRUE;10.1371/journal.pone.0225368;RMSD, RMSF, SASA, Rg, temperature, pressure and density plot analysis were carried out using g_rms, g_rmsf, g_sasa, g_Rg and g_density tools, respectively
SM442171;sasa;https://pypi.org/project/sasa;['https://code.google.com/p/sasa-tool/'];[None];TRUE;10.1038/s41598-019-56052-3;In all cases we utilize the algorithm of implemented in GROMACS tool package (gmx sasa)
SM442171;sasa;https://pypi.org/project/sasa;['https://code.google.com/p/sasa-tool/'];[None];TRUE;10.1038/s41598-021-84569-z;The data are calculated with GROMACS tool gmx sasa from systems B1–8
SM442171;sasa;https://pypi.org/project/sasa;['https://code.google.com/p/sasa-tool/'];[None];TRUE;10.15252/embj.2020106807;"Secondary structure was assigned using STRIDE (Frishman & Argos, 1995); Poisson–Boltzmann electrostatic calculations were performed using APBS/PDB2PQR (Jurrus et al, 2018); protein–protein interfaces were analyzed using PISA (Krissinel & Henrick, 2007), PIC (Tina et al, 2007) and the AnalyseComplex command of FoldX (Delgado et al, 2019); intermolecular contact surface areas were calculated with dr_sasa (Ribeiro et al, 2019)"
SM442505;pyAFQ;https://pypi.org/project/pyAFQ;['https://yeatmanlab.github.io/pyAFQ'];[None];TRUE;10.1371/journal.pcbi.1009136;In addition to demonstrating the our analysis pipeline is robust to changes in tractometry software, the use of the updated pyAFQ capitalized upon the following improvements over the legacy Matlab version: (i) the ability to ingest data provided in the BIDS format [84], and (ii) the calculation of diffusion kurtosis imaging (DKI [43]) metrics We will refer to the mAFQ and pyAFQ pipeline collectively as AFQ.
SM442505;pyAFQ;https://pypi.org/project/pyAFQ;['https://yeatmanlab.github.io/pyAFQ'];[None];TRUE;10.1371/journal.pcbi.1009136;The sofware integrates within a broader automated fiber quantification software ecosystem: AFQ [5] and pyAFQ [57], which extract tract profile data from raw and processed dMRI datasets, as well as AFQ-Browser, which visualizes tract profiles data and facilitates sharing of the results of dMRI studies [58]
SM444148;AON;https://pypi.org/project/AON;[None];[None];TRUE;10.7554/eLife.65445;Consistent with histology and sn-R1/R2/R3 analyses (Figures 1 and 2), simulations from both AON-injection and pPCx-injection bulk RNA-seq datasets (AON-sim and PCx-sim, respectively) contained cell types other than projection neurons, and this contamination was more pronounced in the AON-sim dataset
SM444148;AON;https://pypi.org/project/AON;[None];[None];TRUE;10.1007/s10278-010-9277-6;The AON compression engine writes a lossless-compressed DICOM Part 10 image version as the “original” image in order to meet the guidelines of the US Mammography Quality Standards Act (MQSA)
SM444148;AON;https://pypi.org/project/AON;[None];[None];TRUE;10.3389/fpubh.2021.673321;This was completed initially by AON and then again with a team comprising of the first author and two additional co-researchers
SM444148;AON;https://pypi.org/project/AON;[None];[None];TRUE;10.3389/fnins.2018.00583;For spikes destined for other cores, the output from the axon module is routed to the packetizer unit in the AON router interface block.
SM444148;AON;https://pypi.org/project/AON;[None];[None];TRUE;10.1371/journal.pcbi.1008217;AON-k performs well in evolutionary simulation because it prescribes d as the default action, just as CAPRI-n does in state I, unless the players have synchronized their behavior over the previous k rounds
SM449318;gitlab;https://pypi.org/project/gitlab;['https://yoginth.ml'];[None];TRUE;10.1371/journal.pcbi.1009301;In addition, the authors should guarantee that re-running their code from the gitlab repository is possible.
SM449318;gitlab;https://pypi.org/project/gitlab;['https://yoginth.ml'];[None];TRUE;10.1371/journal.pcbi.1008969;I can confirm that I could access the code shared on gitlab
SM449318;gitlab;https://pypi.org/project/gitlab;['https://yoginth.ml'];[None];TRUE;10.1371/journal.pone.0252775;"These scripts could be made on dedicated platforms such as the Open Science Framework, github, gitlab, ResearchBox, or the PsychArchives; or maybe also Supplementary Material to this paper"
SM449318;gitlab;https://pypi.org/project/gitlab;['https://yoginth.ml'];[None];TRUE;10.5334/jors.289;The software may be forked via gitlab which implements issue trackers to enable bug reporting and feature requests.
SM459266;fwdpy;https://pypi.org/project/fwdpy;['http://www.molpopgen.org'];[None];TRUE;10.1371/journal.pgen.1006573;The model was implemented using the Python package fwdpy version 0.0.4, which uses fwdpp[87] version 0.5.1 as a C++ back-end
SM466265;cbio;https://pypi.org/project/cbio;['https://github.com/Cristian-pg/cbio'];['https://github.com/Cristian-pg/cbio'];TRUE;10.1371/journal.pone.0101411;analyzed in cbio (see Fig
SM466265;cbio;https://pypi.org/project/cbio;['https://github.com/Cristian-pg/cbio'];['https://github.com/Cristian-pg/cbio'];TRUE;10.1371/journal.pone.0199688;The cohorts were queried for CCND1 gene amplification or mutations in the cbio portal by using the advanced onco query language (CCND1: AMP or CCND1: MUT) [20][21]
SM466265;cbio;https://pypi.org/project/cbio;['https://github.com/Cristian-pg/cbio'];['https://github.com/Cristian-pg/cbio'];TRUE;10.1371/journal.pone.0199688;CCND1 mutations specifically in primary endometrial carcinoma were interrogated via the cbio portal and via the advanced onco query language specifically in the endometrial carcinoma TCGA study with sequencing data (n = 248) [18]
SM46852;value;https://pypi.org/project/value;['http://github.com/halst/value'];['http://github.com/halst/value'];TRUE;10.1002/mnfr.201600372;False discovery rates were quantified using Bonferroni corrections for phylum level tests, and the q?value software package was used for remaining comparisons at the taxonomic level
SM46852;value;https://pypi.org/project/value;['http://github.com/halst/value'];['http://github.com/halst/value'];TRUE;10.1186/s12711-015-0111-y;The R package q-value [34] was used to calculate the FDR-based q-value to measure the statistical significance at the genome-wide level for association studies
SM46852;value;https://pypi.org/project/value;['http://github.com/halst/value'];['http://github.com/halst/value'];TRUE;10.3389/fpls.2017.01463;Q-values were calculated using the R-package q-value (Storey et al., 2015)
SM46852;value;https://pypi.org/project/value;['http://github.com/halst/value'];['http://github.com/halst/value'];TRUE;10.1111/eva.12944;For each association model related to the same environmental variable, p?values of G?scores (G) and Wald scores (W) were corrected for multiple testing using the R q?value package (v
SM46852;value;https://pypi.org/project/value;['http://github.com/halst/value'];['http://github.com/halst/value'];TRUE;10.1534/g3.117.300125;p-values were adjusted for multiple testing using R package q-value (Storey )
SM480443;GVA;https://pypi.org/project/GVA;['https://github.com/VladislavNekto/gva/'];['https://github.com/VladislavNekto/gva/'];TRUE;10.5888/pcd17.200096;The CDC WONDER data set is publicly available, has been collected and used for many years, and provides more reliable demographic data than GVA (1)
SM480443;GVA;https://pypi.org/project/GVA;['https://github.com/VladislavNekto/gva/'];['https://github.com/VladislavNekto/gva/'];TRUE;10.1186/s40621-021-00339-5;GVA does not provide data on suicide in real time, as it does other types of firearm violence, and examination of unintentional firearm injuries was beyond the scope of the current paper
SM480443;GVA;https://pypi.org/project/GVA;['https://github.com/VladislavNekto/gva/'];['https://github.com/VladislavNekto/gva/'];TRUE;10.1371/journal.pone.0248437;While some data sets exclude events such as gang violence, GVA does not set any limiting terms to their definition of a mass shooting other than the number of individuals shot and killed, leading to a data set that contains a greater number of events
SM480443;GVA;https://pypi.org/project/GVA;['https://github.com/VladislavNekto/gva/'];['https://github.com/VladislavNekto/gva/'];TRUE;10.1155/2015/256818;The problem of multiple combinations of haplotypes is also resolved in GVA.
SM480443;GVA;https://pypi.org/project/GVA;['https://github.com/VladislavNekto/gva/'];['https://github.com/VladislavNekto/gva/'];TRUE;10.3390/ijerph18179417;The GVA application is used for the validation of the data
SM490293;impact;https://pypi.org/project/impact;['https://github.com/xogeny/impact'];['https://github.com/xogeny/impact'];TRUE;10.1371/journal.pone.0243263;We collected the mobility data from the interactive COVID-19 mobility impact and social distancing analysis platform [1, 2]
SM490293;impact;https://pypi.org/project/impact;['https://github.com/xogeny/impact'];['https://github.com/xogeny/impact'];TRUE;10.1038/s41598-019-43475-1;Lastly, we used “impact” software to calculate standardized effect size (SES) of functional diversity obtained using null models that control for SR effect and eight individual EFs
SM490293;impact;https://pypi.org/project/impact;['https://github.com/xogeny/impact'];['https://github.com/xogeny/impact'];TRUE;10.1186/1751-0473-7-10;"A?: Beta amyloid; AD: Alzheimer’s disease; EC: Entorhinal cortex; GEO: Gene expression omnibus; GSEA: Gene set enrichment analysis; GnRH: Gonadotropin releasing hormone; GO: Gene Ontology; HIP: Hippocampal field CA1; KEGG: Kyoto encyclopedia of genes and genomes; MTG: Middle temporal gyrus; NFTs: Neurofibrillary tangles; NTRs: Neurotrophin receptors; PC: Posterior cingulate cortex; PPI: Protein-protein interaction; SFG: Superior frontal gyrus; SPIA: Signaling pathway impact analysis; VCX: Primary visual cor"
SM492356;mk;https://pypi.org/project/mk;['https://github.com/pycontribs/mk'];['https://github.com/pycontribs/mk'];TRUE;10.1371/journal.pone.0232433;The android.mk file and code are modified so that it can run application opencv-like programs without the need for OpenCV Manager.
SM510719;pickpocket;https://pypi.org/project/pickpocket;['https://github.com/benjaminviart/PickPocket'];['https://github.com/benjaminviart/PickPocket'];TRUE;10.1371/journal.pone.0248061;For accuracy, other software such as an artificial neural network (ANN), stabilized matrix method (SMM), MHC binding energy covariance matrix (SMMPMBEC), NetMHCpan, pickpocket, and NetMHCstapan, were adopted for this purpose
SM510719;pickpocket;https://pypi.org/project/pickpocket;['https://github.com/benjaminviart/PickPocket'];['https://github.com/benjaminviart/PickPocket'];TRUE;10.1101/mcs.a002444;MHC Class I binding predictions were generated through pVACSeq using NetMHC v3.4, as well as five other algorithms from the Immune Epitope Database and Analysis resource (IEDB, iedb.org): netMHC, netmhccons, netmhcpan, pickpocket, smm, and smmpmbec
SM510719;pickpocket;https://pypi.org/project/pickpocket;['https://github.com/benjaminviart/PickPocket'];['https://github.com/benjaminviart/PickPocket'];TRUE;10.1155/2020/2837670;For better predictive accuracy, other software such as artificial neural network (ANN), stabilized matrix method (SMM), MHC-binding energy covariance matrix (SMMPMBEC), NetMHCpan, pickpocket, and NetMHCpan were adopted for this purpose
SM530391;modes;https://pypi.org/project/modes;['https://github.com/jtambasco/modesolverpy'];['https://github.com/jtambasco/modesolverpy'];TRUE;10.1371/journal.pone.0223490;0.75–7, and the bimodality coefficient after Ellison [55] was calculated with the R-package ‘modes’ v
SM530391;modes;https://pypi.org/project/modes;['https://github.com/jtambasco/modesolverpy'];['https://github.com/jtambasco/modesolverpy'];TRUE;10.1098/rsos.191511;Trip duration distribution of these pooled trips was assessed for bimodality with calculation of the bimodality coefficient [61] and mode(s) estimation(s) by mixture distribution implemented in the modes package [62]
SM532078;lunar;https://pypi.org/project/lunar;[None];[None];TRUE;10.1371/journal.pone.0246564;Lunar stage was included as a categorical variable of either ‘new’, ‘waxing’, ‘full’ or ‘waning’ and was obtained using the ‘lunar’ package [63] in the R programming environment [64]
SM532078;lunar;https://pypi.org/project/lunar;[None];[None];TRUE;10.1371/journal.pone.0252092;Lunar illumination was calculated through the ’lunar’ package in R [43] and represents the proportion of lunar illumination for any specific date and time
SM532078;lunar;https://pypi.org/project/lunar;[None];[None];TRUE;10.1002/ece3.7006;Visitation was used as the binary response variable, and the covariates included were the month of the visit, the size of the lick in m2, the lick type (face present or not present), elevation in m, slope in degrees, distance the closest river or stream in m, distance from the closest hunting camp in m (a proxy for hunting pressure, see Griffiths, 2020), and the brightness of the moon calculated using the lunar.illumination function in the lunar package (Lazaridis, 2014) in R
SM568935;foursquare;https://pypi.org/project/foursquare;['http://github.com/mLewisLogic/foursquare'];['http://github.com/mLewisLogic/foursquare'];TRUE;10.1371/journal.pone.0124819;When foursquare users check-in to a place this status can be posted to their Twitter pages
SM568935;foursquare;https://pypi.org/project/foursquare;['http://github.com/mLewisLogic/foursquare'];['http://github.com/mLewisLogic/foursquare'];TRUE;10.1155/2016/1291358;Some applications like foursquare and Google Latitude mainly focus on people current locations, such as hotel or park
SM568935;foursquare;https://pypi.org/project/foursquare;['http://github.com/mLewisLogic/foursquare'];['http://github.com/mLewisLogic/foursquare'];TRUE;10.3390/ijerph15102319;After controlling for gender, age and school track, FOMO positively predicted the use of the four most popular social media platforms: Facebook, Snapchat, Instagram and Youtube, as well as the frequency of using foursquare, Tumblr and Vine
SM568935;foursquare;https://pypi.org/project/foursquare;['http://github.com/mLewisLogic/foursquare'];['http://github.com/mLewisLogic/foursquare'];TRUE;10.2196/jmir.2121;Additionally, some of the respondents represented in the Pew report could be using third-party location-tagging applications (eg, foursquare), which data may not appear in our sample, or they may be tweeting so infrequently that they would be underrepresented in our tweet-based sample
SM568935;foursquare;https://pypi.org/project/foursquare;['http://github.com/mLewisLogic/foursquare'];['http://github.com/mLewisLogic/foursquare'];TRUE;10.2196/jmir.2121;In addition to these mechanisms supported directly by Twitter, users can also provide location context indirectly in the text of their tweets (eg, “My plane just landed at JFK”) or through third-party applications, such as foursquare (https://foursquare.com/)
SM569443;ndl;https://pypi.org/project/ndl;['https://github.com/msull/needle'];['https://github.com/msull/needle'];TRUE;10.1371/journal.pone.0218802;We therefore use the implementation of the equilibrium equations for the Rescorla-Wagner model [30] in version 0.2.18 of the ndl package for the statistical software r to estimate the connection strength (V) of cue (C) to outcome (O): where Pr(C|C) is the conditional probability of cue C given cue C, Pr(O|C) is the conditional probability of outcome O given cue C and n + 1 is the number of different cues
SM569443;ndl;https://pypi.org/project/ndl;['https://github.com/msull/needle'];['https://github.com/msull/needle'];TRUE;10.1371/journal.pone.0075734;We then estimated the weights of the model using the ‘ndl’ package in R (version 0.2.10) which implements the Danks equations [23] introduced above
SM569443;ndl;https://pypi.org/project/ndl;['https://github.com/msull/needle'];['https://github.com/msull/needle'];TRUE;10.1111/cogs.12910;(1), (2), (3) implemented in R (R Core Team, 2019) using the edl package (van Rij & Hoppe, 2020) and the ndl package (Arppe et al., 2018)
SM569610;physarum;https://pypi.org/project/physarum;['https://github.com/MNoichl/physarum'];['https://github.com/MNoichl/physarum'];TRUE;10.1371/journal.pone.0066732;Apply physarum model to find optimal paths between all pairs of nodes.
SM569610;physarum;https://pypi.org/project/physarum;['https://github.com/MNoichl/physarum'];['https://github.com/MNoichl/physarum'];TRUE;10.1155/2014/531032;[16] validate physarum which is apparently able to solve shortest path problems by constructing a maze
SM569610;physarum;https://pypi.org/project/physarum;['https://github.com/MNoichl/physarum'];['https://github.com/MNoichl/physarum'];TRUE;10.3390/s21041373;In 2017, they combined the GA with an innovative algorithm called physarum network (PN), focusing on the determination of the TVB-N [108]
SM569610;physarum;https://pypi.org/project/physarum;['https://github.com/MNoichl/physarum'];['https://github.com/MNoichl/physarum'];TRUE;10.1371/journal.pone.0066732;In the abovementioned model, physarum model can find optimal paths between any pair of nodes, by adapting the flux through each edge and its conductivity
SM569610;physarum;https://pypi.org/project/physarum;['https://github.com/MNoichl/physarum'];['https://github.com/MNoichl/physarum'];TRUE;10.1155/2014/531032;We migrate the physarum foraging model to wireless networks to develop physarum-based routing algorithms through dimensionless analogy analysis [19, 20].
SM579966;gne;https://pypi.org/project/gne;['https://github.com/GeneralNewsExtractor/GeneralNewsExtractor'];['https://github.com/GeneralNewsExtractor/GeneralNewsExtractor'];TRUE;10.1371/journal.pone.0070329;Most of our structures include GalNAc, and the presence of a galE gene elsewhere makes gne a good prediction for this gene [56].
SM589803;Toolserver;https://pypi.org/project/Toolserver;['http://bitbucket.org/rfc1437/toolserver/'];[None];TRUE;10.1371/journal.pone.0071226;These three variables are calculated using the page history databases of Wikimedia Toolserver (http://toolserver.wikimedia.org), which register information about every modification made to the pages of Wikipedia
SM596405;pymagnitude;https://pypi.org/project/pymagnitude;['https://gitlab.com/Plasticity/magnitude'];[None];TRUE;10.1371/journal.pone.0240376;Our analogies of Word2Vec embeddings were carried out on Google CoLab using the pymagnitude package and vector similarity functions (see Section 3.1)
SM601858;mnnpy;https://pypi.org/project/mnnpy;['http://github.com/chriscainx/mnnpy'];['http://github.com/chriscainx/mnnpy'];TRUE;10.1016/j.cell.2020.08.013;The resulting peripheral retina, foveal retina, and developed organoid transcriptomes were integrated using the mnnpy implementation of MNN correction (Haghverdi et al., 2018)
SM601858;mnnpy;https://pypi.org/project/mnnpy;['http://github.com/chriscainx/mnnpy'];['http://github.com/chriscainx/mnnpy'];TRUE;10.1242/dev.174557;Batch effects between the two datasets were corrected by matching mutual nearest neighbours in the implementation of mnnpy (v0.1.9.3) (parameters: svd_mode=‘irlb’) (Lun et al., 2016)
SM601858;mnnpy;https://pypi.org/project/mnnpy;['http://github.com/chriscainx/mnnpy'];['http://github.com/chriscainx/mnnpy'];TRUE;10.1186/s13073-020-00799-2;Mutual nearest neighbor (MNN) correction [31] (mnnpy [32] version 0.1.9.5) was used to combine data across the eight donors for clustering and cell state identification
SM608599;gdsCAD;https://pypi.org/project/gdsCAD;['https://github.com/hohlraum/gdsCAD'];['https://github.com/hohlraum/gdsCAD'];TRUE;10.3390/cells7080094;"The mask was manufactured by Delta Mask, Toppan, Netherlands, using a GDSII layout file that was created using the Python platform and gdsCAD 0.4.5 package containing the pattern designs; i.e., circle patterns with a diameter 50 ?m"
SM626692;libmesh;https://pypi.org/project/libmesh;['https://github.com/superdima05/mesh/'];['https://github.com/superdima05/mesh/'];TRUE;10.1007/s00466-017-1381-8;For the implementation we used the C++ library libmesh [33], and the multi-frontal direct solver mumps [2] to solve the resulting linear systems
SM633190;sorting;https://pypi.org/project/sorting;['https://yoginth.com'];[None];TRUE;10.1016/j.cub.2021.01.005;Manual refinement of the classification was then done using the TINT spike-sorting software (Axona, St Albans, UK)
SM633190;sorting;https://pypi.org/project/sorting;['https://yoginth.com'];[None];TRUE;10.3389/fncel.2016.00256;Single units were extracted from raw waveforms using the Spike2 spike-sorting package, which uses principal components analysis as well as waveshape features
SM633190;sorting;https://pypi.org/project/sorting;['https://yoginth.com'];[None];TRUE;10.3390/genes12060875;To predict whether the variant could affect protein function, we used Alamut VISUAL PLUS TM v.2.15 to access multiple protein prediction programs: Align-GVGD [23], MutationTaster (Build NCBI37/Ensembl 69) [24], sorting intolerant from tolerant (SIFT) [25,26], and Polymorphism Phenotyping v2 (Polyphen-2) [27,28].
SM64748;mpi4py;https://pypi.org/project/mpi4py;['https://github.com/mpi4py/mpi4py/'];['https://github.com/mpi4py/mpi4py/'];TRUE;10.1186/s12859-020-03562-x;HPC-REDItools are again written in Python (to increase portability and for continuity with the previous version) and makes use of mpi4py library [17] (version 2.0.0) that is the binding of the Message Passing Interface (MPI) standard library for the Python programming language
SM64748;mpi4py;https://pypi.org/project/mpi4py;['https://github.com/mpi4py/mpi4py/'];['https://github.com/mpi4py/mpi4py/'];TRUE;10.3389/fnhum.2013.00869;Simulations and analyses were performed in Python, using NumPy 1.7.1, SciPy 0.12.0, mpi4py 1.3, and OpenMPI 1.6.1 on commercially available x86_64 hardware
SM64748;mpi4py;https://pypi.org/project/mpi4py;['https://github.com/mpi4py/mpi4py/'];['https://github.com/mpi4py/mpi4py/'];TRUE;10.3389/fninf.2018.00092;The simulated results and analysis presented here were made possible using Python 2.7.11 with the Intel(R) MPI Library v5.1.3, NEURON v7.5 (1472:078b74551227), Cython v0.23.4, LFPy (github.com/LFPy/LFPy, SHA:0d1509), mpi4py v2.0.0, numpy v1.10.4, scipy v0.17.0, h5py v2.6.0, parameters (github.com/NeuralEnsemble/parameters, SHA:v0aaeb), csa (github.com/INCF/csa, SHA:452a35) and matplotlib v2.1.0 running in parallel using 120-4800 cores on the JURECA cluster in Jülich, Germany, composed of two 2.5 GHz Intel X
SM64748;mpi4py;https://pypi.org/project/mpi4py;['https://github.com/mpi4py/mpi4py/'];['https://github.com/mpi4py/mpi4py/'];TRUE;10.1371/journal.pcbi.1005930;We chose an MPI distributed-memory parallelization implemented with the Python library mpi4py [78] whereby simulation of every spot size is mapped to one MPI process
SM64748;mpi4py;https://pypi.org/project/mpi4py;['https://github.com/mpi4py/mpi4py/'];['https://github.com/mpi4py/mpi4py/'];TRUE;10.1371/journal.pone.0146581;from mpi4py import MPI
SM650181;ABBYY;https://pypi.org/project/ABBYY;['https://github.com/samueltc/ABBYY'];['https://github.com/samueltc/ABBYY'];TRUE;10.1186/s13637-017-0057-1;Hand-writing recognition is a well-established problem and we have experimented with different resources including Omnipage Capture SDK [18], Captricity [19], and ABBYY [20], which to the best of our knowledge are among the best tools in the market for recognizing hand-written letters and have been widely used in recognizing and transforming documents into usable digital forms [21]
SM650181;ABBYY;https://pypi.org/project/ABBYY;['https://github.com/samueltc/ABBYY'];['https://github.com/samueltc/ABBYY'];TRUE;10.12688/f1000research.7329.3;We analyzed different freely available and commercial OCR systems and libraries including Aspose, PUMA, Microsoft OCR, Tesseract, LEADTOOLS, Nicomsoft OCR, MeOCR OCR, OmniPage, ABBYY, Bytescout claiming to be able to extract embedded text from figures
SM650181;ABBYY;https://pypi.org/project/ABBYY;['https://github.com/samueltc/ABBYY'];['https://github.com/samueltc/ABBYY'];TRUE;10.1109/JTEHM.2019.2935451;Four different OCR Engines that can be implemented via an API were evaluated to determine the accuracy and usability of each engine: Google Machine Learning Kit (ML Kit) [26], Microsoft Azure’s Cognitive Services (Azure OCR) [27], ABBYY’s Real Time Recognition SDK (ABBY RTR) [28], and Amazon’s Rekognition SDK (Rekognition) [29]
SM650181;ABBYY;https://pypi.org/project/ABBYY;['https://github.com/samueltc/ABBYY'];['https://github.com/samueltc/ABBYY'];TRUE;10.1109/JTEHM.2019.2935451;Successful search rate at zoom level differed significantly between the 4 OCR engines (, df = 3, p < 0.001), with ML Kit being the most successful in detecting keywords without needing to zoom in, followed by Rekognition, Azure OCR, and ABBYY RTR
SM650181;ABBYY;https://pypi.org/project/ABBYY;['https://github.com/samueltc/ABBYY'];['https://github.com/samueltc/ABBYY'];TRUE;10.1109/JTEHM.2019.2935451;A 4-sample test for equality of proportions showed that the overall successful search rate differed significantly between the OCR engines (, df = 3, p < 0.001), with ML Kit and Rekognition having a significantly higher overall success rate than Azure OCR and ABBYY RTR (p < 0.001 for all multiple pairwise comparison with Bonferroni correction)
SM651388;ped;https://pypi.org/project/ped;['https://github.com/sloria/ped'];['https://github.com/sloria/ped'];TRUE;10.1002/ece3.1261;Because reading large data files from the disk is highly time-consuming, we implemented optimized routines for data import from files with the formats ped/map and vcf (v4.1)
SM651388;ped;https://pypi.org/project/ped;['https://github.com/sloria/ped'];['https://github.com/sloria/ped'];TRUE;10.1002/evl3.103;(2010), vR?ped: vanRaden (2008) including the pedigree in the estimation, Y?ped: Yang et al
SM651388;ped;https://pypi.org/project/ped;['https://github.com/sloria/ped'];['https://github.com/sloria/ped'];TRUE;10.1007/s00414-020-02426-6;Utilities to perform the computations in this paper are provided in a R library named InbredLR, available from the first author, building on several packages in the ped suite, notably pedprobr and forrel [3]
SM652180;insol;https://pypi.org/project/insol;[None];[None];TRUE;10.1002/ece3.2001;"To identify the importance of seasonality in photoperiod for the distribution of F. distichus, we compiled two global rasters with the R packages ‘raster’ (Hijmans 2015) and ‘insol’ (Corripio 2014): (1) Summer solstice, representing the hours of daylight at midsummer (21 Jun); and (2) Winter solstice, representing the hours of daylight at the shortest day of the year (21 Dec)."
SM652180;insol;https://pypi.org/project/insol;[None];[None];TRUE;10.1002/ece3.4189;The azimuth (a) and zenith (z) of the sun were extracted using the “insol” package (Corripio, 2015)
SM652180;insol;https://pypi.org/project/insol;[None];[None];TRUE;10.1038/sdata.2018.177;The soil microclimate temperatures were divided into daytime and nighttime records by calculating the time of sunrise and sunset each day over the time period, per site, using the ‘insol’ package in R (ver
SM652180;insol;https://pypi.org/project/insol;[None];[None];TRUE;10.1038/s41598-020-63005-8;Data on river discharge, water temperature and diel period (calculated with the insol package) was assembled for each hourly increment over the duration of the study.
SM655067;cost;https://pypi.org/project/cost;[None];[None];TRUE;10.1002/ece3.2080;Summary details for studies included in cost?MA.
SM655067;cost;https://pypi.org/project/cost;[None];[None];TRUE;10.1002/ece3.2080;Another limitation of cost?MA is that we cannot distinguish between increased oxidative damage due to compensation and damage that might have occurred during the initial food restriction in the “compensatory growth” group because OS was only measured once in each individual
SM661915;nolds;https://pypi.org/project/nolds;['https://github.com/CSchoel/nolds'];['https://github.com/CSchoel/nolds'];TRUE;10.3390/e20120962;We simulated fBm signals using the Cholesky decomposition method [37] ( function of Python’s nolds library) at a Hurst exponent of H = 0.75 and five scaling coefficients D = 0.001, 0.01, 1, 10, and 100, where the value of D = 1 leads to the original form of fBm
SM661915;nolds;https://pypi.org/project/nolds;['https://github.com/CSchoel/nolds'];['https://github.com/CSchoel/nolds'];TRUE;10.1038/s41598-018-24318-x;SampE and DFA were computed using publicly available software “Nonlinear measures for dynamical systems” or nolds, version 0.3.2, which can be downloaded from (https://pypi.python.org/pypi/nolds).
SM661915;nolds;https://pypi.org/project/nolds;['https://github.com/CSchoel/nolds'];['https://github.com/CSchoel/nolds'];TRUE;10.3390/e20120962;We performed self-similarity analysis of epileptic EEG datasets by extracting their Hurst exponent through the standard rescaled range approach [38] ( function of Python’s nolds library)
SM665653;smnet;https://pypi.org/project/smnet;['https://github.com/smarsuuuuuuu/SMNet'];['https://github.com/smarsuuuuuuu/SMNet'];TRUE;10.1002/env.2340;"As such, smnet allows the user to fit spatial additive models based on P?splines, which may be particularly useful for capturing non?stationary and non?separable spatio?temporal effects; characteristics that we expect to be common in streams data (Peterson et al., 2013)"
SM665653;smnet;https://pypi.org/project/smnet;['https://github.com/smarsuuuuuuu/SMNet'];['https://github.com/smarsuuuuuuu/SMNet'];TRUE;10.1002/env.2340;Until recently, fitting these types of stream network models would have required a great deal of effort and technical expertise, but the SSN and smnet packages make these methods accessible to modellers from a wide variety of disciplines
SM666261;methylcheck;https://pypi.org/project/methylcheck;['https://github.com/FOXOBioScience/methylcheck'];['https://github.com/FOXOBioScience/methylcheck/'];TRUE;10.1186/s13072-019-0321-6;Data obtained via methylcheck python package
SM673828;mopac;https://pypi.org/project/mopac;['https://github.com/mbanders/mopac_checker'];['https://github.com/mbanders/mopac_checker'];TRUE;10.1155/2019/7523159;To understand the binding mechanisms of active constituents of gymnema leaves, molecular modelling studies were accomplished for deaclgymnemic acid, gymnemic acid, quercetin, and the aglycone moiety gymnemagenin with target proteins by the mopac 6 software package (Stewart Computational Chemistry, Colorado Springs, USA)
SM673828;mopac;https://pypi.org/project/mopac;['https://github.com/mbanders/mopac_checker'];['https://github.com/mbanders/mopac_checker'];TRUE;10.1155/2017/7496934;HNQs and FNQs were refined by the parametric method 7 (PM7) [56] and the Eigenvector Following (EF) [56] routine implemented in MOPAC2016 [52] by the Octopus Run_mopac routine, which automatically assigns the total molecular charge for each ligand and checks for errors in the structures
SM681042;sites;https://pypi.org/project/sites;[None];[None];TRUE;10.1002/2211-5463.13201;Single nucleotide polymorphisms (SNPs) were extracted from core genes using SNP?sites version 2.3.3 [50]
SM689759;edd-utils;https://pypi.org/project/edd-utils;['https://github.com/JBEI/edd-utils'];['https://github.com/JBEI/edd-utils'];TRUE;10.3389/fbioe.2021.612893;The edd-utils package uses EDD's REST API to provide a DataFrame inside of your Jupyter notebook to visualize and manipulate as desired
SM689759;edd-utils;https://pypi.org/project/edd-utils;['https://github.com/JBEI/edd-utils'];['https://github.com/JBEI/edd-utils'];TRUE;10.3389/fbioe.2021.612893;The users can run the export_study() function from the edd-utils package (see code availability) to download a study from a particular EDD instance
SM690140;DeFCoM;https://pypi.org/project/DeFCoM;['https://bitbucket.org/bryancquach/defcom'];[None];TRUE;10.3389/fbioe.2020.00886;"For example, the algorithms HINT-ATAC, DeFCoM, and Mocap each focus on identifying TF binding sites from sequencing-based footprint data (Chen et al., 2017; Quach and Furey, 2017; Li et al., 2019)"
SM690140;DeFCoM;https://pypi.org/project/DeFCoM;['https://bitbucket.org/bryancquach/defcom'];[None];TRUE;10.1186/s13059-019-1642-2;We have adapted Wellington and DeFCoM to evaluate them with PDM-based bias correction
SM690140;DeFCoM;https://pypi.org/project/DeFCoM;['https://bitbucket.org/bryancquach/defcom'];[None];TRUE;10.1186/s13059-020-1929-3;The SVM approach used in DeFCoM is more robust to outliers compared to logistic regression [131]
SM690140;DeFCoM;https://pypi.org/project/DeFCoM;['https://bitbucket.org/bryancquach/defcom'];[None];TRUE;10.1186/s13059-020-1929-3;Although more than 200 million reads per sample are recommended, DeFCoM has been described to work comparably well with fewer sequencing reads [10, 48, 131]
SM690140;DeFCoM;https://pypi.org/project/DeFCoM;['https://bitbucket.org/bryancquach/defcom'];[None];TRUE;10.1186/s13059-019-1642-2;DeFCoM, which is based on a classifier, requires TF ChIP-seq data for training a model for each individual TF and is the only method requiring training on K562 and H1-ESC cells
SM701486;spektral;https://pypi.org/project/spektral;['https://github.com/danielegrattarola/spektral'];['https://github.com/danielegrattarola/spektral'];TRUE;10.3389/fgene.2021.733906;We refer to scGAE to build a graph autoencoder that is based on TensorFlow 2.4.1 and Python package spektral 0.6.1
SM701486;spektral;https://pypi.org/project/spektral;['https://github.com/danielegrattarola/spektral'];['https://github.com/danielegrattarola/spektral'];TRUE;10.1186/s13059-020-02214-w;To construct GCNG, we used the python packages of “spektral,” “Keras,” and “Tensorflow.” See Fig. 1a for the architecture of GCNG
SM705201;TranscriptSim;https://pypi.org/project/TranscriptSim;['https://github.com/congxinxu0116/TranscriptSim'];['https://github.com/congxinxu0116/TranscriptSim'];TRUE;10.3389/fgene.2014.00342;To investigate further the dependencies of chemical similarity, biochemical similarity and transcriptional similarity we analyzed TranscriptSim vs
SM705201;TranscriptSim;https://pypi.org/project/TranscriptSim;['https://github.com/congxinxu0116/TranscriptSim'];['https://github.com/congxinxu0116/TranscriptSim'];TRUE;10.3389/fgene.2014.00342;Dissimilar compounds with high KinomePredSim and high TranscriptSim (based on L1000 in A549 cells).
SM705201;TranscriptSim;https://pypi.org/project/TranscriptSim;['https://github.com/congxinxu0116/TranscriptSim'];['https://github.com/congxinxu0116/TranscriptSim'];TRUE;10.3389/fgene.2014.00342;Pairwise TransciptSim values of these pathway-active compounds were compared to the TranscriptSim numbers of the remaining tested compounds and for each pathway the corresponding p-values were calculated
SM705201;TranscriptSim;https://pypi.org/project/TranscriptSim;['https://github.com/congxinxu0116/TranscriptSim'];['https://github.com/congxinxu0116/TranscriptSim'];TRUE;10.3389/fgene.2014.00342;For example, Figure 11 illustrates two highly similar compounds (ChemSim = 0.88) with high KinomePredSim (of 0.70) and TranscriptSim (of 0.56).
SM705201;TranscriptSim;https://pypi.org/project/TranscriptSim;['https://github.com/congxinxu0116/TranscriptSim'];['https://github.com/congxinxu0116/TranscriptSim'];TRUE;10.3389/fgene.2014.00342;Global trend of pairwise transcriptional similarity (TranscriptSim) in (A) A549 cells and (B) VCAP cells as a function of predicted kinase profile similarity (KinomePredSim) for 1027 and 741 compounds per cell line, respectively, illustrated as average TranscriptSim values by KinomePredSim ranges.
SM71816;POAP;https://pypi.org/project/POAP;['http://pypi.python.org/pypi/POAP/'];[None];TRUE;10.31557/APJCP.2019.20.11.3399;"POAP calculates the ligand binding energy and scoring based on the AutoDock Lamarckian Genetic Algorithm and free energy empirical scoring (Morris et al., 2009; Samdani and Vetrivel, 2018)"
SM71816;POAP;https://pypi.org/project/POAP;['http://pypi.python.org/pypi/POAP/'];[None];TRUE;10.3389/fmed.2021.672629;POAP implements dynamic file handling methods for efficient memory usage and data organization, ligand minimization (5,000 steps), MMFF94 force-field was employed with the addition of hydrogens
SM71816;POAP;https://pypi.org/project/POAP;['http://pypi.python.org/pypi/POAP/'];[None];TRUE;10.1038/s41598-021-92622-0;We have obtained the SMILES notations of these compounds, and generated their 3D models (in mol2 format) through the POAP Ligand Preparation pipeline
SM71816;POAP;https://pypi.org/project/POAP;['http://pypi.python.org/pypi/POAP/'];[None];TRUE;10.31557/APJCP.2019.20.11.3399;The energies obtained from POAP were compared with the ligand score identified from Schrodinger
SM71816;POAP;https://pypi.org/project/POAP;['http://pypi.python.org/pypi/POAP/'];[None];TRUE;10.31557/APJCP.2019.20.11.3399;POAP integrates the tools such as Open Babel, AutoDock, AutoDock Vina and AutoDockZN in an easily configurable Bash shell-based text interface
SM729696;httplib2;https://pypi.org/project/httplib2;['https://github.com/httplib2/httplib2'];['https://github.com/httplib2/httplib2'];TRUE;10.3389/fninf.2014.00052;Dependencies are pydicom, httplib2, and DCMTK
SM742643;openrouteservice;https://pypi.org/project/openrouteservice;['https://github.com/GIScience/openrouteservice-py'];['https://github.com/GIScience/openrouteservice-py'];TRUE;10.3389/fped.2020.00395;Then, using openrouteservice, we calculated travel time and travel distance by car from each random point to the nearest provider of each service
SM742643;openrouteservice;https://pypi.org/project/openrouteservice;['https://github.com/GIScience/openrouteservice-py'];['https://github.com/GIScience/openrouteservice-py'];TRUE;10.3389/fped.2020.00395;"Due to the limit in travel data requests per time when using openrouteservice, we calculated travel time and distance from a random sample of about 28% of the random points of each country (Germany: 100,000 points; Ireland: 20,000 points; UK: 70,000 points) to the nearest provider for each type of pediatric service"
SM798961;India;https://pypi.org/project/India;[None];[None];TRUE;10.1016/j.gfs.2019.09.002;Comparison of results: WEAI_India vs reduced_AWEAI.
SM798961;India;https://pypi.org/project/India;[None];[None];TRUE;10.1038/s41598-020-72970-z;This map was generated with ArcGIS 10.5, using World Imagery by Esri, Maxar, GeoEye, Earthstar Geographics, CNES/Airbus DS, USDA, USGS, AeroGRID, IGN and the GIS User Community (https://services.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer), and country borders according to Google Earth imagery (Google India).
SM798961;India;https://pypi.org/project/India;[None];[None];TRUE;10.1038/s41598-020-72970-z;The figures were generated with ArcGIS 10.5, using World Imagery by Esri, Maxar, GeoEye, Earthstar Geographics, CNES/Airbus DS, USDA, USGS, AeroGRID, IGN and the GIS User Community (https://services.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer), and country borders according to Google Earth imagery (Google India).
SM823557;compadre;https://pypi.org/project/compadre;['https://github.com/SNLComputation/compadre'];['https://github.com/SNLComputation/compadre'];TRUE;10.1111/1365-2664.12592;2008) where we sought all published matrix models for invasive species under management and are currently available in the compadre Plant Matrix Database (Salguero?Gomez et al
SM823557;compadre;https://pypi.org/project/compadre;['https://github.com/SNLComputation/compadre'];['https://github.com/SNLComputation/compadre'];TRUE;10.1111/1365-2745.12528;Our matrix projection models come from the compadre data base (Salguero?Gomez et al
SM823557;compadre;https://pypi.org/project/compadre;['https://github.com/SNLComputation/compadre'];['https://github.com/SNLComputation/compadre'];TRUE;10.1111/1365-2745.12528;Our study extends the breadth of these data, which is made possible by the advent of the compadre global data base of projection matrix models for plant populations (Salguero?Gomez et al
SM823557;compadre;https://pypi.org/project/compadre;['https://github.com/SNLComputation/compadre'];['https://github.com/SNLComputation/compadre'];TRUE;10.1111/1365-2745.12528;"We chose plant populations in the compadre data base (version 3.0) that satisfied three criteria: they should be represented by at least three time?dependent projection matrices; they should not be affected by experimental manipulation; they should not be the averages of multiple matrices"
SM823557;compadre;https://pypi.org/project/compadre;['https://github.com/SNLComputation/compadre'];['https://github.com/SNLComputation/compadre'];TRUE;10.1111/1365-2745.12528;In compadre, for example, there exist examples of long?lived trees that are modelled using matrices with only three life stages.
SM824960;pvr;https://pypi.org/project/pvr;[None];[None];TRUE;10.1111/jbi.12171;We used the pvr package in R (see http://cran.r-project.org/web/packages/PVR/index.html) for calculating the PSR curves for each quantitative species trait.
SM82525;SIMLR;https://pypi.org/project/SIMLR;['https://github.com/bowang87/SIMLR-PY'];['https://github.com/bowang87/SIMLR-PY'];TRUE;10.1002/1873-3468.12684;A recent method, SIMLR 37, uses multiple?kernel learning to infer similarity in a gene expression matrix with a given number of cell populations
SM82525;SIMLR;https://pypi.org/project/SIMLR;['https://github.com/bowang87/SIMLR-PY'];['https://github.com/bowang87/SIMLR-PY'];TRUE;10.7554/eLife.48994;Finally, we did not benchmark against ZIFA as it has already been shown to have lower clustering accuracy than SIMLR.
SM82525;SIMLR;https://pypi.org/project/SIMLR;['https://github.com/bowang87/SIMLR-PY'];['https://github.com/bowang87/SIMLR-PY'];TRUE;10.1242/dev.177428;Cell clustering was performed using SIMLR (package version 1.4.1) (Wang et al., 2017)
SM82525;SIMLR;https://pypi.org/project/SIMLR;['https://github.com/bowang87/SIMLR-PY'];['https://github.com/bowang87/SIMLR-PY'];TRUE;10.3389/fgene.2016.00163;SIMLR is a new clustering method designed to learn a distance metric that best fits the structure of the data
SM82525;SIMLR;https://pypi.org/project/SIMLR;['https://github.com/bowang87/SIMLR-PY'];['https://github.com/bowang87/SIMLR-PY'];TRUE;10.1093/bioinformatics/btz704;Overall, Spectrum, Seurat, SC3 and MUDAN performed similarly in these comparisons, however, SIMLR did not perform as well (Supplementary Table S2).
SM826843;ippai;https://pypi.org/project/ippai;[None];[None];TRUE;10.1117/1.JBO.26.8.085001;The simulations were performed with the open source mcx toolkit, and we used the ippai framework for the illumination modeling and data organization
SM866863;onnx;https://pypi.org/project/onnx;['https://github.com/onnx/onnx'];['https://github.com/onnx/onnx'];TRUE;10.1007/s42452-021-04588-3;After that, we used the onnx tool, onnx-TensorRT tool, to convert onnx to TensorRT
SM86948;GDW;https://pypi.org/project/GDW;[None];[None];TRUE;10.1186/1471-2105-11-558;The images before and after processed by GDW.
SM86948;GDW;https://pypi.org/project/GDW;[None];[None];TRUE;10.3389/fpubh.2019.00317;GDW also contains a cluster extraction functionality which allows users to search for SNP clusters based on desired temporal, size, and SNP distance level thresholds
SM885970;ffp;https://pypi.org/project/ffp;['https://github.com/sebpuetz/ffp'];['https://github.com/sebpuetz/ffp'];TRUE;10.1038/srep28970;The computational complexity of all the AF methods can be found in previous studies25262730313436 and ranges from O(n) for ffp, to O(k?×?n?×?z) for kmacs, with n the number of sequences, k the number of mismatches and z the average number of matches between two sequences
SM91616;glib;https://pypi.org/project/glib;[None];[None];TRUE;10.1186/1471-2105-6-31;It is built using the glib portabilility library available from Both exonerate and glib are available under the GNU lesser general public license
SM91616;glib;https://pypi.org/project/glib;[None];[None];TRUE;10.3390/s150304677;Linux based operating systems uses elf ? loader (from glib ? c library) to open binary files and load them into the memory
SM917025;btrtools;https://pypi.org/project/btrtools;[None];[None];TRUE;10.1038/s41598-019-51360-0;The BayesTraits outputs files were analyzed in R with the BayesTraits wrapper (btw) by Randi H Griffin (http://rgriff23.github.io/projects/btw.html) and other functions from btrtools and BTprocessR (https://github.com/hferg)
SM932457;cytoflow;https://pypi.org/project/cytoflow;['https://github.com/cytoflow/cytoflow'];['https://github.com/cytoflow/cytoflow'];TRUE;10.1038/s41598-021-86135-z;The data from the flow cytometry was imported and analysed in Python 3.5 using the cytoflow library
SM932547;mord;https://pypi.org/project/mord;['https://pypi.python.org/pypi/mord'];[None];TRUE;10.1038/s41598-021-86538-y;For that, we use the ordinal logistic regression model available in the software mord developed by Pedregosa-Izquierdo.
SM967339;CoAPthon;https://pypi.org/project/CoAPthon;['https://github.com/Tanganelli/CoAPthon'];['https://github.com/Tanganelli/CoAPthon'];TRUE;10.3390/s19030716;For CoAP, CoAPthon [21], an open-source implementation, was employed to simulate communications and messages were collected from the communication channel
SM967339;CoAPthon;https://pypi.org/project/CoAPthon;['https://github.com/Tanganelli/CoAPthon'];['https://github.com/Tanganelli/CoAPthon'];TRUE;10.3390/s19245467;Hence, a variety of IoT libraries, such as CoAPthon [27], and frameworks [28], such as IDeA, FRASAD, D-LITe, IoTLink, WebRTC based IoT application Framework, Datatweet, IoTSuite and RapIoT, have been developed to manage those complexities.
SM989233;OpenHands;https://pypi.org/project/OpenHands;['https://openhands.ai4bharat.org'];['https://github.com/AI4Bharat/OpenHands'];TRUE;10.3390/s21041525;(a) Talked, (b) OpenHands, (c) Watching public.
