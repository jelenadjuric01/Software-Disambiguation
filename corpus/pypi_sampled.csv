ID;software_mention;package_url;homepage_url;github_repo;exact_match;doi;paragraph
SM1000082;pytplot;https://pypi.org/project/pytplot,https://github.com/MAVENSDC/pytplot;['https://github.com/MAVENSDC/pytplot'];['https://github.com/MAVENSDC/pytplot'];TRUE;10.1007/s11214-018-0576-4;Under the PySPEDAS structure, “*_load_xxx” routines have been developed to access CDF files and import data to populate pytplot variables in a generic way
SM1003436;strand;https://cran.r-project.org/package=strand,https://github.com/strand-tech/strand;;;TRUE;10.1002/sim.8065;Only the data are required, a choice of gates and an indication of the amount of data to be apportioned as pilot data, to implement the essential form of the STRAND Chart using the R package “strand” (available from the author).
SM1003436;strand;https://pypi.org/project/strand,https://github.com/i2mint/strand;https://github.com/i2mint/strand;['https://github.com/i2mint/strand'];FALSE;10.1002/sim.8065;Only the data are required, a choice of gates and an indication of the amount of data to be apportioned as pilot data, to implement the essential form of the STRAND Chart using the R package “strand” (available from the author).
SM1007307;swirl;https://cran.r-project.org/package=swirl,https://swirlstats.com/;;;TRUE;10.1111/test.12258;The swirl R package aims to teach R programming and data science interactively and directly from within the R console
SM1007307;swirl;https://pypi.org/project/swirl,http://code.naeseth.com/swirl/;http://code.naeseth.com/swirl/;;FALSE;10.1111/test.12258;The swirl R package aims to teach R programming and data science interactively and directly from within the R console
SM107466;TreeToReads;https://pypi.org/project/TreeToReads,https://github.com/snacktavish/TreeToReads;['https://github.com/snacktavish/TreeToReads'];;TRUE;10.1186/s12859-017-1592-1;TreeToReads allows researchers to test the joint effects of multiple parameter values on the ability of any analysis pipeline to recover the signal and infer the correct tree
SM107466;TreeToReads;https://pypi.org/project/TreeToReads,https://github.com/snacktavish/TreeToReads;['https://github.com/snacktavish/TreeToReads'];;TRUE;10.1099/mgen.0.000261;Considering that TreeToReads does not simulate SVs, this result indicates that real, complex variants between the reference and root sequence used in the first benchmark surely caused many false-positive SNP calls and enabled realistic evaluation of the accuracy.
SM107466;TreeToReads;https://pypi.org/project/TreeToReads,https://github.com/snacktavish/TreeToReads;['https://github.com/snacktavish/TreeToReads'];;TRUE;10.7717/peerj.3893;The simulated dataset was created using the TreeToReads v 0.0.5 (McTavish et al., 2017), which takes as input a tree file (true phylogeny), an anchor genome, and a set of user-defined parameter values
SM107466;TreeToReads;https://pypi.org/project/TreeToReads,https://github.com/snacktavish/TreeToReads;['https://github.com/snacktavish/TreeToReads'];;TRUE;10.1186/s12859-017-1592-1;Anchoring an observed genome to a tip in a tree using TreeToReads allows us to test choices about selection of reference genomes in a way that is directly comparable to empirical data
SM107466;TreeToReads;https://pypi.org/project/TreeToReads,https://github.com/snacktavish/TreeToReads;['https://github.com/snacktavish/TreeToReads'];;TRUE;10.1186/s12859-017-1592-1;If ART is invoked in TreeToReads the program will output a folder labeled ‘fastq’ containing directories labeled with the names of each tip from the simulation tree, in which the simulated reads are deposited in.fastq.gz formats
SM1077143;kontroller;https://pypi.org/project/kontroller,https://github.com/caruccio/kontroller;;;FALSE;10.7554/eLife.27670;Using kontroller to automate the process, we performed a direct search on hardware to find the best distribution of control signals that was closest to the desired Gaussian distribution
SM1077143;kontroller;https://github.com/emonetlab/kontroller;;;TRUE;10.7554/eLife.27670;Using kontroller to automate the process, we performed a direct search on hardware to find the best distribution of control signals that was closest to the desired Gaussian distribution
SM1077143;kontroller;https://pypi.org/project/kontroller,https://github.com/caruccio/kontroller;;;FALSE;10.7554/eLife.27670;We wrote a general-purpose acquisition and control system called kontroller (available at https://github.com/emonetlab/kontroller) in MATLAB (Mathworks, Inc.) to control MFCs, valves and LEDs and to collect data from electrophysiology and the stimulus measurement.
SM1077143;kontroller;https://github.com/emonetlab/kontroller;;;TRUE;10.7554/eLife.27670;We wrote a general-purpose acquisition and control system called kontroller (available at https://github.com/emonetlab/kontroller) in MATLAB (Mathworks, Inc.) to control MFCs, valves and LEDs and to collect data from electrophysiology and the stimulus measurement.
SM146580;biopy;https://pypi.org/project/biopy,https://github.com/BioPyTeam/biopy;;;FALSE;10.1186/1471-2148-12-23;Tree files were summarized in biopy v0.1.2 [104], the posterior was resampled, and the variance among 100 random resampled species trees was visualized in DensiTree [105]
SM146580;biopy;https://pypi.org/project/biopy,https://github.com/BioPyTeam/biopy;;;FALSE;10.1186/1471-2148-13-221;The methods are implemented in biopy [9], and integrated with DensiTree, making it easy to examine the summary tree in the context of the full posterior.
SM146580;biopy;https://github.com/jheled/biopy;;;TRUE;10.1186/1471-2148-12-23;Tree files were summarized in biopy v0.1.2 [104], the posterior was resampled, and the variance among 100 random resampled species trees was visualized in DensiTree [105]
SM146580;biopy;https://github.com/jheled/biopy;;;TRUE;10.1186/1471-2148-13-221;The methods are implemented in biopy [9], and integrated with DensiTree, making it easy to examine the summary tree in the context of the full posterior.
SM146580;biopy;https://github.com/jheled/biopy;;;TRUE;10.1093/molbev/msx126;Simulated trees were generated using biopy, and trees sampled from a prior distribution were generated using StarBEAST2 with all new features enabled
SM146580;biopy;https://github.com/jheled/biopy;;;TRUE;10.1093/sysbio/syv118;Sequence alignments were also simulated using biopy for experiments 1 and 2, and Seq-Gen (Rambaut and Grass 1997) was used to simulate nucleotide alignments for experiment 3.
SM146580;biopy;https://pypi.org/project/biopy,https://github.com/BioPyTeam/biopy;;;FALSE;10.1093/molbev/msx126;Simulated trees were generated using biopy, and trees sampled from a prior distribution were generated using StarBEAST2 with all new features enabled
SM146580;biopy;https://pypi.org/project/biopy,https://github.com/BioPyTeam/biopy;;;FALSE;10.1093/sysbio/syv118;Sequence alignments were also simulated using biopy for experiments 1 and 2, and Seq-Gen (Rambaut and Grass 1997) was used to simulate nucleotide alignments for experiment 3.
SM146580;biopy;https://pypi.org/project/biopy,https://github.com/BioPyTeam/biopy;;;FALSE;10.1093/molbev/msx126;For all simulations, the version of biopy (Heled, unpublished data) used was 0.1.9
SM146580;biopy;https://github.com/jheled/biopy;;;TRUE;10.1093/molbev/msx126;For all simulations, the version of biopy (Heled, unpublished data) used was 0.1.9
SM16201;X!tandem;https://pypi.org/project/tandem,https://github.com/philippeller/dragoman;;;FALSE;10.1186/1471-2105-12-439;The results on elution peak identification coverage using MaxQuant and X!tandem are summarized in Table 4
SM16201;X!tandem;https://pypi.org/project/tandem,https://github.com/philippeller/dragoman;;;FALSE;10.1371/journal.pgen.1006909;Protein identification was performed with X!Tandem software (DB: X!tandem version 2013.09.01.1) against a protein database of B
SM16201;X!tandem;https://www.thegpm.org/tandem/;;;TRUE;10.1186/1471-2105-12-439;The results on elution peak identification coverage using MaxQuant and X!tandem are summarized in Table 4
SM16201;X!tandem;https://www.thegpm.org/tandem/;;;TRUE;10.1371/journal.pgen.1006909;Protein identification was performed with X!Tandem software (DB: X!tandem version 2013.09.01.1) against a protein database of B
SM16201;tandem;https://tandem.bu.edu/trf/trf.html,https://github.com/Benson-Genomics-Lab/TRF;;;TRUE;10.1186/s12864-021-07626-x;Furthermore, tandem repeat Finder version 4.07 [88], with default settings, was used to calculate tandem repeats in these cp genomes.
SM16201;tandem;https://tandem.bu.edu/trf/trf.html,https://github.com/Benson-Genomics-Lab/TRF;;;TRUE;10.1128/genomeA.01271-17;The obtained data were assembled de novo using the Hierarchical Genome Assembly Process (HGAP version 3.0) and annotated with Prodigal version 2.50 (2), tandem repeats finder software (3), tRNAscan-SE (4), and RNAmmer (5)
SM16201;tandem;https://tandem.bu.edu/trf/trf.html,https://github.com/Benson-Genomics-Lab/TRF;;;TRUE;10.1186/s12864-015-2324-4;The identification of tandem repeat sequences was performed with the software tandem repeats finder [34] using the whole-genome sequence of all W
SM16201;tandem;https://pypi.org/project/tandem,https://github.com/philippeller/dragoman;;;FALSE;10.1186/s12864-021-07626-x;Furthermore, tandem repeat Finder version 4.07 [88], with default settings, was used to calculate tandem repeats in these cp genomes.
SM16201;tandem;https://pypi.org/project/tandem,https://github.com/philippeller/dragoman;;;FALSE;10.1128/genomeA.01271-17;The obtained data were assembled de novo using the Hierarchical Genome Assembly Process (HGAP version 3.0) and annotated with Prodigal version 2.50 (2), tandem repeats finder software (3), tRNAscan-SE (4), and RNAmmer (5)
SM16201;tandem;https://pypi.org/project/tandem,https://github.com/philippeller/dragoman;;;FALSE;10.1186/s12864-015-2324-4;The identification of tandem repeat sequences was performed with the software tandem repeats finder [34] using the whole-genome sequence of all W
SM168910;Pygments;https://pypi.org/project/Pygments,https://pygments.org/,https://github.com/pygments/pygments;;;TRUE;10.1186/s12864-016-3278-x;Code syntax was highlighted using Pygments version 2.2 [33].
SM174676;tripal;https://pypi.org/project/tripal,https://github.com/galaxy-genome-annotation/python-tripal;;;FALSE;10.1186/1471-2164-15-786;GFF3 files, sequences and BLAST results were loaded into the koala genome database with tools from the tripal toolkit
SM174676;tripal;https://pypi.org/project/tripal,https://github.com/galaxy-genome-annotation/python-tripal;;;FALSE;10.3389/fpls.2018.00418;The tripal toolkit for genome database construction
SM174676;tripal;https://tripal.info/,https://github.com/tripal/tripal;;;TRUE;10.1186/1471-2164-15-786;GFF3 files, sequences and BLAST results were loaded into the koala genome database with tools from the tripal toolkit
SM174676;tripal;https://tripal.info/,https://github.com/tripal/tripal;;;TRUE;10.3389/fpls.2018.00418;The tripal toolkit for genome database construction
SM200861;Aeon;https://pypi.org/project/Aeon,https://github.com/logicabrity/aeon;;;FALSE;10.7717/peerj.9965;It features Intel Haswell processors with AVX2, Mellanox FDR InfiniBand interconnects, and Aeon storage (Moore et al., 2014)
SM200861;Aeon;https://pypi.org/project/Aeon,https://github.com/logicabrity/aeon;;;FALSE;10.7554/eLife.49855;The corresponding minimal cylinder radius that allows for the observation of significant , , 1.41 µm and 3.24 µm for Aeon, Connectom, and Prisma, respectively, is indicated by the vertical lines. In all plots, diffusivities and radii are expressed in  and , respectively.
SM204771;django-blastplus;https://pypi.org/project/django-blastplus,https://github.com/michal-stuglik/django-blastplus;;;TRUE;10.1186/s12920-018-0430-2;The BLAST server was constructed by django-blastplus (version 0.4.0) and NCBI BLAST+ (version 2.3.0) [43]
SM247954;treehouse;https://github.com/JLSteenwyk/treehouse;;;TRUE;10.1186/s13104-019-4577-5;Curated phylogenies currently available in treehouse’s database
SM247954;treehouse;https://github.com/JLSteenwyk/treehouse;;;TRUE;10.1186/s13104-019-4577-5;We also anticipate treehouse to be a useful teaching tool.
SM247954;treehouse;https://github.com/JLSteenwyk/treehouse;;;TRUE;10.1186/s13104-019-4577-5;B Treehouse’s user interface features a navigation bar (a) to toggle between phylogenies available in treehouse’s databases for animals, fungi, plants, and the tree of life (left) and a user provided phylogeny in userTree (right)
SM247954;treehouse;https://github.com/JLSteenwyk/treehouse;;;TRUE;10.1186/s13104-019-4577-5;b To enable easy usage of treehouse, quick start directions are displayed
SM247954;treehouse;https://pypi.org/project/treehouse;['https://github.com/jaraco/treehouse'];['https://github.com/jaraco/treehouse'];FALSE;10.1186/s13104-019-4577-5;Curated phylogenies currently available in treehouse’s database
SM247954;treehouse;https://pypi.org/project/treehouse;['https://github.com/jaraco/treehouse'];['https://github.com/jaraco/treehouse'];FALSE;10.1371/journal.pcbi.1007753;- The authors analysed 5 pediatric tumour datasets from UCSC treehouse compendium
SM247954;treehouse;https://pypi.org/project/treehouse;['https://github.com/jaraco/treehouse'];['https://github.com/jaraco/treehouse'];FALSE;10.1186/s13104-019-4577-5;We also anticipate treehouse to be a useful teaching tool.
SM247954;treehouse;https://pypi.org/project/treehouse;['https://github.com/jaraco/treehouse'];['https://github.com/jaraco/treehouse'];FALSE;10.1186/s13104-019-4577-5;B Treehouse’s user interface features a navigation bar (a) to toggle between phylogenies available in treehouse’s databases for animals, fungi, plants, and the tree of life (left) and a user provided phylogeny in userTree (right)
SM247954;treehouse;https://pypi.org/project/treehouse;['https://github.com/jaraco/treehouse'];['https://github.com/jaraco/treehouse'];FALSE;10.1186/s13104-019-4577-5;b To enable easy usage of treehouse, quick start directions are displayed
SM248407;ads;https://pypi.org/project/ads,http://www.github.com/andycasey/ads/;;;FALSE;10.1186/s13104-015-1722-7;Data processing was performed using customised software (ads, Version 4.01, UK Labs, Kempten, Germany).
SM248407;ads;https://pypi.org/project/ads,http://www.github.com/andycasey/ads/;;;FALSE;10.1002/ece3.4592;The L 12 (r)?function was calculated between 1 m and 10 m for distance r by using the package ads (Pélissier & Goreaud, 2015) for free statistical software R (R Core Team, 2017)
SM248407;ads;https://cran.r-project.org/package=ads,https://forge.ird.fr/amap/ads;;;TRUE;10.1002/ece3.4592;The L 12 (r)?function was calculated between 1 m and 10 m for distance r by using the package ads (Pélissier & Goreaud, 2015) for free statistical software R (R Core Team, 2017)
SM248407;ads;https://pypi.org/project/ads,http://www.github.com/andycasey/ads/;;;FALSE;10.1155/2018/9319258;Strain gauge, force plate, EMG, and accelerometer signals were amplified using a custom-built universal amplifier (UMV, uk-labs, Kempen, Germany) and sampled at a rate of 1?kHz using the software package ads (version 1.12, uk-labs, Kempen, Germany), whereas the Locomètre signals were recorded without additional amplification using a software package provided by the manufacturer.
SM263514;pyphysio;https://pypi.org/project/pyphysio,https://github.com/MPBA/pyphysio;;;TRUE;10.3390/s20236778;The processing pipeline was developed in Python, based on pyphysio [39], and it is publicly available at https://gitlab.com/abp-san-public/wearable-clinical-devices.
SM263514;physynch;https://gitlab.com/abp-san-public/physynch;;;TRUE;10.3390/bs10010011;For the analysis of the physiological signals and the computation of the physiological synchrony, we used custom scripts based on pyphysio [33,34], physynch [35], and PySiology [36].
SM263514;PySiology;https://pypi.org/project/pysiology/,https://github.com/Gabrock94/Pysiology;;;TRUE;10.3390/bs10010011;For the analysis of the physiological signals and the computation of the physiological synchrony, we used custom scripts based on pyphysio [33,34], physynch [35], and PySiology [36].
SM263514;pyphysio;https://pypi.org/project/pyphysio,https://github.com/MPBA/pyphysio;;;TRUE;10.3390/bs10010011;For the analysis of the physiological signals and the computation of the physiological synchrony, we used custom scripts based on pyphysio [33,34], physynch [35], and PySiology [36].
SM263514;pyphysio;https://pypi.org/project/pyphysio,https://github.com/MPBA/pyphysio;;;TRUE;10.3390/s20226616;Future work should also consider additional HRV components such as the low frequency: high frequency ratio or percentage of consecutive normal R-peaks differing by at least 50 milliseconds, which can be analyzed using Kubios HRV [21] or open-source physiological signal analysis packages such as pyphysio [33].
SM263514;pyphysio;https://pypi.org/project/pyphysio,https://github.com/MPBA/pyphysio;;;TRUE;10.3390/brainsci11030336;Physiological signals of EDA and ECG have been recorded with a Biopac MP160 at a 2000 Hz sampling rate and processed with Python’s “pyphysio” library [41] for indexes extraction.
SM263514;physynch;https://gitlab.com/abp-san-public/physynch;;;TRUE;10.1038/s41598-020-63596-2;The computation of synchrony was performed using a custom code based on pyphysio and physynch packages.
SM263514;pyphysio;https://pypi.org/project/pyphysio,https://github.com/MPBA/pyphysio;;;TRUE;10.1038/s41598-020-63596-2;The computation of synchrony was performed using a custom code based on pyphysio and physynch packages.
SM274329;eQTLseq;https://pypi.org/project/eQTLseq,https://github.com/dvav/eQTLseq;;;TRUE;10.1093/bioinformatics/btx355; eQTLseq requires appropriately transformed expression data as input, when a Normal model is selected
SM274329;eQTLseq;https://pypi.org/project/eQTLseq,https://github.com/dvav/eQTLseq;;;TRUE;10.1093/bioinformatics/btx355;All methods are implemented in the freely available Python software eQTLseq (https://github.com/dvav/eQTLseq).
SM274329;eQTLseq;https://pypi.org/project/eQTLseq,https://github.com/dvav/eQTLseq;;;TRUE;10.1093/bioinformatics/btx355;eQTLseq (Fig
SM274329;eQTLseq;https://pypi.org/project/eQTLseq,https://github.com/dvav/eQTLseq;;;TRUE;10.1093/bioinformatics/btx355;Availability and implementation All methods are implemented in the free software eQTLseq : https://github.com/dvav/eQTLseq Supplementary information Supplementary data are available at Bioinformatics online.
SM274329;eQTLseq;https://pypi.org/project/eQTLseq,https://github.com/dvav/eQTLseq;;;TRUE;10.1093/bioinformatics/btx355;eQTLseq takes matrices X and Z (or Y, a transformed version of Z) as input and employs Gibbs sampling (Andrieu ) to estimate an M?×?K matrix of regression coefficients B
SM28139;venn;https://pypi.org/project/venn;;;FALSE;10.3389/fmicb.2019.02736;Venn diagrams were calculated and plotted using venn version 1.7 R package
SM28139;venn;https://pypi.org/project/venn;;;FALSE;10.3390/ijms21176060;A Venn diagram comparing the five experimental groups was generated with library “venn” (Dusa 2018) in R 3.5.1 (R Core Team 2018) [129].
SM28139;venn;https://pypi.org/project/venn;;;FALSE;10.3389/fonc.2021.631803;The “edgeR” package was used to explore differential genes between high and low expression groups of m6A “eraser” FTO/ALKBH5, and the common differential expression genes were obtained using the “venn” package
SM28139;venn;https://pypi.org/project/venn;;;FALSE;10.1371/journal.pbio.0050057;Venn diagram analyses were done using the venn package (v1.5) for the statistical programming package, R (http://www.stats.uwo.ca/faculty/murdoch/software).
SM28139;venn;https://pypi.org/project/venn;;;FALSE;10.1371/journal.pone.0118867;Shared and private alleles were plotted with gplots R library with venn package [20].
SM28139;venn;https://cran.r-project.org/package=venn,https://github.com/dusadrian/venn;;;TRUE;10.3389/fmicb.2019.02736;Venn diagrams were calculated and plotted using venn version 1.7 R package
SM28139;venn;https://cran.r-project.org/package=venn,https://github.com/dusadrian/venn;;;TRUE;10.3390/ijms21176060;A Venn diagram comparing the five experimental groups was generated with library “venn” (Dusa 2018) in R 3.5.1 (R Core Team 2018) [129].
SM28139;edgeR;https://bioconductor.org/packages/release/bioc/html/edgeR.html;;;TRUE;10.3389/fonc.2021.631803;The “edgeR” package was used to explore differential genes between high and low expression groups of m6A “eraser” FTO/ALKBH5, and the common differential expression genes were obtained using the “venn” package
SM28139;venn;https://cran.r-project.org/package=venn,https://github.com/dusadrian/venn;;;TRUE;10.3389/fonc.2021.631803;The “edgeR” package was used to explore differential genes between high and low expression groups of m6A “eraser” FTO/ALKBH5, and the common differential expression genes were obtained using the “venn” package
SM28139;venn;https://cran.r-project.org/package=venn,https://github.com/dusadrian/venn;;;TRUE;10.1371/journal.pbio.0050057;Venn diagram analyses were done using the venn package (v1.5) for the statistical programming package, R (http://www.stats.uwo.ca/faculty/murdoch/software).
SM28139;venn;https://cran.r-project.org/package=venn,https://github.com/dusadrian/venn;;;TRUE;10.1371/journal.pone.0118867;Shared and private alleles were plotted with gplots R library with venn package [20].
SM313072;ngCGH;https://pypi.org/project/ngCGH,http://github.com/seandavi/ngCGH;;;TRUE;10.18632/oncotarget.15932;"We also evaluated the ability of the CNA calling tools (CODEX, ngCGH, and falcon) that subcategorize gain and loss events (amplification, +2; duplication, +1; deletion, -1; homozygous deletion, -2) (Supplementary Figure 3) to estimate amplifications and homozygous deletions"
SM313072;ngCGH;https://pypi.org/project/ngCGH,http://github.com/seandavi/ngCGH;;;TRUE;10.1002/cam4.3370;For copy number analysis, We used version 0.4.4 of the ngCGH python package to generate aCGH?like data from the WES data
SM313072;ngCGH;https://pypi.org/project/ngCGH,http://github.com/seandavi/ngCGH;;;TRUE;10.18632/oncotarget.11922;For copy number analysis from the exome sequencing data, ngCGH and RankSegmentation statistical algorithm in NEXUS software v7.5 were used
SM313072;ngCGH;https://pypi.org/project/ngCGH,http://github.com/seandavi/ngCGH;;;TRUE;10.18632/oncotarget.23975;The ngCGH python package was used to generate aCGH-like data from whole exome sequencing (WES)
SM313072;ngCGH;https://pypi.org/project/ngCGH,http://github.com/seandavi/ngCGH;;;TRUE;10.1371/journal.pcbi.1004873;Tools have been developed for copy number analysis of these datasets, as well, including CNVer [6], ExomeCNV [7], exomeCopy [8], CONTRA [9], CoNIFER [10], ExomeDepth [11], VarScan 2 [12], XHMM [13], ngCGH [14], EXCAVATOR [15], CANOES [16], PatternCNV [17], CODEX [18], and recent versions of Control-FREEC [19] and cn.MOPS [20]
SM33148;sst;https://pypi.org/project/sst,http://testutils.org/sst;;;TRUE;10.1371/journal.pone.0129674;To compare our algorithm with the five programs (kaksi, plasse, stick, stlsstr and sst) that we are not able to obtain a local copy we have uploaded to a web server [23] a set of 100 x-ray protein structures (set ??) with the first 50 structures having resolutions between 1.0Å–2.0Å and the rest having resolutions ? 2.5Å(1AKG,1BGF,1EZW,1GSU,1I1N,1K1B,1NTE,1O98,1PVM,1SJD,1UKF,1VZY,1XGW,1YQD,2ASC, 2BJI, 2CWH,2FD5,2GB2, 2GG6,2H1V,2I2C,2NSF, 2POK,2VBA,2W6K,2WRA,2X7H,2YSK,2ZJ3,3C9U,3EDF, 3GG7,3HG7,3IDV,3LCC,3LFJ,3
SM33148;sst;https://pypi.org/project/sst,http://testutils.org/sst;;;TRUE;10.1371/journal.pone.0129674;Due to the difficulty of obtaining a local copy for the programs palsse, stick, xtlsstr, kaksi and sst we have tested them on the set ?? of 100 selected x-ray structures by uploading each one to a web server [23] to obtain their assignments (Table 4)
SM35267;QCluster;https://pypi.org/project/Qcluster,https://github.com/QsonLabs/qcluster;;;FALSE;10.1186/s13015-014-0029-x;We apply QCluster using different distances, to the whole set of reads and then we measure the quality of the clusters produced by evaluating the extent to which the partitioning agrees with the natural splitting of the sequences
SM35267;QCluster;https://pypi.org/project/Qcluster,https://github.com/QsonLabs/qcluster;;;FALSE;10.1186/s13015-014-0029-x;These statistics are implemented in a software called QCluster (http://www.dei.unipd.it/~ciompin/main/qcluster.html).
SM35267;QCluster;https://pypi.org/project/Qcluster,https://github.com/QsonLabs/qcluster;;;FALSE;10.1186/s13015-014-0029-x;All these measures are implemented in a software called QCluster
SM35267;QCluster;https://pypi.org/project/Qcluster,https://github.com/QsonLabs/qcluster;;;FALSE;10.1186/s13015-014-0029-x;Both these approximations are implemented within the software QCluster and tests are presented in the Experimental Results section.
SM35267;QCluster;https://pypi.org/project/Qcluster,https://github.com/QsonLabs/qcluster;;;FALSE;10.1186/s13015-014-0029-x;Starting from this software we developed QCluster by incorporating the computation of the -type statistics described above using both AWP and AQP prior probability estimators and the redistribution of quality values.
SM35267;QCluster;https://github.com/CominLab/Qcluster;;;TRUE;10.1186/s13015-014-0029-x;We apply QCluster using different distances, to the whole set of reads and then we measure the quality of the clusters produced by evaluating the extent to which the partitioning agrees with the natural splitting of the sequences
SM35267;QCluster;https://github.com/CominLab/Qcluster;;;TRUE;10.1186/s13015-014-0029-x;These statistics are implemented in a software called QCluster (http://www.dei.unipd.it/~ciompin/main/qcluster.html).
SM35267;QCluster;https://github.com/CominLab/Qcluster;;;TRUE;10.1186/s13015-014-0029-x;All these measures are implemented in a software called QCluster
SM35267;QCluster;https://github.com/CominLab/Qcluster;;;TRUE;10.1186/s13015-014-0029-x;Both these approximations are implemented within the software QCluster and tests are presented in the Experimental Results section.
SM35267;QCluster;https://github.com/CominLab/Qcluster;;;TRUE;10.1186/s13015-014-0029-x;Starting from this software we developed QCluster by incorporating the computation of the -type statistics described above using both AWP and AQP prior probability estimators and the redistribution of quality values.
SM366486;arcgis;https://pypi.org/project/arcgis,https://developers.arcgis.com/python/;;;FALSE;10.1002/ece3.4292;Sidescan sonar data were accessed using the arcgis 10.1 software package for visualization and interpretation in order to determine the spatial extent of S. spinulosa reef
SM366486;arcgis;https://pypi.org/project/arcgis,https://developers.arcgis.com/python/;;;FALSE;10.1111/eva.12161;Landscape composition (percentage of a given buffer covered by each habitat type) was calculated using hawth’s tools (Beyer 2004) in arcgis 9.2
SM366486;arcgis;https://pypi.org/project/arcgis,https://developers.arcgis.com/python/;;;FALSE;10.1111/zph.12827;"provinces) of the study area, the distribution of the animal samples was depicted using the arcgis software (version 10.3; ESRI, Redlands, CA, USA)"
SM366486;arcgis;https://pypi.org/project/arcgis,https://developers.arcgis.com/python/;;;FALSE;10.1111/ppl.12144;Data were mapped using arcgis (Version 9.3, ESRI, Redlands, CA)
SM366486;arcgis;https://pypi.org/project/arcgis,https://developers.arcgis.com/python/;;;FALSE;10.1111/eva.12240;Spatial mapping of plant traits and canonical variates predicted from regression models was completed using the grid algebra function (raster calculator) of the arcgis 9.3 Spatial Analyst extension (ESRI, Redlands, CA, USA)
SM366486;arcgis;https://www.arcgis.com/index.html,https://www.esri.com/en-us/arcgis/geospatial-platform/overview;;;TRUE;10.1002/ece3.4292;Sidescan sonar data were accessed using the arcgis 10.1 software package for visualization and interpretation in order to determine the spatial extent of S. spinulosa reef
SM366486;arcgis;https://www.arcgis.com/index.html,https://www.esri.com/en-us/arcgis/geospatial-platform/overview;;;TRUE;10.1111/eva.12161;Landscape composition (percentage of a given buffer covered by each habitat type) was calculated using hawth’s tools (Beyer 2004) in arcgis 9.2
SM366486;arcgis;https://www.arcgis.com/index.html,https://www.esri.com/en-us/arcgis/geospatial-platform/overview;;;TRUE;10.1111/zph.12827;"provinces) of the study area, the distribution of the animal samples was depicted using the arcgis software (version 10.3; ESRI, Redlands, CA, USA)"
SM366486;arcgis;https://www.arcgis.com/index.html,https://www.esri.com/en-us/arcgis/geospatial-platform/overview;;;TRUE;10.1111/ppl.12144;Data were mapped using arcgis (Version 9.3, ESRI, Redlands, CA)
SM366486;arcgis;https://www.arcgis.com/index.html,https://www.esri.com/en-us/arcgis/geospatial-platform/overview;;;TRUE;10.1111/eva.12240;Spatial mapping of plant traits and canonical variates predicted from regression models was completed using the grid algebra function (raster calculator) of the arcgis 9.3 Spatial Analyst extension (ESRI, Redlands, CA, USA)
SM395048;summarytools;https://cran.r-project.org/package=summarytools,https://github.com/dcomtois/summarytools;;;TRUE;10.1371/journal.pone.0228262;The analyses were carried out using the packages summarytools and MASS (function polr) in R.
SM395048;summarytools;https://cran.r-project.org/package=summarytools,https://github.com/dcomtois/summarytools;;;TRUE;10.1186/s41155-021-00194-9;All the analysis was conducted in the R software (R Core Team, 2021) using the packages summarytools (Comtois, 2021), polycor (Fox, 2019), GGally (Schloerke et al., 2021), CTT (Willse, 2018), lavaan (Rosseel, 2012), nFactors (Raiche & Magis, 2020), psych (Revelle, 2020)
SM395048;summarytools;https://cran.r-project.org/package=summarytools,https://github.com/dcomtois/summarytools;;;TRUE;10.1371/journal.pone.0239639;Various R packages [76] run in R-studio v.1.2.5033 were used for statistical analyses and plot construction: summarytools library [77] was used for obtaining basal descriptive statistics, ggplot2 library [78] was used to analyze Pearson correlation and plot the result as well as for creating boxplots and histograms, posthoc.kruskal.dunn.test function in the PMCMR library [79] was used for the posthoc Dunn’s test, the FSA library [80] was used to conduct the Mann-Whitney U test, the prcomp function [76] was 
SM395048;summarytools;https://cran.r-project.org/package=summarytools,https://github.com/dcomtois/summarytools;;;TRUE;10.2196/25124;R 3.2.2 (R Development Core Team) software [23] was used on every statistical step of this work: discretization of continuous variables (package car [24]), descriptive and comparative analyses (packages gmodels [25] and epitools [26]), missing data analysis (package summarytools [27]), missing data imputation (package DMwR [28]), hierarchical clustering (package stats [23]), Bayesian network inference (packages bnlearn [29] and gRain [30]), and ROC curve analysis (package pROC [31])
SM395048;dplyr;https://cran.r-project.org/package=dplyr,https://dplyr.tidyverse.org/,https://github.com/tidyverse/dplyr;;;TRUE;10.3390/jpm11060512;R-package ‘dplyr’ was used for data manipulation [28], and R-package ‘summarytools’ was used for frequencies tables, cross-tabulation, and other descriptive statistics [29]
SM395048;summarytools;https://cran.r-project.org/package=summarytools,https://github.com/dcomtois/summarytools;;;TRUE;10.3390/jpm11060512;R-package ‘dplyr’ was used for data manipulation [28], and R-package ‘summarytools’ was used for frequencies tables, cross-tabulation, and other descriptive statistics [29]
SM395048;summarytools;https://pypi.org/project/summarytools,https://github.com/6chaoran/jupyter-summarytools;;;FALSE;10.1371/journal.pone.0228262;The analyses were carried out using the packages summarytools and MASS (function polr) in R.
SM395048;summarytools;https://pypi.org/project/summarytools,https://github.com/6chaoran/jupyter-summarytools;;;FALSE;10.1186/s41155-021-00194-9;All the analysis was conducted in the R software (R Core Team, 2021) using the packages summarytools (Comtois, 2021), polycor (Fox, 2019), GGally (Schloerke et al., 2021), CTT (Willse, 2018), lavaan (Rosseel, 2012), nFactors (Raiche & Magis, 2020), psych (Revelle, 2020)
SM395048;summarytools;https://pypi.org/project/summarytools,https://github.com/6chaoran/jupyter-summarytools;;;FALSE;10.1371/journal.pone.0239639;Various R packages [76] run in R-studio v.1.2.5033 were used for statistical analyses and plot construction: summarytools library [77] was used for obtaining basal descriptive statistics, ggplot2 library [78] was used to analyze Pearson correlation and plot the result as well as for creating boxplots and histograms, posthoc.kruskal.dunn.test function in the PMCMR library [79] was used for the posthoc Dunn’s test, the FSA library [80] was used to conduct the Mann-Whitney U test, the prcomp function [76] was 
SM395048;summarytools;https://pypi.org/project/summarytools,https://github.com/6chaoran/jupyter-summarytools;;;FALSE;10.2196/25124;R 3.2.2 (R Development Core Team) software [23] was used on every statistical step of this work: discretization of continuous variables (package car [24]), descriptive and comparative analyses (packages gmodels [25] and epitools [26]), missing data analysis (package summarytools [27]), missing data imputation (package DMwR [28]), hierarchical clustering (package stats [23]), Bayesian network inference (packages bnlearn [29] and gRain [30]), and ROC curve analysis (package pROC [31])
SM395048;summarytools;https://pypi.org/project/summarytools,https://github.com/6chaoran/jupyter-summarytools;;;FALSE;10.3390/jpm11060512;R-package ‘dplyr’ was used for data manipulation [28], and R-package ‘summarytools’ was used for frequencies tables, cross-tabulation, and other descriptive statistics [29]
SM397327;hab;https://github.com/basille/hab,http://ase-research.org/basille/hab;;;TRUE;10.1371/journal.pone.0195480;We evaluated models with k-fold cross validation [67] using the hab package [68]
SM397327;hab;https://github.com/basille/hab,http://ase-research.org/basille/hab;;;TRUE;10.1002/ece3.7190;We also assessed the predictive ability of each final model with k?fold cross?validation using the hab package (Basille, 2015)
SM397327;hab;https://pypi.org/project/hab,https://github.com/blurstudio/hab;;;FALSE;10.1371/journal.pone.0195480;We evaluated models with k-fold cross validation [67] using the hab package [68]
SM397327;hab;https://pypi.org/project/hab,https://github.com/blurstudio/hab;;;FALSE;10.1002/ece3.7190;We also assessed the predictive ability of each final model with k?fold cross?validation using the hab package (Basille, 2015)
SM407625;geobr;https://cran.r-project.org/package=geobr,https://ipeagit.github.io/geobr/,https://github.com/ipeaGIT/geobr;;;TRUE;10.3390/pathogens10080988;Geographical maps and general plots were generated using R v3.6.1 [68], and the ggplot2 v3.3.2 [69], geobr v.1.4 [70], and sf v0.9.8 [71] packages
SM407625;geobr;https://cran.r-project.org/package=geobr,https://ipeagit.github.io/geobr/,https://github.com/ipeaGIT/geobr;;;TRUE;10.1371/journal.pntd.0009700;We produced the maps using R software, geobr package [31, 32], (MIT license https://ipeagit.github.io/geobr/).
SM407625;geobr;https://pypi.org/project/geobr,https://github.com/ipeaGIT/geobr;;;FALSE;10.3390/pathogens10080988;Geographical maps and general plots were generated using R v3.6.1 [68], and the ggplot2 v3.3.2 [69], geobr v.1.4 [70], and sf v0.9.8 [71] packages
SM407625;geobr;https://pypi.org/project/geobr,https://github.com/ipeaGIT/geobr;;;FALSE;10.1371/journal.pntd.0009700;We produced the maps using R software, geobr package [31, 32], (MIT license https://ipeagit.github.io/geobr/).
SM407625;geobr;https://pypi.org/project/geobr,https://github.com/ipeaGIT/geobr;;;TRUE;10.1371/journal.pone.0257235;Maps data obtained using geobr, an open-source respository of public domain, official spatial data sets of Brazil [24].
SM410629;pyqi;https://pypi.org/project/pyqi,http://bipy.github.io/pyqi;;;TRUE;10.7717/peerj.4395;Other requirements include GoogleAppEnginePipeline 1.9.22.1, pyqi 0.3.1, requests 2.10.0, requests-toolbelt 0.6.2, mailjet-rest 1.2.2, biom-format 1.1.2, ete3 3.0.0 (for tree generation–see below for details), webapp2 2.5.2, numpy 1.6.1, matplotlib 1.2.0, jinja2 2.6, ssl 2.7.11
SM426249;d3plot;https://www.oasys-software.com/dyna/software/d3plot/;;;TRUE;10.1098/rsta.2009.0051;Once boundary conditions were applied, the model was solved within LS-DYNA and the results interpreted using the d3plot post-processor (Ove/Arup).
SM426250;d3plot;https://pypi.org/project/d3plot,https://github.com/yuhangwang/d3plot;;;FALSE;10.1098/rsta.2009.0052;Once boundary conditions were applied, the model was solved within LS-DYNA and the results interpreted using the d3plot post-processor (Ove/Arup).
SM442171;sasa;https://manual.gromacs.org/current/onlinehelp/gmx-sasa.html;;;TRUE;10.3389/fmolb.2019.00025;Shaw Research was converted to Gromacs format and SASA was calculated for 1,044,000 frames using gmx sasa tool from the Gromacs package (Abraham et al., 2015)
SM442171;sasa;https://pypi.org/project/sasa,https://code.google.com/p/sasa-tool/;;;FALSE;10.3389/fmolb.2019.00025;Shaw Research was converted to Gromacs format and SASA was calculated for 1,044,000 frames using gmx sasa tool from the Gromacs package (Abraham et al., 2015)
SM442171;g_sasa;https://manual.gromacs.org/current/onlinehelp/gmx-sasa.html;;;TRUE;10.1371/journal.pone.0225368;RMSD, RMSF, SASA, Rg, temperature, pressure and density plot analysis were carried out using g_rms, g_rmsf, g_sasa, g_Rg and g_density tools, respectively
SM442171;g_sasa;https://pypi.org/project/sasa,https://code.google.com/p/sasa-tool/;;;FALSE;10.1371/journal.pone.0225368;RMSD, RMSF, SASA, Rg, temperature, pressure and density plot analysis were carried out using g_rms, g_rmsf, g_sasa, g_Rg and g_density tools, respectively
SM442171;sasa;https://pypi.org/project/sasa,https://code.google.com/p/sasa-tool/;;;FALSE;10.1038/s41598-019-56052-3;In all cases we utilize the algorithm of implemented in GROMACS tool package (gmx sasa)
SM442171;sasa;https://pypi.org/project/sasa,https://code.google.com/p/sasa-tool/;;;FALSE;10.1038/s41598-021-84569-z;The data are calculated with GROMACS tool gmx sasa from systems B1–8
SM442171;sasa;https://manual.gromacs.org/current/onlinehelp/gmx-sasa.html;;;TRUE;10.1038/s41598-019-56052-3;In all cases we utilize the algorithm of implemented in GROMACS tool package (gmx sasa)
SM442171;sasa;https://manual.gromacs.org/current/onlinehelp/gmx-sasa.html;;;TRUE;10.1038/s41598-021-84569-z;The data are calculated with GROMACS tool gmx sasa from systems B1–8
SM442505;pyAFQ;https://pypi.org/project/pyAFQ,https://yeatmanlab.github.io/pyAFQ;;;TRUE;10.1371/journal.pcbi.1009136;In addition to demonstrating the our analysis pipeline is robust to changes in tractometry software, the use of the updated pyAFQ capitalized upon the following improvements over the legacy Matlab version: (i) the ability to ingest data provided in the BIDS format [84], and (ii) the calculation of diffusion kurtosis imaging (DKI [43]) metrics We will refer to the mAFQ and pyAFQ pipeline collectively as AFQ.
SM442505;pyAFQ;https://pypi.org/project/pyAFQ,https://yeatmanlab.github.io/pyAFQ;;;TRUE;10.1371/journal.pcbi.1009136;The sofware integrates within a broader automated fiber quantification software ecosystem: AFQ [5] and pyAFQ [57], which extract tract profile data from raw and processed dMRI datasets, as well as AFQ-Browser, which visualizes tract profiles data and facilitates sharing of the results of dMRI studies [58]
SM449318;gitlab;https://pypi.org/project/gitlab;;;TRUE;10.1371/journal.pcbi.1009301;In addition, the authors should guarantee that re-running their code from the gitlab repository is possible.
SM449318;gitlab;https://pypi.org/project/gitlab,https://github.com/python-gitlab/python-gitlab,https://python-gitlab.readthedocs.io/en/stable/,https://about.gitlab.com/;;;TRUE;10.1371/journal.pcbi.1008969;I can confirm that I could access the code shared on gitlab
SM449318;gitlab;https://pypi.org/project/gitlab,https://github.com/python-gitlab/python-gitlab,https://python-gitlab.readthedocs.io/en/stable/,https://about.gitlab.com/;;;TRUE;10.1371/journal.pone.0252775;"These scripts could be made on dedicated platforms such as the Open Science Framework, github, gitlab, ResearchBox, or the PsychArchives; or maybe also Supplementary Material to this paper"
SM449318;gitlab;https://pypi.org/project/gitlab,https://github.com/python-gitlab/python-gitlab,https://python-gitlab.readthedocs.io/en/stable/,https://about.gitlab.com/;;;TRUE;10.5334/jors.289;The software may be forked via gitlab which implements issue trackers to enable bug reporting and feature requests.
SM459266;fwdpy;https://pypi.org/project/fwdpy,https://github.com/molpopgen/fwdpy,https://molpopgen.github.io/fwdpy/;;;TRUE;10.1371/journal.pgen.1006573;The model was implemented using the Python package fwdpy version 0.0.4, which uses fwdpp[87] version 0.5.1 as a C++ back-end
SM46852;q?value;https://www.bioconductor.org/packages/release/bioc/html/qvalue.html;;;TRUE;10.1002/mnfr.201600372;False discovery rates were quantified using Bonferroni corrections for phylum level tests, and the q?value software package was used for remaining comparisons at the taxonomic level
SM46852;q-value;https://www.bioconductor.org/packages/release/bioc/html/qvalue.html;;;TRUE;10.1186/s12711-015-0111-y;The R package q-value [34] was used to calculate the FDR-based q-value to measure the statistical significance at the genome-wide level for association studies
SM46852;q?value;https://pypi.org/project/value,http://github.com/halst/value;;;FALSE;10.1002/mnfr.201600372;False discovery rates were quantified using Bonferroni corrections for phylum level tests, and the q?value software package was used for remaining comparisons at the taxonomic level
SM46852;q-value;https://pypi.org/project/value,http://github.com/halst/value;;;FALSE;10.1186/s12711-015-0111-y;The R package q-value [34] was used to calculate the FDR-based q-value to measure the statistical significance at the genome-wide level for association studies
SM46852;q-value;https://pypi.org/project/value,http://github.com/halst/value;;;FALSE;10.3389/fpls.2017.01463;Q-values were calculated using the R-package q-value (Storey et al., 2015)
SM46852;q?value;https://pypi.org/project/value,http://github.com/halst/value;;;FALSE;10.1111/eva.12944;For each association model related to the same environmental variable, p?values of G?scores (G) and Wald scores (W) were corrected for multiple testing using the R q?value package (v
SM46852;q-value;https://pypi.org/project/value,http://github.com/halst/value;;;FALSE;10.1534/g3.117.300125;p-values were adjusted for multiple testing using R package q-value (Storey )
SM46852;q-value;https://www.bioconductor.org/packages/release/bioc/html/qvalue.html;;;TRUE;10.3389/fpls.2017.01463;Q-values were calculated using the R-package q-value (Storey et al., 2015)
SM46852;q?value;https://www.bioconductor.org/packages/release/bioc/html/qvalue.html;;;TRUE;10.1111/eva.12944;For each association model related to the same environmental variable, p?values of G?scores (G) and Wald scores (W) were corrected for multiple testing using the R q?value package (v
SM46852;q-value;https://www.bioconductor.org/packages/release/bioc/html/qvalue.html;;;TRUE;10.1534/g3.117.300125;p-values were adjusted for multiple testing using R package q-value (Storey )
SM510719;pickpocket;https://pypi.org/project/pickpocket,https://github.com/benjaminviart/PickPocket;;;FALSE;10.1371/journal.pone.0248061;For accuracy, other software such as an artificial neural network (ANN), stabilized matrix method (SMM), MHC binding energy covariance matrix (SMMPMBEC), NetMHCpan, pickpocket, and NetMHCstapan, were adopted for this purpose
SM510719;pickpocket;https://pypi.org/project/pickpocket,https://github.com/benjaminviart/PickPocket;;;FALSE;10.1101/mcs.a002444;MHC Class I binding predictions were generated through pVACSeq using NetMHC v3.4, as well as five other algorithms from the Immune Epitope Database and Analysis resource (IEDB, iedb.org): netMHC, netmhccons, netmhcpan, pickpocket, smm, and smmpmbec
SM510719;pickpocket;https://pypi.org/project/pickpocket,https://github.com/benjaminviart/PickPocket;;;FALSE;10.1155/2020/2837670;For better predictive accuracy, other software such as artificial neural network (ANN), stabilized matrix method (SMM), MHC-binding energy covariance matrix (SMMPMBEC), NetMHCpan, pickpocket, and NetMHCpan were adopted for this purpose
SM530391;modes;https://pypi.org/project/modes,https://github.com/jtambasco/modesolverpy;;;FALSE;10.1371/journal.pone.0223490;0.75–7, and the bimodality coefficient after Ellison [55] was calculated with the R-package ‘modes’ v
SM530391;modes;https://pypi.org/project/modes,https://github.com/jtambasco/modesolverpy;;;FALSE;10.1098/rsos.191511;Trip duration distribution of these pooled trips was assessed for bimodality with calculation of the bimodality coefficient [61] and mode(s) estimation(s) by mixture distribution implemented in the modes package [62]
SM530391;modes;https://github.com/sathish-deevi/modes-Package;;;TRUE;10.1371/journal.pone.0223490;0.75–7, and the bimodality coefficient after Ellison [55] was calculated with the R-package ‘modes’ v
SM530391;modes;https://github.com/sathish-deevi/modes-Package;;;TRUE;10.1098/rsos.191511;Trip duration distribution of these pooled trips was assessed for bimodality with calculation of the bimodality coefficient [61] and mode(s) estimation(s) by mixture distribution implemented in the modes package [62]
SM532078;lunar;https://pypi.org/project/lunar,https://github.com/jasonlvhit/lunar;;;FALSE;10.1371/journal.pone.0246564;Lunar stage was included as a categorical variable of either ‘new’, ‘waxing’, ‘full’ or ‘waning’ and was obtained using the ‘lunar’ package [63] in the R programming environment [64]
SM532078;lunar;https://pypi.org/project/lunar,https://github.com/jasonlvhit/lunar;;;FALSE;10.1371/journal.pone.0252092;Lunar illumination was calculated through the ’lunar’ package in R [43] and represents the proportion of lunar illumination for any specific date and time
SM532078;lunar;https://pypi.org/project/lunar,https://github.com/jasonlvhit/lunar;;;FALSE;10.1002/ece3.7006;Visitation was used as the binary response variable, and the covariates included were the month of the visit, the size of the lick in m2, the lick type (face present or not present), elevation in m, slope in degrees, distance the closest river or stream in m, distance from the closest hunting camp in m (a proxy for hunting pressure, see Griffiths, 2020), and the brightness of the moon calculated using the lunar.illumination function in the lunar package (Lazaridis, 2014) in R
SM532078;lunar;https://cran.r-project.org/package=lunar;;;TRUE;10.1371/journal.pone.0246564;Lunar stage was included as a categorical variable of either ‘new’, ‘waxing’, ‘full’ or ‘waning’ and was obtained using the ‘lunar’ package [63] in the R programming environment [64]
SM532078;lunar;https://cran.r-project.org/package=lunar;;;TRUE;10.1371/journal.pone.0252092;Lunar illumination was calculated through the ’lunar’ package in R [43] and represents the proportion of lunar illumination for any specific date and time
SM532078;lunar;https://cran.r-project.org/package=lunar;;;TRUE;10.1002/ece3.7006;Visitation was used as the binary response variable, and the covariates included were the month of the visit, the size of the lick in m2, the lick type (face present or not present), elevation in m, slope in degrees, distance the closest river or stream in m, distance from the closest hunting camp in m (a proxy for hunting pressure, see Griffiths, 2020), and the brightness of the moon calculated using the lunar.illumination function in the lunar package (Lazaridis, 2014) in R
SM569443;ndl;https://cran.r-project.org/package=ndl;;;TRUE;10.1371/journal.pone.0218802;We therefore use the implementation of the equilibrium equations for the Rescorla-Wagner model [30] in version 0.2.18 of the ndl package for the statistical software r to estimate the connection strength (V) of cue (C) to outcome (O): where Pr(C|C) is the conditional probability of cue C given cue C, Pr(O|C) is the conditional probability of outcome O given cue C and n + 1 is the number of different cues
SM569443;ndl;https://cran.r-project.org/package=ndl;;;TRUE;10.1371/journal.pone.0075734;We then estimated the weights of the model using the ‘ndl’ package in R (version 0.2.10) which implements the Danks equations [23] introduced above
SM569443;ndl;https://cran.r-project.org/package=ndl;;;TRUE;10.1111/cogs.12910;(1), (2), (3) implemented in R (R Core Team, 2019) using the edl package (van Rij & Hoppe, 2020) and the ndl package (Arppe et al., 2018)
SM569443;ndl;https://pypi.org/project/ndl,https://github.com/msull/needle;;;FALSE;10.1371/journal.pone.0218802;We therefore use the implementation of the equilibrium equations for the Rescorla-Wagner model [30] in version 0.2.18 of the ndl package for the statistical software r to estimate the connection strength (V) of cue (C) to outcome (O): where Pr(C|C) is the conditional probability of cue C given cue C, Pr(O|C) is the conditional probability of outcome O given cue C and n + 1 is the number of different cues
SM569443;ndl;https://pypi.org/project/ndl,https://github.com/msull/needle;;;FALSE;10.1371/journal.pone.0075734;We then estimated the weights of the model using the ‘ndl’ package in R (version 0.2.10) which implements the Danks equations [23] introduced above
SM569443;ndl;https://pypi.org/project/ndl,https://github.com/msull/needle;;;FALSE;10.1111/cogs.12910;(1), (2), (3) implemented in R (R Core Team, 2019) using the edl package (van Rij & Hoppe, 2020) and the ndl package (Arppe et al., 2018)
SM589803;Toolserver;https://pypi.org/project/Toolserver,http://bitbucket.org/rfc1437/toolserver/;;;FALSE;10.1371/journal.pone.0071226;These three variables are calculated using the page history databases of Wikimedia Toolserver (http://toolserver.wikimedia.org), which register information about every modification made to the pages of Wikipedia
SM589803;Toolserver;https://www.mediawiki.org/wiki/Toolserver:Getting_started;;;TRUE;10.1371/journal.pone.0071226;These three variables are calculated using the page history databases of Wikimedia Toolserver (http://toolserver.wikimedia.org), which register information about every modification made to the pages of Wikipedia
SM596405;pymagnitude;https://pypi.org/project/pymagnitude,https://gitlab.com/Plasticity/magnitude;;;TRUE;10.1371/journal.pone.0240376;Our analogies of Word2Vec embeddings were carried out on Google CoLab using the pymagnitude package and vector similarity functions (see Section 3.1)
SM601858;mnnpy;https://pypi.org/project/mnnpy,http://github.com/chriscainx/mnnpy;;;TRUE;10.1016/j.cell.2020.08.013;The resulting peripheral retina, foveal retina, and developed organoid transcriptomes were integrated using the mnnpy implementation of MNN correction (Haghverdi et al., 2018)
SM601858;mnnpy;https://pypi.org/project/mnnpy,http://github.com/chriscainx/mnnpy;;;TRUE;10.1242/dev.174557;Batch effects between the two datasets were corrected by matching mutual nearest neighbours in the implementation of mnnpy (v0.1.9.3) (parameters: svd_mode=‘irlb’) (Lun et al., 2016)
SM601858;mnnpy;https://pypi.org/project/mnnpy,http://github.com/chriscainx/mnnpy;;;TRUE;10.1186/s13073-020-00799-2;Mutual nearest neighbor (MNN) correction [31] (mnnpy [32] version 0.1.9.5) was used to combine data across the eight donors for clustering and cell state identification
SM608599;gdsCAD;https://pypi.org/project/gdsCAD,https://github.com/hohlraum/gdsCAD;;;TRUE;10.3390/cells7080094;"The mask was manufactured by Delta Mask, Toppan, Netherlands, using a GDSII layout file that was created using the Python platform and gdsCAD 0.4.5 package containing the pattern designs; i.e., circle patterns with a diameter 50 ?m"
SM626692;libmesh;https://libmesh.github.io/,https://github.com/libMesh/libmesh;;;TRUE;10.1007/s00466-017-1381-8;For the implementation we used the C++ library libmesh [33], and the multi-frontal direct solver mumps [2] to solve the resulting linear systems
SM626692;libmesh;https://pypi.org/project/libmesh,https://github.com/superdima05/mesh/;;;FALSE;10.1007/s00466-017-1381-8;For the implementation we used the C++ library libmesh [33], and the multi-frontal direct solver mumps [2] to solve the resulting linear systems
SM64748;mpi4py;https://pypi.org/project/mpi4py,https://github.com/mpi4py/mpi4py/;;;TRUE;10.1186/s12859-020-03562-x;HPC-REDItools are again written in Python (to increase portability and for continuity with the previous version) and makes use of mpi4py library [17] (version 2.0.0) that is the binding of the Message Passing Interface (MPI) standard library for the Python programming language
SM64748;mpi4py;https://pypi.org/project/mpi4py,https://github.com/mpi4py/mpi4py/;;;TRUE;10.3389/fnhum.2013.00869;Simulations and analyses were performed in Python, using NumPy 1.7.1, SciPy 0.12.0, mpi4py 1.3, and OpenMPI 1.6.1 on commercially available x86_64 hardware
SM64748;mpi4py;https://pypi.org/project/mpi4py,https://github.com/mpi4py/mpi4py/;;;TRUE;10.3389/fninf.2018.00092;The simulated results and analysis presented here were made possible using Python 2.7.11 with the Intel(R) MPI Library v5.1.3, NEURON v7.5 (1472:078b74551227), Cython v0.23.4, LFPy (github.com/LFPy/LFPy, SHA:0d1509), mpi4py v2.0.0, numpy v1.10.4, scipy v0.17.0, h5py v2.6.0, parameters (github.com/NeuralEnsemble/parameters, SHA:v0aaeb), csa (github.com/INCF/csa, SHA:452a35) and matplotlib v2.1.0 running in parallel using 120-4800 cores on the JURECA cluster in Jülich, Germany, composed of two 2.5 GHz Intel X
SM64748;mpi4py;https://pypi.org/project/mpi4py,https://github.com/mpi4py/mpi4py/;;;TRUE;10.1371/journal.pcbi.1005930;We chose an MPI distributed-memory parallelization implemented with the Python library mpi4py [78] whereby simulation of every spot size is mapped to one MPI process
SM64748;mpi4py;https://pypi.org/project/mpi4py,https://github.com/mpi4py/mpi4py/;;;TRUE;10.1371/journal.pone.0146581;from mpi4py import MPI
SM650181;ABBYY;https://pypi.org/project/ABBYY,https://github.com/samueltc/ABBYY;;;TRUE;10.1186/s13637-017-0057-1;Hand-writing recognition is a well-established problem and we have experimented with different resources including Omnipage Capture SDK [18], Captricity [19], and ABBYY [20], which to the best of our knowledge are among the best tools in the market for recognizing hand-written letters and have been widely used in recognizing and transforming documents into usable digital forms [21]
SM650181;ABBYY;https://pypi.org/project/ABBYY,https://github.com/samueltc/ABBYY;;;TRUE;10.12688/f1000research.7329.3;We analyzed different freely available and commercial OCR systems and libraries including Aspose, PUMA, Microsoft OCR, Tesseract, LEADTOOLS, Nicomsoft OCR, MeOCR OCR, OmniPage, ABBYY, Bytescout claiming to be able to extract embedded text from figures
SM650181;ABBYY;https://pypi.org/project/ABBYY,https://github.com/samueltc/ABBYY;;;TRUE;10.1109/JTEHM.2019.2935451;Four different OCR Engines that can be implemented via an API were evaluated to determine the accuracy and usability of each engine: Google Machine Learning Kit (ML Kit) [26], Microsoft Azure’s Cognitive Services (Azure OCR) [27], ABBYY’s Real Time Recognition SDK (ABBY RTR) [28], and Amazon’s Rekognition SDK (Rekognition) [29]
SM650181;ABBYY;https://pypi.org/project/ABBYY,https://github.com/samueltc/ABBYY;;;TRUE;10.1109/JTEHM.2019.2935451;Successful search rate at zoom level differed significantly between the 4 OCR engines (, df = 3, p < 0.001), with ML Kit being the most successful in detecting keywords without needing to zoom in, followed by Rekognition, Azure OCR, and ABBYY RTR
SM650181;ABBYY;https://pypi.org/project/ABBYY,https://github.com/samueltc/ABBYY;;;TRUE;10.1109/JTEHM.2019.2935451;A 4-sample test for equality of proportions showed that the overall successful search rate differed significantly between the OCR engines (, df = 3, p < 0.001), with ML Kit and Rekognition having a significantly higher overall success rate than Azure OCR and ABBYY RTR (p < 0.001 for all multiple pairwise comparison with Bonferroni correction)
SM652180;insol;https://github.com/cran/insol,https://meteoexploration.com/R/insol/index.html;;;TRUE;10.1002/ece3.2001;"To identify the importance of seasonality in photoperiod for the distribution of F. distichus, we compiled two global rasters with the R packages ‘raster’ (Hijmans 2015) and ‘insol’ (Corripio 2014): (1) Summer solstice, representing the hours of daylight at midsummer (21 Jun); and (2) Winter solstice, representing the hours of daylight at the shortest day of the year (21 Dec)."
SM652180;insol;https://github.com/cran/insol,https://meteoexploration.com/R/insol/index.html;;;TRUE;10.1002/ece3.4189;The azimuth (a) and zenith (z) of the sun were extracted using the “insol” package (Corripio, 2015)
SM652180;insol;https://github.com/cran/insol,https://meteoexploration.com/R/insol/index.html;;;TRUE;10.1038/sdata.2018.177;The soil microclimate temperatures were divided into daytime and nighttime records by calculating the time of sunrise and sunset each day over the time period, per site, using the ‘insol’ package in R (ver
SM652180;insol;https://github.com/cran/insol,https://meteoexploration.com/R/insol/index.html;;;TRUE;10.1038/s41598-020-63005-8;Data on river discharge, water temperature and diel period (calculated with the insol package) was assembled for each hourly increment over the duration of the study.
SM652180;insol;https://pypi.org/project/insol;;;FALSE;10.1002/ece3.2001;"To identify the importance of seasonality in photoperiod for the distribution of F. distichus, we compiled two global rasters with the R packages ‘raster’ (Hijmans 2015) and ‘insol’ (Corripio 2014): (1) Summer solstice, representing the hours of daylight at midsummer (21 Jun); and (2) Winter solstice, representing the hours of daylight at the shortest day of the year (21 Dec)."
SM652180;insol;https://pypi.org/project/insol;;;FALSE;10.1002/ece3.4189;The azimuth (a) and zenith (z) of the sun were extracted using the “insol” package (Corripio, 2015)
SM652180;insol;https://pypi.org/project/insol;;;FALSE;10.1038/sdata.2018.177;The soil microclimate temperatures were divided into daytime and nighttime records by calculating the time of sunrise and sunset each day over the time period, per site, using the ‘insol’ package in R (ver
SM652180;insol;https://pypi.org/project/insol;;;FALSE;10.1038/s41598-020-63005-8;Data on river discharge, water temperature and diel period (calculated with the insol package) was assembled for each hourly increment over the duration of the study.
SM661915;nolds;https://pypi.org/project/nolds,https://github.com/CSchoel/nolds;;;TRUE;10.3390/e20120962;We simulated fBm signals using the Cholesky decomposition method [37] ( function of Python’s nolds library) at a Hurst exponent of H = 0.75 and five scaling coefficients D = 0.001, 0.01, 1, 10, and 100, where the value of D = 1 leads to the original form of fBm
SM661915;nolds;https://pypi.org/project/nolds,https://github.com/CSchoel/nolds;;;TRUE;10.1038/s41598-018-24318-x;SampE and DFA were computed using publicly available software “Nonlinear measures for dynamical systems” or nolds, version 0.3.2, which can be downloaded from (https://pypi.python.org/pypi/nolds).
SM661915;nolds;https://pypi.org/project/nolds,https://github.com/CSchoel/nolds;;;TRUE;10.3390/e20120962;We performed self-similarity analysis of epileptic EEG datasets by extracting their Hurst exponent through the standard rescaled range approach [38] ( function of Python’s nolds library)
SM665653;smnet;https://github.com/alastairrushworth/smnet;;;TRUE;10.1002/env.2340;"As such, smnet allows the user to fit spatial additive models based on P?splines, which may be particularly useful for capturing non?stationary and non?separable spatio?temporal effects; characteristics that we expect to be common in streams data (Peterson et al., 2013)"
SM665653;smnet;https://github.com/alastairrushworth/smnet;;;TRUE;10.1002/env.2340;Until recently, fitting these types of stream network models would have required a great deal of effort and technical expertise, but the SSN and smnet packages make these methods accessible to modellers from a wide variety of disciplines
SM665653;smnet;https://pypi.org/project/smnet;;;FALSE;10.1002/env.2340;"As such, smnet allows the user to fit spatial additive models based on P?splines, which may be particularly useful for capturing non?stationary and non?separable spatio?temporal effects; characteristics that we expect to be common in streams data (Peterson et al., 2013)"
SM665653;smnet;https://pypi.org/project/smnet;;;FALSE;10.1002/env.2340;Until recently, fitting these types of stream network models would have required a great deal of effort and technical expertise, but the SSN and smnet packages make these methods accessible to modellers from a wide variety of disciplines
SM666261;methylcheck;https://pypi.org/project/methylcheck,https://github.com/FOXOBioScience/methylcheck;;;TRUE;10.1186/s13072-019-0321-6;Data obtained via methylcheck python package
SM673828;mopac;http://openmopac.net/;;;TRUE;10.1155/2019/7523159;To understand the binding mechanisms of active constituents of gymnema leaves, molecular modelling studies were accomplished for deaclgymnemic acid, gymnemic acid, quercetin, and the aglycone moiety gymnemagenin with target proteins by the mopac 6 software package (Stewart Computational Chemistry, Colorado Springs, USA)
SM673828;MOPAC2016;http://openmopac.net/;;;TRUE;10.1155/2017/7496934;HNQs and FNQs were refined by the parametric method 7 (PM7) [56] and the Eigenvector Following (EF) [56] routine implemented in MOPAC2016 [52] by the Octopus Run_mopac routine, which automatically assigns the total molecular charge for each ligand and checks for errors in the structures
SM673828;mopac;https://pypi.org/project/mopac,https://github.com/mbanders/mopac_checker;;;FALSE;10.1155/2019/7523159;To understand the binding mechanisms of active constituents of gymnema leaves, molecular modelling studies were accomplished for deaclgymnemic acid, gymnemic acid, quercetin, and the aglycone moiety gymnemagenin with target proteins by the mopac 6 software package (Stewart Computational Chemistry, Colorado Springs, USA)
SM673828;MOPAC2016;https://pypi.org/project/mopac,https://github.com/mbanders/mopac_checker;;;FALSE;10.1155/2017/7496934;HNQs and FNQs were refined by the parametric method 7 (PM7) [56] and the Eigenvector Following (EF) [56] routine implemented in MOPAC2016 [52] by the Octopus Run_mopac routine, which automatically assigns the total molecular charge for each ligand and checks for errors in the structures
SM689759;edd-utils;https://pypi.org/project/edd-utils,https://github.com/JBEI/edd-utils;;;TRUE;10.3389/fbioe.2021.612893;The edd-utils package uses EDD's REST API to provide a DataFrame inside of your Jupyter notebook to visualize and manipulate as desired
SM689759;edd-utils;https://pypi.org/project/edd-utils,https://github.com/JBEI/edd-utils;;;TRUE;10.3389/fbioe.2021.612893;The users can run the export_study() function from the edd-utils package (see code availability) to download a study from a particular EDD instance
SM701486;spektral;https://pypi.org/project/spektral,https://github.com/danielegrattarola/spektral;;;TRUE;10.3389/fgene.2021.733906;We refer to scGAE to build a graph autoencoder that is based on TensorFlow 2.4.1 and Python package spektral 0.6.1
SM701486;spektral;https://pypi.org/project/spektral,https://github.com/danielegrattarola/spektral;;;TRUE;10.1186/s13059-020-02214-w;To construct GCNG, we used the python packages of “spektral,” “Keras,” and “Tensorflow.” See Fig. 1a for the architecture of GCNG
SM71816;POAP;https://pypi.org/project/POAP;;;FALSE;10.31557/APJCP.2019.20.11.3399;"POAP calculates the ligand binding energy and scoring based on the AutoDock Lamarckian Genetic Algorithm and free energy empirical scoring (Morris et al., 2009; Samdani and Vetrivel, 2018)"
SM71816;POAP;https://pypi.org/project/POAP;;;FALSE;10.3389/fmed.2021.672629;POAP implements dynamic file handling methods for efficient memory usage and data organization, ligand minimization (5,000 steps), MMFF94 force-field was employed with the addition of hydrogens
SM71816;POAP;https://pypi.org/project/POAP;;;FALSE;10.1038/s41598-021-92622-0;We have obtained the SMILES notations of these compounds, and generated their 3D models (in mol2 format) through the POAP Ligand Preparation pipeline
SM71816;POAP;https://pypi.org/project/POAP;;;FALSE;10.31557/APJCP.2019.20.11.3399;The energies obtained from POAP were compared with the ligand score identified from Schrodinger
SM71816;POAP;https://pypi.org/project/POAP;;;FALSE;10.31557/APJCP.2019.20.11.3399;POAP integrates the tools such as Open Babel, AutoDock, AutoDock Vina and AutoDockZN in an easily configurable Bash shell-based text interface
SM71816;POAP;https://github.com/inpacdb/POAP;;;TRUE;10.31557/APJCP.2019.20.11.3399;"POAP calculates the ligand binding energy and scoring based on the AutoDock Lamarckian Genetic Algorithm and free energy empirical scoring (Morris et al., 2009; Samdani and Vetrivel, 2018)"
SM71816;POAP;https://github.com/inpacdb/POAP;;;TRUE;10.3389/fmed.2021.672629;POAP implements dynamic file handling methods for efficient memory usage and data organization, ligand minimization (5,000 steps), MMFF94 force-field was employed with the addition of hydrogens
SM71816;POAP;https://github.com/inpacdb/POAP;;;TRUE;10.1038/s41598-021-92622-0;We have obtained the SMILES notations of these compounds, and generated their 3D models (in mol2 format) through the POAP Ligand Preparation pipeline
SM71816;POAP;https://github.com/inpacdb/POAP;;;TRUE;10.31557/APJCP.2019.20.11.3399;The energies obtained from POAP were compared with the ligand score identified from Schrodinger
SM71816;POAP;https://github.com/inpacdb/POAP;;;TRUE;10.31557/APJCP.2019.20.11.3399;POAP integrates the tools such as Open Babel, AutoDock, AutoDock Vina and AutoDockZN in an easily configurable Bash shell-based text interface
SM729696;httplib2;https://pypi.org/project/httplib2,https://github.com/httplib2/httplib2;;;TRUE;10.3389/fninf.2014.00052;Dependencies are pydicom, httplib2, and DCMTK
SM742643;openrouteservice;https://pypi.org/project/openrouteservice,https://openrouteservice.org/,https://github.com/GIScience/openrouteservice-py;;;TRUE;10.3389/fped.2020.00395;Then, using openrouteservice, we calculated travel time and travel distance by car from each random point to the nearest provider of each service
SM742643;openrouteservice;https://pypi.org/project/openrouteservice,https://openrouteservice.org/,https://github.com/GIScience/openrouteservice-py;;;TRUE;10.3389/fped.2020.00395;"Due to the limit in travel data requests per time when using openrouteservice, we calculated travel time and distance from a random sample of about 28% of the random points of each country (Germany: 100,000 points; Ireland: 20,000 points; UK: 70,000 points) to the nearest provider for each type of pediatric service"
SM824960;pvr;https://cran.r-project.org/package=PVR;;;TRUE;10.1111/jbi.12171;We used the pvr package in R (see http://cran.r-project.org/web/packages/PVR/index.html) for calculating the PSR curves for each quantitative species trait.
SM82525;SIMLR;https://pypi.org/project/SIMLR,https://github.com/bowang87/SIMLR-PY;;;FALSE;10.1242/dev.177428;Cell clustering was performed using SIMLR (package version 1.4.1) (Wang et al., 2017)
SM82525;SIMLR;https://www.bioconductor.org/packages/release/bioc/html/SIMLR.html;;;TRUE;10.1242/dev.177428;Cell clustering was performed using SIMLR (package version 1.4.1) (Wang et al., 2017)
SM866863;onnx;https://pypi.org/project/onnx,https://github.com/onnx/onnx;;;TRUE;10.1007/s42452-021-04588-3;After that, we used the onnx tool, onnx-TensorRT tool, to convert onnx to TensorRT
SM91616;glib;https://pypi.org/project/glib;;;FALSE;10.1186/1471-2105-6-31;It is built using the glib portabilility library available from Both exonerate and glib are available under the GNU lesser general public license
SM91616;glib;https://pypi.org/project/glib;;;FALSE;10.3390/s150304677;Linux based operating systems uses elf ? loader (from glib ? c library) to open binary files and load them into the memory
SM91616;glib;https://gitlab.gnome.org/GNOME/glib/;;;TRUE;10.1186/1471-2105-6-31;It is built using the glib portabilility library available from Both exonerate and glib are available under the GNU lesser general public license
SM91616;glib;https://gitlab.gnome.org/GNOME/glib/;;;TRUE;10.3390/s150304677;Linux based operating systems uses elf ? loader (from glib ? c library) to open binary files and load them into the memory
SM932457;cytoflow;https://pypi.org/project/cytoflow,https://github.com/cytoflow/cytoflow;;;TRUE;10.1038/s41598-021-86135-z;The data from the flow cytometry was imported and analysed in Python 3.5 using the cytoflow library
SM932547;mord;https://pypi.org/project/mord,https://github.com/fabianp/mord;;;TRUE;10.1038/s41598-021-86538-y;For that, we use the ordinal logistic regression model available in the software mord developed by Pedregosa-Izquierdo.
SM967339;CoAPthon;https://pypi.org/project/CoAPthon,https://github.com/Tanganelli/CoAPthon;;;TRUE;10.3390/s19030716;For CoAP, CoAPthon [21], an open-source implementation, was employed to simulate communications and messages were collected from the communication channel
SM967339;CoAPthon;https://pypi.org/project/CoAPthon,https://github.com/Tanganelli/CoAPthon;;;TRUE;10.3390/s19245467;Hence, a variety of IoT libraries, such as CoAPthon [27], and frameworks [28], such as IDeA, FRASAD, D-LITe, IoTLink, WebRTC based IoT application Framework, Datatweet, IoTSuite and RapIoT, have been developed to manage those complexities.
