name;candidate_urls;doi;paragraph
pytorch;https://pypi.org/project/pytorch;10.3389/fnins.2020.00919;Further preprocessing can be directly applied using the utils python package provided, making the data readily available to exploit in popular python machine learning packages as pytorch and tensorflow.
pytorch;https://pypi.org/project/pytorch;10.3390/s20205762;All transformations can be implemented by pytorch and were performed during training on each data batch according to the mentioned probabilities
pytorch;https://pypi.org/project/pytorch;10.3390/s21061983;All the proposed method and models were implemented using pytorch and fastai [51]
Django;https://pypi.org/project/Django,https://github.com/django/django;10.1093/database/baz101;The annotation tool was written using the Django web-framework (V.: 2.0.1) with a PostgreSQL (V.: 9.6.9) backend
Django;https://pypi.org/project/Django,https://github.com/django/django;10.3389/fninf.2021.713899;The EBRAINS NeuroFeatureExtract consists of a full stack web-based application implemented via the Python-based Django web framework and deployed on a dedicated Virtual Machine (VM) hosted on the CINECA supercomputing center and accessible/configurable through the OpenStack interface
Django;https://pypi.org/project/Django,https://github.com/django/django;10.3390/s18113891;The atmospheric environmental monitoring system software is created in the Django framework [21], which stores data using a MySQL database and communicates with the terminal collection device via Socket communication
requests;https://pypi.org/project/requests,https://github.com/psf/requests;10.1186/s12911-020-1046-y;Project name: Prikbord Project home page:http://prikbord.science.ru.nl/Operating system: Linux Programming language: Python, javascript Other requirements: Django 1.5.11 or higher, MongoDB 2.6.10, pymongo 2.7.2 or higher, requests 2.13.0 or higher License: GNU GPL Any restrictions to use by non-academics: licence needed
requests;https://pypi.org/project/requests,https://github.com/psf/requests;10.3389/fvets.2021.674730;Using requests and BeautifulSoup packages in Python, all the PDF files with the titles containing “MRK” by avoiding cases sensitivity of uppercase or lowercase for each letter (e.g., “mRK,” “MrK,” “mrk,” etc.) from the years 2018, 2019, and 2020 were automatically collected and saved in a separate folder for further steps
requests;https://pypi.org/project/requests,https://github.com/psf/requests;10.1016/j.dib.2021.107360;We used the json and requests packages [35,36]to collect data and the scikit-learn package [37] to impute missing values
scikit-learn;https://pypi.org/project/scikit-learn,https://github.com/scikit-learn/scikit-learn;10.3389/fmicb.2020.00383;We performed random forest classification using the implementation of this method in Python’s scikit-learn package
scikit-learn;https://pypi.org/project/scikit-learn,https://github.com/scikit-learn/scikit-learn;10.1186/s13073-021-00919-6;For taxonomic classification, a scikit-learn [44] naive Bayes classifier was created against the taxonomic classification from ARB-SILVA [45] 132 release (99% OTU data set), which was trained for the used primers
scikit-learn;https://pypi.org/project/scikit-learn,https://github.com/scikit-learn/scikit-learn;10.7554/eLife.46935;scikit-learn (Pedregosa et al., 2011).
matplotlib;https://pypi.org/project/matplotlib,https://github.com/matplotlib/matplotlib;10.3389/fncir.2014.00005;Figures and data visualization were done using matplotlib (Hunter, 2007) and Inkscape (Andler et al., 2004–2014)
matplotlib;https://pypi.org/project/matplotlib,https://github.com/matplotlib/matplotlib;10.1186/s13321-019-0351-x;Additionally, basic Python computing libraries employed include numpy [21, 22] and pandas [23, 24] (high-performance data structures and analysis), scikit-learn [25] (machine learning), as well as matplotlib [26] and seaborn [27] (plotting)
matplotlib;https://pypi.org/project/matplotlib,https://github.com/matplotlib/matplotlib;10.3390/pharmaceutics12111071;The analysis was performed in Python, using numpy and matplotlib.
numpy;https://pypi.org/project/numpy,https://github.com/numpy/numpy;10.1371/journal.pone.0225900;In particular, indexing is possible via square brackets […] and mostly follows the conventions of numpy [45], the de facto standard for numerics in Python
numpy;https://pypi.org/project/numpy,https://github.com/numpy/numpy;10.1371/journal.pone.0249624;Numerical arrays were stored using the numpy package [35]
numpy;https://pypi.org/project/numpy,https://github.com/numpy/numpy;10.7717/peerj.2823;"Python packages used for analysis include numpy (Oliphant, 2007; Van der Walt, Colbert & Varoquaux, 2011), matplotlib (Hunter, 2007), sqlalchemy (Bayer, 2014), pandas (McKinney, 2010), macroecotools (Xiao et al., 2016), and retriever (Morris & White, 2013)"
pandas;https://pypi.org/project/pandas,https://github.com/pandas-dev/pandas;10.7717/peerj-cs.687;Step 2: Load data by using the pandas library
pandas;https://pypi.org/project/pandas,https://github.com/pandas-dev/pandas;10.1093/bib/bbab055;Other requirements: Bowtie (developed with 1.1.2), biopython (Python2-1.76, Python3-1.76 or higher), numpy (Python2-1.16-1.18, Python3-1.16 or higher), pandas (Python2-0.24.2, Python3-0.24.2 or higher)
pandas;https://pypi.org/project/pandas,https://github.com/pandas-dev/pandas;10.3390/s19061361;To do this, we used the programming language Python and five libraries: scipy, numpy, matplotlib, pandas, and sklearn.
tensorflow;https://pypi.org/project/tensorflow;10.1186/s12880-021-00551-1;Other requirements: matplotlib, pytorch, fastai (v1.0.61), gif, tensorflow, altair, fastai2, pydicom, kornia, scikit-image, torchio.
tensorflow;https://pypi.org/project/tensorflow;10.3389/fnins.2019.01321;The DL model was written in tensorflow 1.4 (Abadi et al., 2016) and the interprettensor library (https://github.com/VigneshSrinivasan10/interprettensor).
tensorflow;https://pypi.org/project/tensorflow;10.1186/s40537-020-00387-6;With tensorflow version 1.14.0 and python version 3.7.4
BeautifulSoup;https://pypi.org/project/BeautifulSoup;10.1186/s12859-020-3540-8;For the prior knowledge from UniProt KB, we use Bioservices, urllib, BeautifulSoup tool does finish a series of processes
BeautifulSoup;https://pypi.org/project/BeautifulSoup;10.1038/s41597-020-00682-0;Wikipedia is accessed through the MediaWiki API using Python, and the BeautifulSoup, json, and requests packages
BeautifulSoup;https://pypi.org/project/BeautifulSoup;10.1186/s40537-021-00476-0;In this paper, the Python programming language, with packages made by BeautifulSoup and Selenium, was used to write an algorithm and purposely collect desired variables for apartment listings in the capital city of Vilnius with sell and rent operations
Flask;https://pypi.org/project/Flask,https://github.com/pallets/flask/;10.3390/ijms22157811;The server side is run by a Flask application server, also implemented in Python
Flask;https://pypi.org/project/Flask,https://github.com/pallets/flask/;10.3390/diagnostics10060421;This application was developed using the Dash Framework (Plotly’s Python-based micro Web Framework using Flask as a Server)
Flask;https://pypi.org/project/Flask,https://github.com/pallets/flask/;10.1038/sdata.2018.23;"The back-end of the website was developed with Flask; the front-end of the website was developed with JavaScript, HTML, and CSS"
beautifulsoup4;https://pypi.org/project/beautifulsoup4;10.3390/s20010190;Our API for the acquisition of weather data operates by scraping the web page of the automatic Brazilian weather stations [5] using the libraries requests [67] and beautifulsoup4 [68], as well the frameworks Django [69] and Django rest [70]
